[
  {
    "title": "phi ws setup - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/setup",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws setup\n\nSetup workspace from the current directory\n\n​\nParams\npath\nstr\n\nPath to workspace [default: current directory]\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi ws delete\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi ws delete - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/delete",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws delete\n\nDelete workspace record\n\n​\nParams\nws_name\nstr\n\nName of the workspace to delete -ws\n\nall_workspaces\nstr\n\nDelete all workspaces from phidata --all -a\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi ws config\nphi ws setup\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi ws config - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/config",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws config\n\nPrints active workspace config\n\n​\nParams\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi ws restart\nphi ws delete\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi ws restart - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/restart",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws restart\n\nRestart resources for active workspace\n\n​\nParams\nresources_filter\nstr\n\nResource filter. Format - ENV:INFRA:GROUP:NAME:TYPE\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\npull\nbool\n\nPull --pull -p\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi ws patch\nphi ws config\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi ws patch - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/patch",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws patch\n\nUpdate resources for active workspace\n\n​\nParams\nresources_filter\nstr\n\nResource filter. Format - ENV:INFRA:GROUP:NAME:TYPE\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\npull\nbool\n\nPull --pull -p\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi ws down\nphi ws restart\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi ws down - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/down",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws down\n\nDelete resources for active workspace\n\n​\nParams\nresources_filter\nstr\n\nResource filter. Format - ENV:INFRA:GROUP:NAME:TYPE\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi ws up\nphi ws patch\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi ws up - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/up",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws up\n\nCreate resources for the active workspace\n\n​\nParams\nresources_filter\nstr\n\nResource filter. Format - ENV:INFRA:GROUP:NAME:TYPE\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\npull\nbool\n\nPull --pull -p\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi ws create\nphi ws down\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi ws create - Phidata",
    "url": "https://docs.phidata.com/reference/cli/ws/create",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nphi ws create\nphi ws up\nphi ws down\nphi ws patch\nphi ws restart\nphi ws config\nphi ws delete\nphi ws setup\nphi ws\nphi ws create\n\nCreate a new workspace in the current directory.\n\n​\nParams\nname\nstr\n\nName of the new workspace. --name -n\n\ntemplate\nstr\n\nStarter template for the workspace. --template -t\n\nurl\nstr\n\nURL of the starter template. --url -u\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi reset\nphi ws up\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi reset - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/reset",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi reset\n\nReset phi installation\n\n​\nParams\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi set\nphi ws create\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi set - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/set",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi set\n\nSet current directory as active workspace\n\n​\nParams\nws_name\nbool\n\nActive workspace name --ws\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi config\nphi reset\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi config - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/config",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi config\n\nPrint phi config\n\n​\nParams\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nshow_all\nbool\n\nShow all workspaces --all -a\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi restart\nphi set\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi restart - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/restart",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi restart\n\nRestart resources defined in a resources.py file\n\n​\nParams\nresources_file\nstr\n\nPath to workspace file.\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi patch\nphi config\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi patch - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/patch",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi patch\n\nUpdate resources defined in a resources.py file\n\n​\nParams\nresources_file\nstr\n\nPath to workspace file.\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi stop\nphi restart\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi stop - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/stop",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi stop\n\nStop resources defined in a resources.py file\n\n​\nParams\nresources_file\nstr\n\nPath to workspace file.\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi start\nphi patch\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi start - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/start",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi start\n\nStart resources defined in a resources.py file\n\n​\nParams\nresources_file\nstr\n\nPath to workspace file.\n\nenv_filter\nstr\n\nFilter the environment to deploy --env -e\n\ninfra_filter\nstr\n\nFilter the infra to deploy. --infra -i\n\nconfig_filter\nstr\n\nFilter the config to deploy. --config -c\n\ngroup_filter\nstr\n\nFilter resources using group name. --group -g\n\nname_filter\nstr\n\nFilter resource using name. --name -n\n\ntype_filter\nstr\n\nFilter resource using type --type -t\n\ndry_run\nbool\n\nPrint resources and exit. --dry-run -dr\n\nauto_confirm\nbool\n\nSkip the confirmation before deploying resources. --yes -y\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nforce\nbool\n\nForce --force -f\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi auth\nphi stop\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi auth - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/auth",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi auth\n\nAuthenticate with phidata.com\n\n​\nParams\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nphi init\nphi start\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "phi init - Phidata",
    "url": "https://docs.phidata.com/reference/cli/phi/init",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi init\nphi auth\nphi start\nphi stop\nphi patch\nphi restart\nphi config\nphi set\nphi reset\nphi ws\nphi\nphi init\n\nInitialize phidata, use -r to reset\n\n​\nParams\nreset\nbool\n\nReset phidata --reset -r\n\nprint_debug_log\nbool\n\nPrint debug logs. --debug -d\n\nlogin\nbool\n\nLogin with phidata.com --login -l\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPineconeDB\nphi auth\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nParams"
  },
  {
    "title": "PineconeDB - Phidata",
    "url": "https://docs.phidata.com/reference/vectordb/pineconedb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nPgVector\nPgVector\nSingle Store\nQdrant\nLanceDb\nChromaDb\nPineconeDB\nCommand Line\nphi\nphi ws\nVectorDbs\nPineconeDB\n​\nPineconeDB Params\nParameter\tType\tDefault\tDescription\nname\tstr\t-\tThe name of the Pinecone index\ndimension\tint\t-\tThe dimension of the embeddings\nspec\tUnion[Dict, ServerlessSpec, PodSpec]\t-\tThe index spec\nembedder\tOptional[Embedder]\tNone\tEmbedder instance for creating embeddings (defaults to OpenAIEmbedder if not provided)\nmetric\tOptional[str]\t\"cosine\"\tThe metric used for similarity search\nadditional_headers\tOptional[Dict[str, str]]\tNone\tAdditional headers to pass to the Pinecone client\npool_threads\tOptional[int]\t1\tThe number of threads to use for the Pinecone client\nnamespace\tOptional[str]\tNone\tThe namespace for the Pinecone index\ntimeout\tOptional[int]\tNone\tThe timeout for Pinecone operations\nindex_api\tOptional[Any]\tNone\tThe Index API object\napi_key\tOptional[str]\tNone\tThe Pinecone API key\nhost\tOptional[str]\tNone\tThe Pinecone host\nconfig\tOptional[Config]\tNone\tThe Pinecone config\nuse_hybrid_search\tbool\tFalse\tWhether to use hybrid search\nhybrid_alpha\tfloat\t0.5\tThe alpha value for hybrid search\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nChromaDb\nphi init\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPineconeDB Params"
  },
  {
    "title": "ChromaDb - Phidata",
    "url": "https://docs.phidata.com/reference/vectordb/chromadb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nPgVector\nPgVector\nSingle Store\nQdrant\nLanceDb\nChromaDb\nPineconeDB\nCommand Line\nphi\nphi ws\nVectorDbs\nChromaDb\nagent.py\nimport typer\nfrom rich.prompt import Prompt\nfrom typing import Optional\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.chroma import ChromaDb\n\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=ChromaDb(collection=\"recipes\"),\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=False)\n\n\ndef pdf_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        use_tools=True,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(pdf_agent)\n\n\n​\nChromaDb Params\nParameter\tType\tDefault\tDescription\ncollection\tstr\t-\tName of the Chroma collection\nembedder\tEmbedder\tOpenAIEmbedder()\tEmbedder for embedding the document contents\ndistance\tDistance\tDistance.cosine\tDistance metric for similarity search\npath\tstr\t\"tmp/chromadb\"\tPath to store Chroma database\npersistent_client\tbool\tFalse\tWhether to use a persistent Chroma client\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nLanceDb\nPineconeDB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nChromaDb Params"
  },
  {
    "title": "LanceDb - Phidata",
    "url": "https://docs.phidata.com/reference/vectordb/lancedb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nPgVector\nPgVector\nSingle Store\nQdrant\nLanceDb\nChromaDb\nPineconeDB\nCommand Line\nphi\nphi ws\nVectorDbs\nLanceDb\nagent.py\nimport typer\nfrom rich.prompt import Prompt\nfrom typing import Optional\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb\n\n# type: ignore\ndb_url = \"/tmp/lancedb\"\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=LanceDb(table_name=\"recipes\", uri=db_url),\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=False)\n\n\ndef pdf_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        use_tools=True,\n        show_tool_calls=True,\n        # Uncomment the following line to use traditional RAG\n        # add_references_to_prompt=True,\n    )\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(pdf_agent)\n\n\n​\nLanceDb Params\nParameter\tType\tDefault\tDescription\nuri\tlancedb.URI\t/tmp/lancedb\tURI for LanceDB connection\ntable\tOptional[lancedb.db.LanceTable]\tNone\tLanceDB table instance\ntable_name\tOptional[str]\tNone\tName of the LanceDB table\nconnection\tOptional[lancedb.DBConnection]\tNone\tLanceDB connection instance\napi_key\tOptional[str]\tNone\tAPI key for LanceDB connection\nembedder\tOptional[Embedder]\tOpenAIEmbedder()\tEmbedder for embedding document contents\nsearch_type\tSearchType\tSearchType.vector\tType of search to perform\ndistance\tDistance\tDistance.cosine\tDistance metric for similarity search\nnprobes\tOptional[int]\tNone\tNumber of probes for approximate search\nreranker\tOptional[Reranker]\tNone\tReranker for search results\nuse_tantivy\tbool\tTrue\tWhether to use Tantivy for full-text search\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nQdrant\nChromaDb\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nLanceDb Params"
  },
  {
    "title": "Qdrant - Phidata",
    "url": "https://docs.phidata.com/reference/vectordb/qdrant",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nPgVector\nPgVector\nSingle Store\nQdrant\nLanceDb\nChromaDb\nPineconeDB\nCommand Line\nphi\nphi ws\nVectorDbs\nQdrant\nagent.py\nimport os\nimport typer\nfrom typing import Optional\nfrom rich.prompt import Prompt\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.qdrant import Qdrant\n\napi_key = os.getenv(\"QDRANT_API_KEY\")\nqdrant_url = os.getenv(\"QDRANT_URL\")\ncollection_name = \"thai-recipe-index\"\n\nvector_db = Qdrant(\n    collection=collection_name,\n    url=qdrant_url,\n    api_key=api_key,\n)\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db,\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=True, upsert=True)\n\n\ndef qdrant_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        tool_calls=True,\n        use_tools=True,\n        show_tool_calls=True,\n        debug_mode=True,\n        # Uncomment the following line to use traditional RAG\n        # add_references_to_prompt=True,\n    )\n\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(qdrant_agent)\n\n\n​\nQdrant Params\nName\tType\tDefault\tDescription\ncollection\tstr\t-\tName of the Qdrant collection\nembedder\tEmbedder\tOpenAIEmbedder()\tEmbedder for embedding the document contents\ndistance\tDistance\tDistance.cosine\tDistance metric for similarity search\nlocation\tOptional[str]\tNone\tLocation of the Qdrant database\nurl\tOptional[str]\tNone\tURL of the Qdrant server\nport\tOptional[int]\t6333\tPort number for the Qdrant server\ngrpc_port\tint\t6334\tgRPC port number for the Qdrant server\nprefer_grpc\tbool\tFalse\tWhether to prefer gRPC over HTTP\nhttps\tOptional[bool]\tNone\tWhether to use HTTPS\napi_key\tOptional[str]\tNone\tAPI key for authentication\nprefix\tOptional[str]\tNone\tPrefix for the Qdrant API\ntimeout\tOptional[float]\tNone\tTimeout for Qdrant operations\nhost\tOptional[str]\tNone\tHost address for the Qdrant server\npath\tOptional[str]\tNone\tPath to the Qdrant database\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSingle Store\nLanceDb\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nQdrant Params"
  },
  {
    "title": "Single Store - Phidata",
    "url": "https://docs.phidata.com/reference/vectordb/singlestore",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nPgVector\nPgVector\nSingle Store\nQdrant\nLanceDb\nChromaDb\nPineconeDB\nCommand Line\nphi\nphi ws\nVectorDbs\nSingle Store\nagent.py\nimport typer\nfrom typing import Optional\nfrom os import getenv\n\nfrom sqlalchemy.engine import create_engine\n\nfrom phi.assistant import Assistant\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.singlestore import S2VectorDb\n\nUSERNAME = getenv(\"SINGLESTORE_USERNAME\")\nPASSWORD = getenv(\"SINGLESTORE_PASSWORD\")\nHOST = getenv(\"SINGLESTORE_HOST\")\nPORT = getenv(\"SINGLESTORE_PORT\")\nDATABASE = getenv(\"SINGLESTORE_DATABASE\")\nSSL_CERT = getenv(\"SINGLESTORE_SSL_CERT\", None)\n\ndb_url = f\"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4\"\nif SSL_CERT:\n    db_url += f\"&ssl_ca={SSL_CERT}&ssl_verify_cert=true\"\n\ndb_engine = create_engine(db_url)\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=S2VectorDb(\n        collection=\"recipes\",\n        db_engine=db_engine,\n        schema=DATABASE,\n    ),\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=False)\n\n\ndef pdf_assistant(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    assistant = Assistant(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        use_tools=True,\n        show_tool_calls=True,\n        # Uncomment the following line to use traditional RAG\n        # add_references_to_prompt=True,\n    )\n    if run_id is None:\n        run_id = assistant.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        assistant.cli_app(markdown=True)\n\n\nif __name__ == \"__main__\":\n    typer.run(pdf_assistant)\n\n\n​\nSingle Store Params\nParameter\tType\tDefault\tDescription\ncollection\tstr\t-\tName of the collection to store vector data\nschema\tOptional[str]\t\"ai\"\tDatabase schema name\ndb_url\tOptional[str]\tNone\tDatabase connection URL\ndb_engine\tOptional[Engine]\tNone\tSQLAlchemy database engine\nembedder\tEmbedder\tOpenAIEmbedder()\tEmbedder instance for creating embeddings\ndistance\tDistance\tDistance.cosine\tDistance metric for vector comparisons\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPgVector\nQdrant\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSingle Store Params"
  },
  {
    "title": "PgVector - Phidata",
    "url": "https://docs.phidata.com/reference/vectordb/pgvector2",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nPgVector\nPgVector\nSingle Store\nQdrant\nLanceDb\nChromaDb\nPineconeDB\nCommand Line\nphi\nphi ws\nVectorDbs\nPgVector\n​\nPgVectorDb Params\nParameter\tType\tDefault\tDescription\ncollection\tstr\t-\tName of the collection to store vector data\nschema\tOptional[str]\t\"ai\"\tDatabase schema name\ndb_url\tOptional[str]\tNone\tDatabase connection URL\ndb_engine\tOptional[Engine]\tNone\tSQLAlchemy database engine\nembedder\tOptional[Embedder]\tNone\tEmbedder instance for creating embeddings (defaults to OpenAIEmbedder if not provided)\ndistance\tDistance\tDistance.cosine\tDistance metric for vector comparisons\nindex\tOptional[Union[Ivfflat, HNSW]]\tHNSW()\tVector index configuration\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPgVector\nSingle Store\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPgVectorDb Params"
  },
  {
    "title": "PgVector - Phidata",
    "url": "https://docs.phidata.com/reference/vectordb/pgvector",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nPgVector\nPgVector\nSingle Store\nQdrant\nLanceDb\nChromaDb\nPineconeDB\nCommand Line\nphi\nphi ws\nVectorDbs\nPgVector\nagent.py\nfrom phi.agent import Agent\nfrom phi.storage.agent.postgres import PgAgentStorage\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector2\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nagent = Agent(\n    storage=PgAgentStorage(table_name=\"recipe_agent\", db_url=db_url),\n    knowledge_base=PDFUrlKnowledgeBase(\n        urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n        vector_db=PgVector2(collection=\"recipe_documents\", db_url=db_url),\n    ),\n    # Show tool calls in the response\n    show_tool_calls=True,\n    # Enable the agent to search the knowledge base\n    search_knowledge=True,\n    # Enable the agent to read the chat history\n    read_chat_history=True,\n)\n# Comment out after first run\nagent.knowledge_base.load(recreate=False)  # type: ignore\n\nagent.print_response(\"How do I make pad thai?\", markdown=True)\n\n\n​\nPgVectorDb Params\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to store vector data\nschema\tstr\t\"ai\"\tDatabase schema name\ndb_url\tOptional[str]\tNone\tDatabase connection URL\ndb_engine\tOptional[Engine]\tNone\tSQLAlchemy database engine\nembedder\tOptional[Embedder]\tOpenAIEmbedder()\tEmbedder instance for creating embeddings\nsearch_type\tSearchType\tSearchType.vector\tType of search to perform\nvector_index\tUnion[Ivfflat, HNSW]\tHNSW()\tVector index configuration\ndistance\tDistance\tDistance.cosine\tDistance metric for vector comparisons\nprefix_match\tbool\tFalse\tEnable prefix matching for full-text search\nvector_score_weight\tfloat\t0.5\tWeight for vector similarity in hybrid search\ncontent_language\tstr\t\"english\"\tLanguage for full-text search\nschema_version\tint\t1\tVersion of the database schema\nauto_upgrade_schema\tbool\tFalse\tAutomatically upgrade schema if True\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWikipedia\nPgVector\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPgVectorDb Params"
  },
  {
    "title": "ChromaDB Agent Knowledge - Phidata",
    "url": "https://docs.phidata.com/vectordb/chroma",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nIntroduction\nPgVector\nQdrant\nPinecone\nLanceDB\nChromaDB\nSingleStore\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nVectorDbs\nChromaDB Agent Knowledge\n​\nSetup\npip install chromadb\n\n​\nExample\nagent_with_knowledge.py\nimport typer\nfrom rich.prompt import Prompt\nfrom typing import Optional\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.chroma import ChromaDb\n\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=ChromaDb(collection=\"recipes\"),\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=False)\n\n\ndef pdf_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        use_tools=True,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(pdf_agent)\n\n\n​\nChromaDb Params\nParameter\tType\tDefault\tDescription\ncollection\tstr\t-\tThe name of the collection to use.\nembedder\tEmbedder\tOpenAIEmbedder()\tThe embedder to use for embedding document contents.\ndistance\tDistance\tcosine\tThe distance metric to use.\npath\tstr\t”tmp/chromadb”\tThe path where ChromaDB data will be stored.\npersistent_client\tbool\tFalse\tWhether to use a persistent ChromaDB client.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nLanceDB\nSingleStore\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nExample\nChromaDb Params"
  },
  {
    "title": "LanceDB Agent Knowledge - Phidata",
    "url": "https://docs.phidata.com/vectordb/lancedb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nIntroduction\nPgVector\nQdrant\nPinecone\nLanceDB\nChromaDB\nSingleStore\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nVectorDbs\nLanceDB Agent Knowledge\n​\nSetup\npip install lancedb\n\n​\nExample\nagent_with_knowledge.py\nimport typer\nfrom typing import Optional\nfrom rich.prompt import Prompt\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb\nfrom phi.vectordb.search import SearchType\n\n# LanceDB Vector DB\nvector_db = LanceDb(\n    table_name=\"recipes\",\n    uri=\"/tmp/lancedb\",\n    search_type=SearchType.keyword,\n)\n\n# Knowledge Base\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db,\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=True)\n\n\ndef lancedb_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge=knowledge_base,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(lancedb_agent)\n\n\n​\nLanceDb Params\nParameter\tType\tDefault\tDescription\nuri\tstr\t-\tThe URI to connect to.\ntable\tLanceTable\t-\tThe Lance table to use.\ntable_name\tstr\t-\tThe name of the table to use.\nconnection\tDBConnection\t-\tThe database connection to use.\napi_key\tstr\t-\tThe API key to use.\nembedder\tEmbedder\t-\tThe embedder to use.\nsearch_type\tSearchType\tvector\tThe search type to use.\ndistance\tDistance\tcosine\tThe distance to use.\nnprobes\tint\t-\tThe number of probes to use. More Info\nreranker\tReranker\t-\tThe reranker to use. More Info\nuse_tantivy\tbool\t-\tWhether to use tantivy.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPinecone\nChromaDB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nExample\nLanceDb Params"
  },
  {
    "title": "Pinecone Agent Knowledge - Phidata",
    "url": "https://docs.phidata.com/vectordb/pinecone",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nIntroduction\nPgVector\nQdrant\nPinecone\nLanceDB\nChromaDB\nSingleStore\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nVectorDbs\nPinecone Agent Knowledge\n​\nSetup\n\nFollow the instructions in the Pinecone Setup Guide to get started quickly with Pinecone.\n\n​\nExample\nagent_with_knowledge.py\nimport os\nimport typer\nfrom typing import Optional\nfrom rich.prompt import Prompt\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pineconedb import PineconeDB\n\napi_key = os.getenv(\"PINECONE_API_KEY\")\nindex_name = \"thai-recipe-hybrid-search\"\n\nvector_db = PineconeDB(\n    name=index_name,\n    dimension=1536,\n    metric=\"cosine\",\n    spec={\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}},\n    api_key=api_key,\n    use_hybrid_search=True,\n    hybrid_alpha=0.5,\n)\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db,\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=True, upsert=True)\n\n\ndef pinecone_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge=knowledge_base,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(pinecone_agent)\n\n\n\n​\nPineconeDB Params\nParameter\tType\tDefault\tDescription\nname\tstr\t-\tThe name of the table to use.\ndimension\tint\t-\tThe dimension of the embeddings.\nspec\tUnion[Dict, ServerlessSpec, PodSpec]\t-\tThe spec of the table to use. More Info\nembedder\tOptional[Embedder]\tNone\tThe embedder to use for encoding vectors. If not provided, a default embedder will be used.\nmetric\tOptional[str]\t\"cosine\"\tThe metric used for similarity search.\nadditional_headers\tOptional[Dict[str, str]]\tNone\tAdditional headers to include in API requests.\npool_threads\tOptional[int]\t1\tThe number of threads to use for the connection pool.\nnamespace\tOptional[str]\tNone\tThe namespace to use for the index.\ntimeout\tOptional[int]\tNone\tThe timeout for API requests in seconds.\nindex_api\tOptional[Any]\tNone\tA custom index API implementation to use instead of the default.\napi_key\tOptional[str]\tNone\tThe API key for authentication with Pinecone.\nhost\tOptional[str]\tNone\tThe host URL for the Pinecone service.\nconfig\tOptional[Config]\tNone\tAdditional configuration options for the Pinecone client.\nuse_hybrid_search\tbool\tFalse\tWhether to use hybrid search (combining vector and keyword search).\nhybrid_alpha\tfloat\t0.5\tThe alpha parameter for hybrid search, balancing between vector and keyword search.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nQdrant\nLanceDB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nExample\nPineconeDB Params"
  },
  {
    "title": "Qdrant Agent Knowledge - Phidata",
    "url": "https://docs.phidata.com/vectordb/qdrant",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nIntroduction\nPgVector\nQdrant\nPinecone\nLanceDB\nChromaDB\nSingleStore\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nVectorDbs\nQdrant Agent Knowledge\n​\nSetup\n\nFollow the instructions in the Qdrant Setup Guide to install Qdrant locally. Here is a guide to get API keys: Qdrant API Keys.\n\n​\nExample\nagent_with_knowledge.py\nimport os\nimport typer\nfrom typing import Optional\nfrom rich.prompt import Prompt\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.qdrant import Qdrant\n\napi_key = os.getenv(\"QDRANT_API_KEY\")\nqdrant_url = os.getenv(\"QDRANT_URL\")\ncollection_name = \"thai-recipe-index\"\n\nvector_db = Qdrant(\n    collection=collection_name,\n    url=qdrant_url,\n    api_key=api_key,\n)\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db,\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=True, upsert=True)\n\n\ndef qdrant_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge=knowledge_base,\n        tool_calls=True,\n        use_tools=True,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(qdrant_agent)\n\n\n​\nQdrant Params\nParameter\tType\tDefault\tDescription\ncollection\tstr\t-\tThe name of the collection to use.\nembedder\tEmbedder\tOpenAIEmbedder\tThe embedder to use.\ndistance\tDistance\tcosine\tThe distance to use.\nlocation\tOptional[str]\tNone\tThe location of the Qdrant database.\nurl\tOptional[str]\tNone\tThe URL of the Qdrant server.\nport\tOptional[int]\t6333\tThe port number for the Qdrant server.\ngrpc_port\tint\t6334\tThe gRPC port number.\nprefer_grpc\tbool\tFalse\tWhether to prefer gRPC over HTTP.\nhttps\tOptional[bool]\tNone\tWhether to use HTTPS for connection.\napi_key\tOptional[str]\tNone\tThe API key for authentication.\nprefix\tOptional[str]\tNone\tThe prefix to use for the Qdrant client.\ntimeout\tOptional[float]\tNone\tThe timeout for requests in seconds.\nhost\tOptional[str]\tNone\tThe host address of the Qdrant server.\npath\tOptional[str]\tNone\tThe path to the Qdrant database.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPgVector\nPinecone\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nExample\nQdrant Params"
  },
  {
    "title": "Wikipedia KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/wikipedia",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nWikipedia KnowledgeBase\n​\nExample\n\nInstall wikipedia if needed using this guide\n\nknowledge_base.py\nfrom phi.knowledge.wikipedia import WikipediaKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = WikipediaKnowledgeBase(\n    topics=[\"Manchester United\", \"Real Madrid\"],\n    # Table name: ai.wikipedia_documents\n    vector_db=PgVector(\n        table_name=\"wikipedia_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nWikipediaKnowledgeBase Params\nParameter\tType\tDefault\tDescription\ntopics\tList[str]\t[]\tTopics to read\n​\nAgentKnowledge Params\n\nWikipediaKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWebsite\nPgVector\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nWikipediaKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "Website KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/website",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nWebsite KnowledgeBase\n​\nExample\n\nInstall beautifulsoup4 using this guide\n\nknowledge_base.py\nfrom phi.knowledge.website import WebsiteKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = WebsiteKnowledgeBase(\n    urls=[\"https://docs.phidata.com/introduction\"],\n    # Number of links to follow from the seed URLs\n    max_links=10,\n    # Table name: ai.website_documents\n    vector_db=PgVector(\n        table_name=\"website_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nWebsiteKnowledgeBase Params\nParameter\tType\tDefault\tDescription\nurls\tList[str]\t[]\tURLs to read\nreader\tOptional[WebsiteReader]\tNone\tA WebsiteReader that reads the urls and converts them into Documents for the vector database.\nmax_depth\tint\t3\tMaximum depth to crawl.\nmax_links\tint\t10\tNumber of links to crawl.\n​\nAgentKnowledge Params\n\nWebsiteKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nText\nWikipedia\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nWebsiteKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "Text KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/text",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nText KnowledgeBase\n​\nExample\n\nInstall textract if needed using this guide\n\nknowledge_base.py\nfrom phi.knowledge.text import TextKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = TextKnowledgeBase(\n    path=\"data/docs\",\n    # Table name: ai.text_documents\n    vector_db=PgVector(\n        table_name=\"text_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nTextKnowledgeBase Params\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to text files. Can point to a single text file or a directory of text files.\nformats\tList[str]\t[\".txt\"]\tFormats accepted by this knowledge base.\nreader\tTextReader\tTextReader()\tA TextReader that converts the text files into Documents for the vector database.\n​\nAgentKnowledge Params\n\nTextKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPDF Url\nWebsite\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nTextKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "PDF Url KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/pdf-url",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nPDF Url KnowledgeBase\n​\nExample\n\nInstall pypdf if needed using this guide\n\nknowledge_base.py\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"pdf_url\"],\n    # Table name: llm.pdf_documents\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nPDFUrlKnowledgeBase Params\nParameter\tType\tDefault\tDescription\nurls\tList[str]\t-\tURLs for PDF files.\nreader\tPDFUrlReader\t-\tA PDFUrlReader that converts the PDFs into Documents for the vector database.\n​\nAgentKnowledge Params\n\nPDFUrlKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPDF\nText\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nPDFUrlKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "PDF KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/pdf",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nPDF KnowledgeBase\n​\nExample\n\nInstall pypdf if needed using this guide\n\nknowledge_base.py\nfrom phi.knowledge.pdf import PDFKnowledgeBase, PDFReader\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\npdf_knowledge_base = PDFKnowledgeBase(\n    path=\"data/pdfs\",\n    # Table name: llm.pdf_documents\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n    reader=PDFReader(chunk=True),\n)\n\n​\nPDFKnowledgeBase Params\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to PDF files. Can point to a single PDF file or a directory of PDF files.\nreader\tUnion[PDFReader, PDFImageReader]\tPDFReader()\tA PDFReader or PDFImageReader that converts the PDFs into Documents for the vector database.\n​\nAgentKnowledge Params\n\nPDFKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nLlamaIndex\nPDF Url\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nPDFKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "LlamaIndex KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/llamaindex",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nLlamaIndex KnowledgeBase\n​\nLlamaIndexKnowledgeBase Params\nParameter\tType\tDefault\tDescription\nretriever\tBaseRetriever\t-\tLlamaIndex retriever used for querying the knowledge base\nloader\tOptional[Callable]\tNone\tOptional loader function to load documents into the knowledge base\n​\nAgentKnowledge Params\n\nLlamaIndexKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nLangChain\nPDF\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nLlamaIndexKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "LangChain KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/langchain",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nLangChain KnowledgeBase\n​\nExample\nlangchain_kb.py\nfrom phi.agent import Agent\nfrom phi.knowledge.langchain import LangChainKnowledgeBase\n\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\nchroma_db_dir = \"./chroma_db\"\n\n\ndef load_vector_store():\n    state_of_the_union = ws_settings.ws_root.joinpath(\"data/demo/state_of_the_union.txt\")\n    # -*- Load the document\n    raw_documents = TextLoader(str(state_of_the_union)).load()\n    # -*- Split it into chunks\n    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n    documents = text_splitter.split_documents(raw_documents)\n    # -*- Embed each chunk and load it into the vector store\n    Chroma.from_documents(documents, OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))\n\n\n# -*- Get the vectordb\ndb = Chroma(embedding_function=OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))\n# -*- Create a retriever from the vector store\nretriever = db.as_retriever()\n\n# -*- Create a knowledge base from the vector store\nknowledge_base = LangChainKnowledgeBase(retriever=retriever)\n\nagent = Agent(knowledge_base=knowledge_base, add_references_to_prompt=True)\nconv.print_response(\"What did the president say about technology?\")\n\n​\nLangChainKnowledgeBase Params\nParameter\tType\tDefault\tDescription\nloader\tOptional[Callable]\tNone\tLangChain loader.\nvectorstore\tOptional[Any]\tNone\tLangChain vector store used to create a retriever.\nsearch_kwargs\tOptional[dict]\tNone\tSearch kwargs when creating a retriever using the langchain vector store.\nretriever\tOptional[Any]\tNone\tLangChain retriever.\n​\nAgentKnowledge Params\n\nLangChainKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nJSON\nLlamaIndex\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nLangChainKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "JSON KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/json",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nJSON KnowledgeBase\n​\nExample\nknowledge_base.py\nfrom phi.knowledge.json import JSONKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = JSONKnowledgeBase(\n    path=\"data/json\",\n    # Table name: llm.json_documents\n    vector_db=PgVector(\n        table_name=\"json_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nJSONKnowledgeBase Params\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to JSON files.\nCan point to a single JSON file or a directory of JSON files.\nreader\tJSONReader\tJSONReader()\tA JSONReader that converts the JSON files into Documents for the vector database.\n​\nAgentKnowledge Params\n\nJSONKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDocument\nLangChain\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nJSONKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "Document KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/document",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nDocument KnowledgeBase\n​\nDocumentKnowledgeBase Params\nParameter\tType\tDefault\tDescription\ndocuments\tList[Document]\t-\tList of Document objects to be used as the knowledge base\n​\nAgentKnowledge Params\n\nDocumentKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDocx\nJSON\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nDocumentKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "Docx KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/docx",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nDocx KnowledgeBase\n​\nExample\nknowledge_base.py\nfrom phi.knowledge.text import DocxKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = DocxKnowledgeBase(\n    path=\"data/docs\",\n    # Table name: ai.docx_documents\n    vector_db=PgVector(\n        table_name=\"docx_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nDocxKnowledgeBase Params\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to text files. Can point to a single docx file or a directory of docx files.\nformats\tList[str]\t[\".doc\", \".docx\"]\tFormats accepted by this knowledge base.\nreader\tDocxReader\tDocxReader()\tA DocxReader that converts the docx files into Documents for the vector database.\n​\nAgentKnowledge Params\n\nDocxKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCSV\nDocument\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nDocxKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "CSV KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/csv",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nCSV KnowledgeBase\n​\nCSVKnowledgeBase Params\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to the CSV file\nreader\tCSVReader\tCSVReader()\tA CSVReader that reads the CSV file and converts it into Documents for the vector database\n​\nAgentKnowledge Params\n\nCSVKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCombined\nDocx\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nCSVKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "Combined KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/combined",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nCombined KnowledgeBase\n​\nExample\nknowledge_base.py\nfrom phi.knowledge.combined import CombinedKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = CombinedKnowledgeBase(\n    sources=[\n        url_pdf_knowledge_base,\n        website_knowledge_base,\n        local_pdf_knowledge_base,\n    ],\n    vector_db=PgVector(\n        # Table name: llm.combined_documents\n        table_name=\"combined_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nCombinedKnowledgeBase Params\nParameter\tType\tDefault\tDescription\nsources\tList[AgentKnowledge]\t[]\tList of knowledge bases.\n​\nAgentKnowledge Params\n\nCombinedKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nArxiv\nCSV\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nCombinedKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "Arxiv KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/reference/kb/arxiv",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nArxiv KnowledgeBase\n​\nExample\n\nInstall arxiv using this guide\n\nknowledge_base.py\nfrom phi.knowledge.arxiv import ArxivKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nfrom resources import vector_db\n\nknowledge_base = ArxivKnowledgeBase(\n    queries=[\"Generative AI\", \"Machine Learning\"],\n    # Table name: llm.arxiv_documents\n    vector_db=PgVector(\n        table_name=\"arxiv_documents\",\n        db_url=vector_db.get_db_connection_local(),\n    ),\n)\n\n​\nArxivKnowledgeBase Params\nParameter\tType\tDefault\tDescription\nqueries\tList[str]\t[]\tQueries to search\nreader\tArxivReader\tArxivReader()\tA ArxivReader that reads the articles and converts them into Documents for the vector database\n​\nAgentKnowledge Params\n\nArxivKnowledgeBase is a subclass of the AgentKnowledge class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nBase\nCombined\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nArxivKnowledgeBase Params\nAgentKnowledge Params"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/vectordb/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nIntroduction\nPgVector\nQdrant\nPinecone\nLanceDB\nChromaDB\nSingleStore\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nVectorDbs\nIntroduction\n\nVector databases enable us to store information as embeddings and search for “results similar” to our input query using cosine similarity or full text search. These results are then provided to the Agent as context so it can respond in a context-aware manner using Retrieval Augmented Generation (RAG).\n\nHere’s how vector databases are used with Agents:\n\n1\n\nChunk the information\n\nBreak down the knowledge into smaller chunks to ensure our search query returns only relevant results.\n\n2\n\nLoad the knowledge base\n\nConvert the chunks into embedding vectors and store them in a vector database.\n\n3\n\nSearch the knowledge base\n\nWhen the user sends a message, we convert the input message into an embedding and “search” for nearest neighbors in the vector database.\n\nMany vector databases also support hybrid search, which combines the power of vector similarity search with traditional keyword-based search. This approach can significantly improve the relevance and accuracy of search results, especially for complex queries or when dealing with diverse types of data.\n\nHybrid search typically works by:\n\nPerforming a vector similarity search to find semantically similar content.\nConducting a keyword-based search to identify exact or close matches.\nCombining the results using a weighted approach to provide the most relevant information.\n\nThis capability allows for more flexible and powerful querying, often yielding better results than either method alone.\n\nThe following VectorDb are currently supported:\n\nPgVector*\nLanceDb*\nPinecone*\nQdrant\n\n*hybrid search supported\n\nEach of these databases has its own strengths and features, including varying levels of support for hybrid search. Be sure to check the specific documentation for each to understand how to best leverage their capabilities in your projects.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWikipedia\nPgVector\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "PgVector Agent Knowledge - Phidata",
    "url": "https://docs.phidata.com/vectordb/pgvector",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nIntroduction\nPgVector\nQdrant\nPinecone\nLanceDB\nChromaDB\nSingleStore\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nVectorDbs\nPgVector Agent Knowledge\n​\nSetup\ndocker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\n​\nExample\nagent_with_knowledge.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector, SearchType\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url, search_type=SearchType.hybrid),\n)\n# Load the knowledge base: Comment out after first run\nknowledge_base.load(recreate=True, upsert=True)\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    knowledge=knowledge_base,\n    # Add a tool to read chat history.\n    read_chat_history=True,\n    show_tool_calls=True,\n    markdown=True,\n    # debug_mode=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\nagent.print_response(\"What was my last question?\", stream=True)\n\n\n​\nPgVector Params\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tThe name of the table to use.\nschema\tstr\t-\tThe schema to use.\ndb_url\tstr\t-\tThe database URL to connect to.\ndb_engine\tEngine\t-\tThe database engine to use.\nembedder\tEmbedder\t-\tThe embedder to use.\nsearch_type\tSearchType\tvector\tThe search type to use.\nvector_index\tUnion[Ivfflat, HNSW]\t-\tThe vector index to use.\ndistance\tDistance\tcosine\tThe distance to use.\nprefix_match\tbool\t-\tWhether to use prefix matching.\nvector_score_weight\tfloat\t0.5\tWeight for vector similarity in hybrid search. Must be between 0 and 1.\ncontent_language\tstr\t-\tThe content language to use.\nschema_version\tint\t-\tThe schema version to use.\nauto_upgrade_schema\tbool\t-\tWhether to auto upgrade the schema.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nQdrant\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nExample\nPgVector Params"
  },
  {
    "title": "SingleStore Agent Knowledge - Phidata",
    "url": "https://docs.phidata.com/vectordb/singlestore",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nIntroduction\nPgVector\nQdrant\nPinecone\nLanceDB\nChromaDB\nSingleStore\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nVectorDbs\nSingleStore Agent Knowledge\n​\nSetup\n\nFollow the instructions in the SingleStore Setup Guide to install SingleStore locally.\n\n​\nExample\nagent_with_knowledge.py\nimport typer\nfrom typing import Optional\nfrom os import getenv\n\nfrom sqlalchemy.engine import create_engine\n\nfrom phi.assistant import Assistant\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.singlestore import S2VectorDb\n\nUSERNAME = getenv(\"SINGLESTORE_USERNAME\")\nPASSWORD = getenv(\"SINGLESTORE_PASSWORD\")\nHOST = getenv(\"SINGLESTORE_HOST\")\nPORT = getenv(\"SINGLESTORE_PORT\")\nDATABASE = getenv(\"SINGLESTORE_DATABASE\")\nSSL_CERT = getenv(\"SINGLESTORE_SSL_CERT\", None)\n\ndb_url = f\"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4\"\nif SSL_CERT:\n    db_url += f\"&ssl_ca={SSL_CERT}&ssl_verify_cert=true\"\n\ndb_engine = create_engine(db_url)\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=S2VectorDb(\n        collection=\"recipes\",\n        db_engine=db_engine,\n        schema=DATABASE,\n    ),\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=False)\n\n\ndef pdf_assistant(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    assistant = Assistant(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        use_tools=True,\n        show_tool_calls=True,\n        # Uncomment the following line to use traditional RAG\n        # add_references_to_prompt=True,\n    )\n    if run_id is None:\n        run_id = assistant.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        assistant.cli_app(markdown=True)\n\n\nif __name__ == \"__main__\":\n    typer.run(pdf_assistant)\n\n\n​\nSingleStore Params\nParameter\tType\tDefault\tDescription\ncollection\tstr\t-\tThe name of the collection to use.\nschema\tOptional[str]\t\"ai\"\tThe database schema to use.\ndb_url\tOptional[str]\tNone\tThe database connection URL.\ndb_engine\tOptional[Engine]\tNone\tSQLAlchemy engine instance.\nembedder\tEmbedder\tOpenAIEmbedder()\tThe embedder to use for creating vector embeddings.\ndistance\tDistance\tDistance.cosine\tThe distance metric to use for similarity search.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nChromaDB\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nExample\nSingleStore Params"
  },
  {
    "title": "AgentKnowledge - Phidata",
    "url": "https://docs.phidata.com/reference/kb/base",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nBase\nArxiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Url\nText\nWebsite\nWikipedia\nVectorDbs\nCommand Line\nphi\nphi ws\nKnowledge Base\nAgentKnowledge\n​\nAgentKnowledge Params\nParameter\tType\tDefault\tDescription\nreader\tOptional[Reader]\tNone\tReader to read the documents\nvector_db\tOptional[VectorDb]\tNone\tVector db to store the knowledge base\nnum_documents\tint\t2\tNumber of relevant documents to return on search\noptimize_on\tOptional[int]\t1000\tNumber of documents to optimize the vector db on\ndriver\tstr\t\"knowledge\"\tDriver for the Assistant knowledge\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDynamoDB\nArxiv\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAgentKnowledge Params"
  },
  {
    "title": "Wikipedia KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/knowledge/wikipedia",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nWikipedia KnowledgeBase\n\nThe WikipediaKnowledgeBase reads wikipedia topics, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install wikipedia\n\nknowledge_base.py\nfrom phi.knowledge.wikipedia import WikipediaKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = WikipediaKnowledgeBase(\n    topics=[\"Manchester United\", \"Real Madrid\"],\n    # Table name: ai.wikipedia_documents\n    vector_db=PgVector(\n        table_name=\"wikipedia_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntopics\tList[str]\t-\tTopics to read\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nreader\tReader\t-\tA Reader that reads the topics and converts them into Documents for the vector database.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWebsite\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Website Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/website",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nWebsite Knowledge Base\n\nThe WebsiteKnowledgeBase reads websites, converts them into vector embeddings and loads them to a vector_db.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install bs4\n\nknowledge_base.py\nfrom phi.knowledge.website import WebsiteKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = WebsiteKnowledgeBase(\n    urls=[\"https://docs.phidata.com/introduction\"],\n    # Number of links to follow from the seed URLs\n    max_links=10,\n    # Table name: ai.website_documents\n    vector_db=PgVector(\n        table_name=\"website_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nurls\tList[str]\t-\tURLs to read\nreader\tWebsiteReader\t-\tA WebsiteReader that reads the urls and converts them into Documents for the vector database.\nmax_depth\tint\t3\tMaximum depth to crawl.\nmax_links\tint\t10\tNumber of links to crawl.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nText\nWikipedia\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Text Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/text",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nText Knowledge Base\n\nThe TextKnowledgeBase reads local txt files, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\nknowledge_base.py\nfrom phi.knowledge.text import TextKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = TextKnowledgeBase(\n    path=\"data/txt_files\",\n    # Table name: ai.text_documents\n    vector_db=PgVector(\n        table_name=\"text_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge_base=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to text files. Can point to a single txt file or a directory of txt files.\nformats\tList[str]\t[\".txt\"]\tFormats accepted by this knowledge base.\nreader\tTextReader\tTextReader()\tA TextReader that converts the text files into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nS3 Text\nWebsite\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "S3 Text Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/s3_text",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nS3 Text Knowledge Base\n\nThe S3TextKnowledgeBase reads text files from an S3 bucket, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install textract\n\nfrom phi.knowledge.s3.text import S3TextKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nknowledge_base = S3TextKnowledgeBase(\n    bucket_name=\"phi-public\",\n    key=\"recipes/recipes.docx\",\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"How to make Hummus?\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nformats\tList[str]\t[\".doc\", \".docx\"]\tFormats accepted by this knowledge base.\nreader\tS3TextReader\tS3TextReader()\tA S3TextReader that converts the Text files into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nS3 PDF\nText\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "PDF URL Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/pdf-url",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nPDF URL Knowledge Base\n\nThe PDFUrlKnowledgeBase reads PDFs from urls, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install pypdf\n\nknowledge_base.py\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"pdf_url\"],\n    # Table name: ai.pdf_documents\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nurls\tList[str]\t-\tURLs for PDF files.\nreader\tUnion[PDFUrlReader, PDFUrlImageReader]\tPDFUrlReader()\tA PDFUrlReader that converts the PDFs into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPDF\nS3 PDF\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "S3 PDF Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/s3_pdf",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nS3 PDF Knowledge Base\n\nThe S3PDFKnowledgeBase reads PDF files from an S3 bucket, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\nfrom phi.knowledge.s3.pdf import S3PDFKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nknowledge_base = S3PDFKnowledgeBase(\n    bucket_name=\"phi-public\",\n    key=\"recipes/ThaiRecipes.pdf\",\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"How to make Thai curry?\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nreader\tS3PDFReader\tS3PDFReader()\tA S3PDFReader that converts the PDFs into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPDF Urls\nS3 Text\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "PDF Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/pdf",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nPDF Knowledge Base\n\nThe PDFKnowledgeBase reads local PDF files, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install pypdf\n\nknowledge_base.py\nfrom phi.knowledge.pdf import PDFKnowledgeBase, PDFReader\nfrom phi.vectordb.pgvector import PgVector\n\npdf_knowledge_base = PDFKnowledgeBase(\n    path=\"data/pdfs\",\n    # Table name: ai.pdf_documents\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n    reader=PDFReader(chunk=True),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to PDF files. Can point to a single PDF file or a directory of PDF files.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base. Example: PgVector\nreader\tUnion[PDFReader, PDFImageReader]\tPDFReader()\tA PDFReader that converts the PDFs into Documents for the vector database.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on. For Example: Create an index for PgVector.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nLlamaIndex\nPDF Urls\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "LangChain Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/langchain",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nLangChain Knowledge Base\n\nThe LangchainKnowledgeBase allows us to use a LangChain retriever or vector store as a knowledge base.\n\n​\nUsage\npip install langchain\n\nlangchain_kb.py\nfrom phi.agent import Agent\nfrom phi.knowledge.langchain import LangChainKnowledgeBase\n\nfrom langchain.embeddings import OpenAIEmbeddings\nfrom langchain.document_loaders import TextLoader\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import Chroma\n\nchroma_db_dir = \"./chroma_db\"\n\n\ndef load_vector_store():\n    state_of_the_union = ws_settings.ws_root.joinpath(\"data/demo/state_of_the_union.txt\")\n    # -*- Load the document\n    raw_documents = TextLoader(str(state_of_the_union)).load()\n    # -*- Split it into chunks\n    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n    documents = text_splitter.split_documents(raw_documents)\n    # -*- Embed each chunk and load it into the vector store\n    Chroma.from_documents(documents, OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))\n\n\n# -*- Get the vectordb\ndb = Chroma(embedding_function=OpenAIEmbeddings(), persist_directory=str(chroma_db_dir))\n# -*- Create a retriever from the vector store\nretriever = db.as_retriever()\n\n# -*- Create a knowledge base from the vector store\nknowledge_base = LangChainKnowledgeBase(retriever=retriever)\n\nagent = Agent(knowledge_base=knowledge_base, add_references_to_prompt=True)\nconv.print_response(\"What did the president say about technology?\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nretriever\tAny\tNone\tLangChain retriever.\nvectorstore\tAny\tNone\tLangChain vector store used to create a retriever.\nsearch_kwargs\tdict\tNone\tSearch kwargs when creating a retriever using the langchain vector store.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nJSON\nLlamaIndex\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "LlamaIndex Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/llamaindex",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nLlamaIndex Knowledge Base\n\nThe LlamaIndexKnowledgeBase allows us to use a LlamaIndex retriever or vector store as a knowledge base.\n\n​\nUsage\npip install llama-index-core llama-index-readers-file llama-index-embeddings-openai\n\nllamaindex_kb.py\n\nfrom pathlib import Path\nfrom shutil import rmtree\n\nimport httpx\nfrom phi.agent import Agent\nfrom phi.knowledge.llamaindex import LlamaIndexKnowledgeBase\nfrom llama_index.core import (\n    SimpleDirectoryReader,\n    StorageContext,\n    VectorStoreIndex,\n)\nfrom llama_index.core.retrievers import VectorIndexRetriever\nfrom llama_index.core.node_parser import SentenceSplitter\n\n\ndata_dir = Path(__file__).parent.parent.parent.joinpath(\"wip\", \"data\", \"paul_graham\")\nif data_dir.is_dir():\n    rmtree(path=data_dir, ignore_errors=True)\ndata_dir.mkdir(parents=True, exist_ok=True)\n\nurl = \"https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt\"\nfile_path = data_dir.joinpath(\"paul_graham_essay.txt\")\nresponse = httpx.get(url)\nif response.status_code == 200:\n    with open(file_path, \"wb\") as file:\n        file.write(response.content)\n    print(f\"File downloaded and saved as {file_path}\")\nelse:\n    print(\"Failed to download the file\")\n\n\ndocuments = SimpleDirectoryReader(str(data_dir)).load_data()\n\nsplitter = SentenceSplitter(chunk_size=1024)\n\nnodes = splitter.get_nodes_from_documents(documents)\n\nstorage_context = StorageContext.from_defaults()\n\nindex = VectorStoreIndex(nodes=nodes, storage_context=storage_context)\n\nretriever = VectorIndexRetriever(index)\n\n# Create a knowledge base from the vector store\nknowledge_base = LlamaIndexKnowledgeBase(retriever=retriever)\n\n# Create an agent with the knowledge base\nagent = Agent(knowledge_base=knowledge_base, search_knowledge=True, debug_mode=True, show_tool_calls=True)\n\n# Use the agent to ask a question and print a response.\nagent.print_response(\"Explain what this text means: low end eats the high end\", markdown=True)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nretriever\tBaseRetriever\tNone\tLlamaIndex retriever used for querying the knowledge base.\nloader\tOptional[Callable]\tNone\tOptional callable function to load documents into the knowledge base.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nLangChain\nPDF\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "JSON Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/json",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nJSON Knowledge Base\n\nThe JSONKnowledgeBase reads local JSON files, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\nknowledge_base.py\nfrom phi.knowledge.json import JSONKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = JSONKnowledgeBase(\n    path=\"data/json\",\n    # Table name: ai.json_documents\n    vector_db=PgVector(\n        table_name=\"json_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to JSON files. Can point to a single JSON file or a directory of JSON files.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nreader\tJSONReader\tJSONReader()\tA JSONReader that converts the JSON files into Documents for the vector database.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDocument\nLangChain\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Document Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/document",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nDocument Knowledge Base\n\nThe DocumentKnowledgeBase reads local docs files, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install textract\n\nfrom phi.knowledge.document import DocumentKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = DocumentKnowledgeBase(\n    path=\"data/docs\",\n    # Table name: ai.documents\n    vector_db=PgVector(\n        table_name=\"documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\ndocuments\tList[Document]\t-\tList of documents to load into the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nreader\tReader\t-\tA Reader that converts the content of the documents into Documents for the vector database.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDocx\nJSON\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Docx Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/docx",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nDocx Knowledge Base\n\nThe DocxKnowledgeBase reads local docx files, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install textract\n\nfrom phi.knowledge.docx import DocxKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = DocxKnowledgeBase(\n    path=\"data/docs\",\n    # Table name: ai.docx_documents\n    vector_db=PgVector(\n        table_name=\"docx_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to docx files. Can point to a single docx file or a directory of docx files.\nformats\tList[str]\t[\".doc\", \".docx\"]\tFormats accepted by this knowledge base.\nreader\tDocxReader\tDocxReader()\tA DocxReader that converts the docx files into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCSV\nDocument\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "CSV Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/csv",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nCSV Knowledge Base\n\nThe CSVKnowledgeBase reads local CSV files, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\nfrom phi.knowledge.csv import CSVKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = CSVKnowledgeBase(\n    path=\"data/csv\",\n    # Table name: ai.csv_documents\n    vector_db=PgVector(\n        table_name=\"csv_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\npath\tUnion[str, Path]\t-\tPath to docx files. Can point to a single docx file or a directory of docx files.\nreader\tCSVReader\tCSVReader()\tA CSVReader that converts the CSV files into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCombined\nDocx\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Combined KnowledgeBase - Phidata",
    "url": "https://docs.phidata.com/knowledge/combined",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nCombined KnowledgeBase\n\nThe CombinedKnowledgeBase combines multiple knowledge bases into 1 and is used when your app needs information using multiple sources.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install pypdf bs4\n\nknowledge_base.py\nfrom phi.knowledge.combined import CombinedKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nurl_pdf_knowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"pdf_url\"],\n    # Table name: ai.pdf_documents\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\nwebsite_knowledge_base = WebsiteKnowledgeBase(\n    urls=[\"https://docs.phidata.com/introduction\"],\n    # Number of links to follow from the seed URLs\n    max_links=10,\n    # Table name: ai.website_documents\n    vector_db=PgVector(\n        table_name=\"website_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\nlocal_pdf_knowledge_base = PDFKnowledgeBase(\n    path=\"data/pdfs\",\n    # Table name: ai.pdf_documents\n    vector_db=PgVector(\n        table_name=\"pdf_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n    reader=PDFReader(chunk=True),\n)\n\nknowledge_base = CombinedKnowledgeBase(\n    sources=[\n        url_pdf_knowledge_base,\n        website_knowledge_base,\n        local_pdf_knowledge_base,\n    ],\n    vector_db=PgVector(\n        # Table name: ai.combined_documents\n        collection=\"combined_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nsources\tList[AgentKnowledge]\t-\tList of Agent knowledge bases.\nreader\tReader\t-\tA Reader that converts the content of the documents into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nArXiv\nCSV\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "ArXiv Knowledge Base - Phidata",
    "url": "https://docs.phidata.com/knowledge/arxiv",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nArXiv Knowledge Base\n\nThe ArxivKnowledgeBase reads Arxiv articles, converts them into vector embeddings and loads them to a vector databse.\n\n​\nUsage\n\nWe are using a local PgVector database for this example. Make sure it’s running\n\npip install arxiv\n\nknowledge_base.py\nfrom phi.knowledge.arxiv import ArxivKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\nknowledge_base = ArxivKnowledgeBase(\n    queries=[\"Generative AI\", \"Machine Learning\"],\n    # Table name: ai.arxiv_documents\n    vector_db=PgVector(\n        collection=\"arxiv_documents\",\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n    ),\n)\n\n\nThen use the knowledge_base with an Agent:\n\nagent.py\nfrom phi.agent import Agent\nfrom knowledge_base import knowledge_base\n\nagent = Agent(\n    knowledge=knowledge_base,\n    search_knowledge=True,\n)\nagent.knowledge.load(recreate=False)\n\nagent.print_response(\"Ask me about something from the knowledge base\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nqueries\tList[str]\t-\tQueries to search\nreader\tArxivReader\tArxivReader()\tA ArxivReader that reads the articles and converts them into Documents for the vector database.\nvector_db\tVectorDb\t-\tVector Database for the Knowledge Base.\nnum_documents\tint\t5\tNumber of documents to return on search.\noptimize_on\tint\t-\tNumber of documents to optimize the vector db on.\nchunking_strategy\tChunkingStrategy\tCharacterChunks\tThe chunking strategy to use.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nCombined\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Singlestore Agent Storage - Phidata",
    "url": "https://docs.phidata.com/storage/singlestore",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nIntroduction\nPostgres\nSqlite\nSinglestore\nDynamoDB\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nStorage\nSinglestore Agent Storage\n\nPhidata supports using Singlestore as a storage backend for Agents using the S2AgentStorage class.\n\n​\nUsage\n\nObtain the credentials for Singlestore from here\n\nstorage.py\nfrom phi.storage.agent.singlestore import S2AgentStorage\n\n# SingleStore Configuration\nUSERNAME = getenv(\"SINGLESTORE_USERNAME\")\nPASSWORD = getenv(\"SINGLESTORE_PASSWORD\")\nHOST = getenv(\"SINGLESTORE_HOST\")\nPORT = getenv(\"SINGLESTORE_PORT\")\nDATABASE = getenv(\"SINGLESTORE_DATABASE\")\nSSL_CERT = getenv(\"SINGLESTORE_SSL_CERT\", None)\n\n# SingleStore DB URL\ndb_url = f\"mysql+pymysql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DATABASE}?charset=utf8mb4\"\nif SSL_CERT:\n    db_url += f\"&ssl_ca={SSL_CERT}&ssl_verify_cert=true\"\n\n# Create a database engine\ndb_engine = create_engine(db_url)\n\n# Create a storage backend using the Singlestore database\nstorage = S2AgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # db_engine: Singlestore database engine\n    db_engine=db_engine,\n    # schema: Singlestore schema\n    schema=DATABASE,\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nschema\tOptional[str]\t\"ai\"\tSchema name.\ndb_url\tOptional[str]\tNone\tDatabase URL, if provided.\ndb_engine\tOptional[Engine]\tNone\tDatabase engine to be used.\nschema_version\tint\t1\tVersion of the schema.\nauto_upgrade_schema\tbool\tFalse\tIf true, automatically upgrades the schema when necessary.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSqlite\nDynamoDB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Sqlite Agent Storage - Phidata",
    "url": "https://docs.phidata.com/storage/sqlite",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nIntroduction\nPostgres\nSqlite\nSinglestore\nDynamoDB\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nStorage\nSqlite Agent Storage\n\nPhidata supports using Sqlite as a storage backend for Agents using the SqlAgentStorage class.\n\n​\nUsage\n\nYou need to provide either db_url, db_file or db_engine. The following example uses db_file.\n\nstorage.py\nfrom phi.storage.agent.sqlite import SqlAgentStorage\n\n# Create a storage backend using the Sqlite database\nstorage = SqlAgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # db_file: Sqlite database file\n    db_file=\"tmp/data.db\",\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nschema\tOptional[str]\t\"ai\"\tSchema name, default is \"ai\".\ndb_url\tOptional[str]\tNone\tDatabase URL, if provided.\ndb_engine\tOptional[Engine]\tNone\tDatabase engine to be used.\nschema_version\tint\t1\tVersion of the schema, default is 1.\nauto_upgrade_schema\tbool\tFalse\tIf true, automatically upgrades the schema when necessary.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPostgres\nSinglestore\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Postgres Agent Storage - Phidata",
    "url": "https://docs.phidata.com/storage/postgres",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nIntroduction\nPostgres\nSqlite\nSinglestore\nDynamoDB\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nStorage\nPostgres Agent Storage\n\nPhidata supports using PostgreSQL as a storage backend for Agents using the PgAgentStorage class.\n\n​\nUsage\n​\nRun PgVector\n\nInstall docker desktop and run PgVector on port 5532 using:\n\ndocker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\nstorage.py\nfrom phi.storage.agent.postgres import PgAgentStorage\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\n# Create a storage backend using the Postgres database\nstorage = PgAgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # db_url: Postgres database URL\n    db_url=db_url,\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nschema\tOptional[str]\t\"ai\"\tSchema name, default is \"ai\".\ndb_url\tOptional[str]\tNone\tDatabase URL, if provided.\ndb_engine\tOptional[Engine]\tNone\tDatabase engine to be used.\nschema_version\tint\t1\tVersion of the schema, default is 1.\nauto_upgrade_schema\tbool\tFalse\tIf true, automatically upgrades the schema when necessary.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nSqlite\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nRun PgVector\nParams"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/storage/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nIntroduction\nPostgres\nSqlite\nSinglestore\nDynamoDB\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nStorage\nIntroduction\n\nAgents come with built-in memory but it only lasts while the session is active. To continue conversations across sessions, we store Agent sessions in a database like PostgreSQL.\n\nStorage is a necessary component when building user facing AI products as any production application will require users to be able to “continue” their conversation with the Agent.\n\nThe general syntax for adding storage to an Agent looks like:\n\nstorage.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.storage.agent.postgres import PgAgentStorage\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    storage=PgAgentStorage(table_name=\"agent_sessions\", db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\"),\n    tools=[DuckDuckGo()],\n    show_tool_calls=True,\n    add_history_to_messages=True,\n)\nagent.print_response(\"How many people live in Canada?\")\nagent.print_response(\"What is their national anthem called?\")\nagent.print_response(\"Which country are we speaking about?\")\n\n\nThe following databases are supported as a storage backend:\n\nPostgreSQL\nSqlite\nSingleStore\nDynamoDB\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSingleStore\nPostgres\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "DynamoDB Agent Storage - Phidata",
    "url": "https://docs.phidata.com/reference/storage/dynamodb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nPostgreSQL\nSqlite\nSingle Store\nDynamoDB\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nStorage\nDynamoDB Agent Storage\n​\nExample\nstorage.py\nfrom phi.storage.agent.dynamodb import DynamoDbAgentStorage\n\n# Create a storage backend using the DynamoDB database\nstorage = DynamoDbAgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # region_name: AWS region name\n    region_name=\"us-east-1\",\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nregion_name\tOptional[str]\tNone\tRegion name of the DynamoDB table.\naws_access_key_id\tOptional[str]\tNone\tAWS access key id, if provided.\naws_secret_access_key\tOptional[str]\tNone\tAWS secret access key, if provided.\nendpoint_url\tOptional[str]\tNone\tEndpoint URL, if provided.\ncreate_table_if_not_exists\tbool\tTrue\tIf true, creates the table if it does not exist.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSingle Store\nBase\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nParams"
  },
  {
    "title": "Single Store Agent Storage - Phidata",
    "url": "https://docs.phidata.com/reference/storage/singlestore",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nPostgreSQL\nSqlite\nSingle Store\nDynamoDB\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nStorage\nSingle Store Agent Storage\n​\nExample\nstorage.py\nfrom phi.storage.agent.singlestore import S2AgentStorage\n\n# Create a storage backend using the SingleStore database\nstorage = S2AgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # db_engine: SingleStore database engine\n    db_engine=db_engine,\n    # schema: SingleStore schema\n    schema=\"ai\",\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nschema\tOptional[str]\t\"ai\"\tSchema name.\ndb_url\tOptional[str]\tNone\tDatabase URL, if provided.\ndb_engine\tOptional[Engine]\tNone\tDatabase engine to be used.\nschema_version\tint\t1\tVersion of the schema.\nauto_upgrade_schema\tbool\tFalse\tIf true, automatically upgrades the schema when necessary.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSqlite\nDynamoDB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nParams"
  },
  {
    "title": "Sqlite Agent Storage - Phidata",
    "url": "https://docs.phidata.com/reference/storage/sqlite",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nPostgreSQL\nSqlite\nSingle Store\nDynamoDB\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nStorage\nSqlite Agent Storage\n​\nExample\nstorage.py\nfrom phi.storage.agent.sqlite import SqlAgentStorage\n\n# Create a storage backend using the Sqlite database\nstorage = SqlAgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # db_file: Sqlite database file\n    db_file=db_file,\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nschema\tOptional[str]\t\"ai\"\tSchema name, default is \"ai\".\ndb_url\tOptional[str]\tNone\tDatabase URL, if provided.\ndb_engine\tOptional[Engine]\tNone\tDatabase engine to be used.\nschema_version\tint\t1\tVersion of the schema, default is 1.\nauto_upgrade_schema\tbool\tFalse\tIf true, automatically upgrades the schema when necessary.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPostgreSQL\nSingle Store\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nParams"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/knowledge/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nIntroduction\nArXiv\nCombined\nCSV\nDocx\nDocument\nJSON\nLangChain\nLlamaIndex\nPDF\nPDF Urls\nS3 PDF\nS3 Text\nText\nWebsite\nWikipedia\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nKnowledge\nIntroduction\n\nA knowledge base is a database of information that an agent can search to improve its responses. This information is stored in a vector database and provides agents with business context, helping them respond in a context-aware manner. The general syntax is:\n\nfrom phi.agent import Agent, AgentKnowledge\n\n# Create a knowledge base for the Agent\nknowledge_base = AgentKnowledge(vector_db=...)\n\n# Add information to the knowledge base\nknowledge_base.load_text(\"The sky is blue\")\n\n# Add the knowledge base to the Agent and\n# give it a tool to search the knowledge base as needed\nagent = Agent(knowledge=knowledge_base, search_knowledge=True)\n\n​\nVector Databases\n\nWhile any type of storage can act as a knowledge base, vector databases offer the best solution for retrieving relevant results from dense information quickly. Here’s how vector databases are used with Agents:\n\n1\n\nChunk the information\n\nBreak down the knowledge into smaller chunks to ensure our search query returns only relevant results.\n\n2\n\nLoad the knowledge base\n\nConvert the chunks into embedding vectors and store them in a vector database.\n\n3\n\nSearch the knowledge base\n\nWhen the user sends a message, we convert the input message into an embedding and “search” for nearest neighbors in the vector database.\n\n​\nLoading the Knowledge Base\n\nBefore you can use a knowledge base, it needs to be loaded with embeddings that will be used for retrieval. Use one of the following knowledge bases to simplify the chunking, loading, searching and optimization process:\n\nArXiv knowledge base: Load ArXiv papers to a knowledge base\nCombined knowledge base: Combine multiple knowledge bases into 1\nCSV knowledge base: Load CSV files to a knowledge base\nDocument knowledge base: Load local docx files to a knowledge base\nJSON knowledge base: Load JSON files to a knowledge base\nLangChain knowledge base: Use a Langchain retriever as a knowledge base\nPDF knowledge base: Load local PDF files to a knowledge base\nPDF URL knowledge base: Load PDF files from a URL to a knowledge base\nS3 PDF knowledge base: Load PDF files from S3 to a knowledge base\nS3 Text knowledge base: Load text files from S3 to a knowledge base\nText knowledge base: Load text/docx files to a knowledge base\nWebsite knowledge base: Load website data to a knowledge base\nWikipedia knowledge base: Load wikipedia articles to a knowledge base\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nZoom\nArXiv\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nVector Databases\nLoading the Knowledge Base"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  },
  {
    "title": "DynamoDB Agent Storage - Phidata",
    "url": "https://docs.phidata.com/storage/dynamodb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nIntroduction\nPostgres\nSqlite\nSinglestore\nDynamoDB\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nStorage\nDynamoDB Agent Storage\n\nPhidata supports using DynamoDB as a storage backend for Agents using the DynamoDbAgentStorage class.\n\n​\nUsage\n\nYou need to provide aws_access_key_id and aws_secret_access_key parameters to the DynamoDbAgentStorage class.\n\nstorage.py\nfrom phi.storage.agent.dynamodb import DynamoDbAgentStorage\n\n# AWS Credentials\nAWS_ACCESS_KEY_ID = getenv(\"AWS_ACCESS_KEY_ID\")\nAWS_SECRET_ACCESS_KEY = getenv(\"AWS_SECRET_ACCESS_KEY\")\n\nstorage = DynamoDbAgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # region_name: DynamoDB region name\n    region_name=\"us-east-1\",\n    # aws_access_key_id: AWS access key id\n    aws_access_key_id=AWS_ACCESS_KEY_ID,\n    # aws_secret_access_key: AWS secret access key\n    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nregion_name\tOptional[str]\tNone\tRegion name of the DynamoDB table.\naws_access_key_id\tOptional[str]\tNone\tAWS access key id, if provided.\naws_secret_access_key\tOptional[str]\tNone\tAWS secret access key, if provided.\nendpoint_url\tOptional[str]\tNone\tEndpoint URL, if provided.\ncreate_table_if_not_exists\tbool\tTrue\tIf true, creates the table if it does not exist.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSinglestore\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "PostgreSQL Agent Storage - Phidata",
    "url": "https://docs.phidata.com/reference/storage/postgres",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nPostgreSQL\nSqlite\nSingle Store\nDynamoDB\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nStorage\nPostgreSQL Agent Storage\n​\nExample\nstorage.py\nfrom phi.storage.agent.postgres import PgAgentStorage\n\n# Create a storage backend using the Postgres database\nstorage = PgAgentStorage(\n    # store sessions in the ai.sessions table\n    table_name=\"agent_sessions\",\n    # db_url: Postgres database URL\n    db_url=db_url,\n)\n\n# Add storage to the Agent\nagent = Agent(storage=storage)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ntable_name\tstr\t-\tName of the table to be used.\nschema\tOptional[str]\t\"ai\"\tSchema name, default is \"ai\".\ndb_url\tOptional[str]\tNone\tDatabase URL, if provided.\ndb_engine\tOptional[Engine]\tNone\tDatabase engine to be used.\nschema_version\tint\t1\tVersion of the schema, default is 1.\nauto_upgrade_schema\tbool\tFalse\tIf true, automatically upgrades the schema when necessary.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSambanova\nSqlite\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nParams"
  },
  {
    "title": "Nvidia - Phidata",
    "url": "https://docs.phidata.com/models/nvidia",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nNvidia\n​\nAuthentication\n\nSet your NVIDIA_API_KEY environment variable. Get your key from Nvidia here.\n\nMac\nWindows\nexport NVIDIA_API_KEY=***\n\n​\nExample\n\nUse Nvidia with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.nvidia import Nvidia\n\nagent = Agent(model=Nvidia(), markdown=True)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"nvidia/llama-3.1-nemotron-70b-instruct\"\tThe specific model ID used for generating responses.\nname\tstr\t\"Nvidia\"\tThe name identifier for the Nvidia agent.\nprovider\tstr\t-\tThe provider of the model, combining “Nvidia” with the model ID.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the Nvidia service. Retrieved from the environment variable NVIDIA_API_KEY.\nbase_url\tstr\t\"https://integrate.api.nvidia.com/v1\"\tThe base URL for making API requests to the Nvidia service.\n\nNvidia also supports all the params of OpenAI.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenRouter\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "OpenRouter - Phidata",
    "url": "https://docs.phidata.com/models/openrouter",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nOpenRouter\n\nOpenRouter is a platform for providing endpoints for Large Language models.\n\n​\nAuthentication\n\nSet your OPENROUTER_API_KEY environment variable. Get your key from here.\n\nMac\nWindows\nexport OPENROUTER_API_KEY=***\n\n​\nExample\n\nUse OpenRouter with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openrouter import OpenRouter\n\nagent = Agent(\n    model=OpenRouter(id=\"gpt-4o\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"gpt-4o\"\tThe specific model ID used for generating responses.\nname\tstr\t\"OpenRouter\"\tThe name identifier for the OpenRouter agent.\nprovider\tstr\t-\tThe provider of the model, combining “OpenRouter” with the model ID.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the OpenRouter service. Retrieved from the environment variable OPENROUTER_API_KEY.\nbase_url\tstr\t\"https://openrouter.ai/api/v1\"\tThe base URL for making API requests to the OpenRouter service.\nmax_tokens\tint\t1024\tThe maximum number of tokens to generate in the response.\n\nOpenRouter also supports all the params of OpenAI.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nHuggingFace\nNvidia\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "HuggingFace - Phidata",
    "url": "https://docs.phidata.com/models/huggingface",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nHuggingFace\n​\nAuthentication\n\nSet your HF_TOKEN environment. You can get one from HuggingFace here.\n\nMac\nWindows\nexport HF_TOKEN=***\n\n​\nExample\n\nUse HuggingFace with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.huggingface import HuggingFaceChat\n\nagent = Agent(\n    model=HuggingFaceChat(\n        id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n        max_tokens=4096,\n    ),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"meta-llama/Meta-Llama-3-8B-Instruct\"\tThe id of the HuggingFace model to use.\nname\tstr\t\"HuggingFaceChat\"\tThe name of this chat model instance.\nprovider\tstr\t\"HuggingFace\"\tThe provider of the model.\nstore\tOptional[bool]\t-\tWhether or not to store the output of this chat completion request.\nfrequency_penalty\tOptional[float]\t-\tPenalizes new tokens based on their frequency in the text so far.\nlogit_bias\tOptional[Any]\t-\tModifies the likelihood of specified tokens appearing in the completion.\nlogprobs\tOptional[bool]\t-\tInclude the log probabilities on the logprobs most likely tokens.\nmax_tokens\tOptional[int]\t-\tThe maximum number of tokens to generate in the chat completion.\npresence_penalty\tOptional[float]\t-\tPenalizes new tokens based on whether they appear in the text so far.\nresponse_format\tOptional[Any]\t-\tAn object specifying the format that the model must output.\nseed\tOptional[int]\t-\tA seed for deterministic sampling.\nstop\tOptional[Union[str, List[str]]]\t-\tUp to 4 sequences where the API will stop generating further tokens.\ntemperature\tOptional[float]\t-\tControls randomness in the model’s output.\ntop_logprobs\tOptional[int]\t-\tHow many log probability results to return per token.\ntop_p\tOptional[float]\t-\tControls diversity via nucleus sampling.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the request.\napi_key\tOptional[str]\t-\tThe Access Token for authenticating with HuggingFace.\nbase_url\tOptional[Union[str, httpx.URL]]\t-\tThe base URL for API requests.\ntimeout\tOptional[float]\t-\tThe timeout for API requests.\nmax_retries\tOptional[int]\t-\tThe maximum number of retries for failed requests.\ndefault_headers\tOptional[Any]\t-\tDefault headers to include in all requests.\ndefault_query\tOptional[Any]\t-\tDefault query parameters to include in all requests.\nhttp_client\tOptional[httpx.Client]\t-\tAn optional pre-configured HTTP client.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for client configuration.\nclient\tOptional[InferenceClient]\t-\tThe HuggingFace Hub Inference client instance.\nasync_client\tOptional[AsyncInferenceClient]\t-\tThe asynchronous HuggingFace Hub client instance.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAzure\nOpenRouter\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Azure - Phidata",
    "url": "https://docs.phidata.com/models/azure",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nAzure\n\nUse the best in class GPT models using Azure’s OpenAI API.\n\n​\nAuthentication\n\nSet your environment variables.\n\nMac\nWindows\nexport AZURE_OPENAI_API_KEY=***\nexport AZURE_OPENAI_ENDPOINT=***\nexport AZURE_OPENAI_MODEL_NAME=***\nexport AZURE_OPENAI_DEPLOYMENT=***\n# Optional:\n# export AZURE_OPENAI_API_VERSION=***\n\n​\nExample\n\nUse AzureOpenAIChat with your Agent:\n\nagent.py\nimport os\nfrom typing import Iterator\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.azure import AzureOpenAIChat\n\nazure_model = AzureOpenAIChat(\n    id=os.getenv(\"AZURE_OPENAI_MODEL_NAME\"),\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n)\n\nagent = Agent(\n    model=azure_model,\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tThe specific model ID used for generating responses. This field is required.\nname\tstr\t\"AzureOpenAIChat\"\tThe name identifier for the agent.\nprovider\tstr\t\"Azure\"\tThe provider of the model.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the Azure OpenAI service.\napi_version\tstr\t\"2024-02-01\"\tThe version of the Azure OpenAI API to use.\nazure_endpoint\tOptional[str]\t-\tThe endpoint URL for the Azure OpenAI service.\nazure_deployment\tOptional[str]\t-\tThe deployment name or ID in Azure.\nbase_url\tOptional[str]\t-\tThe base URL for making API requests to the Azure OpenAI service.\nazure_ad_token\tOptional[str]\t-\tThe Azure Active Directory token for authenticating requests.\nazure_ad_token_provider\tOptional[Any]\t-\tThe provider for obtaining Azure Active Directory tokens.\norganization\tOptional[str]\t-\tThe organization associated with the API requests.\nopenai_client\tOptional[AzureOpenAIClient]\t-\tAn instance of AzureOpenAIClient provided for making API requests.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nxAI\nHuggingFace\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Mistral - Phidata",
    "url": "https://docs.phidata.com/models/mistral",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nMistral\n\nMistral is a platform for providing endpoints for Large Language models.\n\n​\nAuthentication\n\nSet your MISTRAL_API_KEY environment variable. Get your key from here.\n\nMac\nWindows\nexport MISTRAL_API_KEY=***\n\n​\nExample\n\nUse Mistral with your Agent:\n\nagent.py\nimport os\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.mistral import MistralChat\n\nmistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n\nagent = Agent(\n    model=MistralChat(\n        id=\"mistral-large-latest\",\n        api_key=mistral_api_key,\n    ),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"mistral-large-latest\"\tThe specific model ID used for generating responses.\nname\tstr\t\"MistralChat\"\tThe name identifier for the agent.\nprovider\tstr\t\"Mistral\"\tThe provider of the model.\ntemperature\tOptional[float]\t-\tThe sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\nmax_tokens\tOptional[int]\t-\tThe maximum number of tokens to generate in the response.\ntop_p\tOptional[float]\t-\tThe nucleus sampling parameter. The model considers the results of the tokens with top_p probability mass.\nrandom_seed\tOptional[int]\t-\tThe seed for random number generation to ensure reproducibility of results.\nsafe_mode\tbool\tFalse\tEnable safe mode to filter potentially harmful or inappropriate content.\nsafe_prompt\tbool\tFalse\tEnable safe prompt mode to filter potentially harmful or inappropriate prompts.\nresponse_format\tOptional[Union[Dict[str, Any], ChatCompletionResponse]]\t-\tThe format of the response, either as a dictionary or as a ChatCompletionResponse object.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the request.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the service.\nendpoint\tOptional[str]\t-\tThe API endpoint URL for making requests to the service.\nmax_retries\tOptional[int]\t-\tThe maximum number of retry attempts for failed requests.\ntimeout\tOptional[int]\t-\tThe timeout duration for requests, specified in seconds.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for client configuration.\nmistral_client\tOptional[Mistral]\t-\tAn instance of Mistral client provided for making API requests.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFireworks\nGemini - AI Studio\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Gemini - AI Studio - Phidata",
    "url": "https://docs.phidata.com/models/google_ai_studio",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nGemini - AI Studio\n\nUse Google’s AI Studio to access the Gemini and Gemma models.\n\n​\nAuthentication\n\nSet your GOOGLE_API_KEY environment variable. You can get one from Google here.\n\nMac\nWindows\nexport GOOGLE_API_KEY=***\n\n​\nExample\n\nUse Gemini with your Agent:\n\nagent.py\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.google import Gemini\n\nagent = Agent(\n    model=Gemini(id=\"gemini-1.5-flash\"),\n    markdown=True,\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"gemini-1.5-flash\"\tThe specific model ID used for generating responses.\nname\tstr\t\"Gemini\"\tThe name identifier for the agent.\nprovider\tstr\t\"Google\"\tThe provider of the model.\nfunction_declarations\tOptional[List[FunctionDeclaration]]\t-\tA list of function declarations that the model can utilize during the response generation process.\ngeneration_config\tOptional[Any]\t-\tConfiguration settings for the generation process, such as parameters for controlling output behavior.\nsafety_settings\tOptional[Any]\t-\tSettings related to safety measures, ensuring the generation of appropriate and safe content.\ngenerative_model_kwargs\tOptional[Dict[str, Any]]\t-\tAdditional keyword arguments for the generative model.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the Google AI Studio service.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for client configuration.\nclient\tOptional[GenerativeModel]\t-\tA pre-configured instance of the Gemini client.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nMistral\nxAI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Fireworks - Phidata",
    "url": "https://docs.phidata.com/models/fireworks",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nFireworks\n\nFireworks is a platform for providing endpoints for Large Language models.\n\n​\nAuthentication\n\nSet your FIREWORKS_API_KEY environment variable. Get your key from here.\n\nMac\nWindows\nexport FIREWORKS_API_KEY=***\n\n​\nExample\n\nUse Fireworks with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.fireworks import Fireworks\n\nagent = Agent(\n    model=Fireworks(id=\"accounts/fireworks/models/firefunction-v2\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"accounts/fireworks/models/firefunction-v2\"\tThe specific model ID used for generating responses.\nname\tstr\t\"Fireworks: {id}\"\tThe name identifier for the agent. Defaults to “Fireworks: ” followed by the model ID.\nprovider\tstr\t\"Fireworks\"\tThe provider of the model.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the service. Retrieved from the environment variable FIREWORKS_API_KEY.\nbase_url\tstr\t\"https://api.fireworks.ai/inference/v1\"\tThe base URL for making API requests to the Fireworks service.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTogether\nMistral\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "xAI - Phidata",
    "url": "https://docs.phidata.com/models/xai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nxAI\n\nxAI is a platform for providing endpoints for Large Language models.\n\n​\nAuthentication\n\nSet your XAI_API_KEY environment variable. You can get one from xAI here.\n\nMac\nWindows\nexport XAI_API_KEY=sk-***\n\n​\nExample\n\nUse xAI with your Agent:\n\nagent.py\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.xai import xAI\n\nagent = Agent(\n    model=xAI(id=\"grok-beta\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\n\nFor more information, please refer to the xAI docs as well.\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"grok-beta\"\tThe specific model ID used for generating responses.\nname\tstr\t\"xAI\"\tThe name identifier for the xAI agent.\nprovider\tstr\t\"xAI\"\tThe provider of the model, combining “xAI” with the model ID.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the xAI service. Retrieved from the environment variable XAI_API_KEY.\nbase_url\tstr\t\"https://api.xai.xyz/v1\"\tThe base URL for making API requests to the xAI service.\n\nxAI also supports all the params of OpenAI.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGemini - AI Studio\nAzure\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams\nParams"
  },
  {
    "title": "Together - Phidata",
    "url": "https://docs.phidata.com/models/together",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nTogether\n\nTogether is a platform for providing endpoints for Large Language models.\n\n​\nAuthentication\n\nSet your TOGETHER_API_KEY environment variable. Get your key from Together here.\n\nMac\nWindows\nexport TOGETHER_API_KEY=***\n\n​\nExample\n\nUse Together with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.together import Together\n\nagent = Agent(\n    model=Together(id=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\tThe specific model ID used for generating responses.\nname\tstr\t\"Together\"\tThe name identifier for the Together agent.\nprovider\tstr\t-\tThe provider of the model, combining “Together” with the model ID.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the Together service. Retrieved from the environment variable TOGETHER_API_KEY.\nbase_url\tstr\t\"https://api.together.xyz/v1\"\tThe base URL for making API requests to the Together service.\nmonkey_patch\tbool\tFalse\tWhether to apply monkey patching.\n\nTogether also supports all the params of OpenAI.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAWS Bedrock Claude\nFireworks\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "AWS Bedrock Claude - Phidata",
    "url": "https://docs.phidata.com/models/aws-bedrock",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nAWS Bedrock Claude\n\nUse AWS Bedrock to access the Claude models.\n\n​\nAuthentication\n\nSet your AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_DEFAULT_REGION environment variables. Get your keys from here.\n\nMac\nWindows\nexport AWS_ACCESS_KEY_ID=***\nexport AWS_SECRET_ACCESS_KEY=***\nexport AWS_DEFAULT_REGION=***\n\n​\nExample\n\nUse AWS BedrockClaude with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.aws.claude import Claude\n\nagent = Agent(\n    model=Claude(id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"anthropic.claude-3-sonnet-20240229-v1:0\"\tThe specific model ID used for generating responses.\nname\tstr\t\"AwsBedrockAnthropicClaude\"\tThe name identifier for the Claude agent.\nprovider\tstr\t\"AwsBedrock\"\tThe provider of the model.\nmax_tokens\tint\t4096\tThe maximum number of tokens to generate in the response.\ntemperature\tOptional[float]\t-\tThe sampling temperature to use, between 0 and 2. Higher values like 0.8 make the output more random, while lower values like 0.2 make it more focused and deterministic.\ntop_p\tOptional[float]\t-\tThe nucleus sampling parameter. The model considers the results of the tokens with top_p probability mass.\ntop_k\tOptional[int]\t-\tThe number of highest probability vocabulary tokens to keep for top-k-filtering.\nstop_sequences\tOptional[List[str]]\t-\tA list of sequences where the API will stop generating further tokens.\nanthropic_version\tstr\t\"bedrock-2023-05-31\"\tThe version of the Anthropic API to use.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for the request, provided as a dictionary.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional client parameters for initializing the AwsBedrock client, provided as a dictionary.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSambanova\nTogether\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Sambanova - Phidata",
    "url": "https://docs.phidata.com/models/sambanova",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nSambanova\n\nSambanova is a platform for providing endpoints for Large Language models. Note that Sambanova currently does not support function calling.\n\n​\nAuthentication\n\nSet your SAMBANOVA_API_KEY environment variable. Get your key from here.\n\nMac\nWindows\nexport SAMBANOVA_API_KEY=***\n\n​\nExample\n\nUse Sambanova with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.sambanova import Sambanova\n\nagent = Agent(model=Sambanova(), markdown=True)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"Meta-Llama-3.1-8B-Instruct\"\tThe specific model ID used for generating responses.\nname\tstr\t\"Sambanova\"\tThe name identifier for the Sambanova model.\nprovider\tstr\t\"Sambanova\"\tThe provider of the model.\napi_key\tOptional[str]\t-\tThe API key used for authenticating requests to the Sambanova service. Retrieved from the environment variable SAMBANOVA_API_KEY.\nbase_url\tstr\t\"https://api.sambanova.ai/v1\"\tThe base URL for making API requests to the Sambanova service.\n\nSambanova also supports all the params of OpenAI.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDeepSeek\nAWS Bedrock Claude\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "DeepSeek - Phidata",
    "url": "https://docs.phidata.com/models/deepseek",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nDeepSeek\n\nDeepSeek is a platform for providing endpoints for Large Language models.\n\n​\nAuthentication\n\nSet your DEEPSEEK_API_KEY environment variable. Get your key from here.\n\nMac\nWindows\nexport DEEPSEEK_API_KEY=***\n\n​\nExample\n\nUse DeepSeek with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.deepseek import DeepSeekChat\n\nagent = Agent(model=DeepSeekChat(), markdown=True)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"deepseek-chat\"\tThe specific model ID used for generating responses.\nname\tstr\t\"DeepSeekChat\"\tThe name identifier for the DeepSeek model.\nprovider\tstr\t\"DeepSeek\"\tThe provider of the model.\napi_key\tOptional[str]\t-\tThe API key used for authenticating requests to the DeepSeek service. Retrieved from the environment variable DEEPSEEK_API_KEY.\nbase_url\tstr\t\"https://api.deepseek.com\"\tThe base URL for making API requests to the DeepSeek service.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenAI Like\nSambanova\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "OpenAI Like - Phidata",
    "url": "https://docs.phidata.com/models/openai-like",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nOpenAI Like\n\nMany providers like Together, Groq, Sambanova, etc support the OpenAI API format. Use the OpenAILike model to access them by replacing the base_url.\n\n​\nExample\nagent.py\nfrom os import getenv\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openai.like import OpenAILike\n\nagent = Agent(\n    model=OpenAILike(\n        id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n        api_key=getenv(\"TOGETHER_API_KEY\"),\n        base_url=\"https://api.together.xyz/v1\",\n    )\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tThe name of the model to be used for generating responses.\napi_key\tstr\t-\tThe API key for authenticating requests to the service.\nbase_url\tstr\t-\tThe base URL for making API requests to the service.\n\nOpenAILike also support all the params of OpenAIChat\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGroq\nDeepSeek\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nParams"
  },
  {
    "title": "Groq - Phidata",
    "url": "https://docs.phidata.com/models/groq",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nGroq\n\nGroq offers blazing-fast API endpoints for large language models\n\n​\nAuthentication\n\nSet your GROQ_API_KEY environment variable. Get your key from here.\n\nMac\nWindows\nexport GROQ_API_KEY=***\n\n​\nExample\n\nUse Groq with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.groq import Groq\n\nagent = Agent(\n    model=Groq(id=\"llama3-groq-70b-8192-tool-use-preview\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"llama3-groq-70b-8192-tool-use-preview\"\tThe specific model ID used for generating responses.\nname\tstr\t\"Groq\"\tThe name identifier for the agent.\nprovider\tstr\t\"Groq\"\tThe provider of the model.\nfrequency_penalty\tOptional[float]\t-\tA number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.\nlogit_bias\tOptional[Any]\t-\tA JSON object that modifies the likelihood of specified tokens appearing in the completion by mapping token IDs to bias values between -100 and 100.\nlogprobs\tOptional[bool]\t-\tWhether to return log probabilities of the output tokens.\nmax_tokens\tOptional[int]\t-\tThe maximum number of tokens to generate in the chat completion.\npresence_penalty\tOptional[float]\t-\tA number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics.\nresponse_format\tOptional[Dict[str, Any]]\t-\tSpecifies the format that the model must output. Setting to { \"type\": \"json_object\" } enables JSON mode, ensuring the message generated is valid JSON.\nseed\tOptional[int]\t-\tA seed value for deterministic sampling, ensuring repeated requests with the same seed and parameters return the same result.\nstop\tOptional[Union[str, List[str]]]\t-\tUp to 4 sequences where the API will stop generating further tokens.\ntemperature\tOptional[float]\t-\tThe sampling temperature to use, between 0 and 2. Higher values like 0.8 make the output more random, while lower values like 0.2 make it more focused and deterministic.\ntop_logprobs\tOptional[int]\t-\tThe number of top log probabilities to return for each generated token.\ntop_p\tOptional[float]\t-\tNucleus sampling parameter. The model considers the results of the tokens with top_p probability mass.\nuser\tOptional[str]\t-\tA unique identifier representing your end-user, helping to monitor and detect abuse.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the request.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the service.\nbase_url\tOptional[Union[str, httpx.URL]]\t-\tThe base URL for making API requests to the service.\ntimeout\tOptional[int]\t-\tThe timeout duration for requests, specified in seconds.\nmax_retries\tOptional[int]\t-\tThe maximum number of retry attempts for failed requests.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for client configuration.\ngroq_client\tOptional[GroqClient]\t-\tAn instance of GroqClient provided for making API requests.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOllama\nOpenAI Like\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Ollama - Phidata",
    "url": "https://docs.phidata.com/models/ollama",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nOllama\n\nRun Large Language Models locally with Ollama\n\nOllama is a fantastic tool for running models locally. Install ollama and run a model using\n\nrun model\nserve\nollama run llama3.1\n\n\nAfter you have the local model running, use the Ollama model to access them\n\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.ollama import Ollama\n\nagent = Agent(\n    model=Ollama(id=\"llama3.1\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"llama3.2\"\tThe name of the model to be used.\nname\tstr\t\"Ollama\"\tThe name identifier for the agent.\nprovider\tstr\t\"Ollama {id}\"\tThe provider of the model, combining “Ollama” with the model ID.\nformat\tOptional[str]\t-\tThe response format, either None for default or a specific format like “json”.\noptions\tOptional[Any]\t-\tAdditional options to include with the request, e.g., temperature or stop sequences.\nkeep_alive\tOptional[Union[float, str]]\t-\tThe keep-alive duration for maintaining persistent connections, specified in seconds or as a string.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the request.\nhost\tOptional[str]\t-\tThe host URL for making API requests to the Ollama service.\ntimeout\tOptional[Any]\t-\tThe timeout duration for requests, can be specified in seconds.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for client configuration.\nclient\tOptional[OllamaClient]\t-\tAn instance of OllamaClient provided for making API requests.\nasync_client\tOptional[AsyncOllamaClient]\t-\tAn instance of AsyncOllamaClient for making asynchronous API requests.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCohere\nGroq\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nParams"
  },
  {
    "title": "Cohere - Phidata",
    "url": "https://docs.phidata.com/models/cohere",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nCohere\n\nLeverage Cohere’s powerful command models and more.\n\n​\nAuthentication\n\nSet your CO_API_KEY environment variable. Get your key from here.\n\nMac\nWindows\nexport CO_API_KEY=***\n\n​\nExample\n\nUse CohereChat with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.cohere import CohereChat\n\nagent = Agent(\n    model=CohereChat(id=\"command-r-08-2024\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"command-r-08-2024\"\tThe specific model ID used for generating responses.\nname\tstr\t\"CohereChat\"\tThe name identifier for the agent.\nprovider\tstr\t\"Cohere\"\tThe provider of the model.\ntemperature\tOptional[float]\t-\tThe sampling temperature to use, between 0 and 2. Higher values like 0.8 make the output more random, while lower values like 0.2 make it more focused and deterministic.\nmax_tokens\tOptional[int]\t-\tThe maximum number of tokens to generate in the response.\ntop_k\tOptional[int]\t-\tThe number of highest probability vocabulary tokens to keep for top-k-filtering.\ntop_p\tOptional[float]\t-\tNucleus sampling parameter. The model considers the results of the tokens with top_p probability mass.\nfrequency_penalty\tOptional[float]\t-\tNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.\npresence_penalty\tOptional[float]\t-\tNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the request.\nadd_chat_history\tbool\tFalse\tWhether to add chat history to the Cohere messages instead of using the conversation_id.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the Cohere service.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for client configuration.\ncohere_client\tOptional[CohereClient]\t-\tA pre-configured instance of the Cohere client.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAnthropic\nOllama\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Anthropic - Phidata",
    "url": "https://docs.phidata.com/models/anthropic",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nAnthropic\n\nClaude is a family of foundational AI models by Anthropic that can be used in a variety of applications.\n\n​\nAuthentication\n\nSet your ANTHROPIC_API_KEY environment. You can get one from Anthropic here.\n\nMac\nWindows\nexport ANTHROPIC_API_KEY=***\n\n​\nExample\n\nUse Claude with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.anthropic import Claude\n\nagent = Agent(\n    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nParams\nParameter\tType\tDefault\tDescription\nid\tstr\t\"claude-3-5-sonnet-20240620\"\tThe specific model ID used for generating responses.\nname\tstr\t\"Claude\"\tThe name identifier for the agent.\nprovider\tstr\t\"Anthropic\"\tThe provider of the model.\nmax_tokens\tOptional[int]\t1024\tThe maximum number of tokens to generate in the response.\ntemperature\tOptional[float]\t-\tThe sampling temperature to use, between 0 and 2. Higher values like 0.8 make the output more random, while lower values like 0.2 make it more focused and deterministic.\nstop_sequences\tOptional[List[str]]\t-\tA list of sequences where the API will stop generating further tokens.\ntop_p\tOptional[float]\t-\tNucleus sampling parameter. The model considers the results of the tokens with top_p probability mass.\ntop_k\tOptional[int]\t-\tThe number of highest probability vocabulary tokens to keep for top-k-filtering.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the request.\napi_key\tOptional[str]\t-\tThe API key for authenticating requests to the service.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for client configuration.\nclient\tOptional[AnthropicClient]\t-\tA pre-configured instance of the Anthropic client.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenAI\nCohere\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "OpenAI - Phidata",
    "url": "https://docs.phidata.com/models/openai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nOpenAI\n\nThe GPT models are the best in class LLMs and used as the default LLM by Agents.\n\n​\nAuthentication\n\nSet your OPENAI_API_KEY environment variable. You can get one from OpenAI here.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n​\nExample\n\nUse OpenAIChat with your Agent:\n\nagent.py\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openai import OpenAIChat\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nParams\n\nFor more information, please refer to the OpenAI docs as well.\n\nParameter\tType\tDefault\tDescription\nid\tstr\t\"gpt-4o\"\tOpenAI model ID.\nname\tstr\t\"OpenAIChat\"\tName identifier for the OpenAI chat model.\nprovider\tstr\t-\tProvider of the model, combining “OpenAI” with the model ID.\nstore\tOptional[bool]\t-\tIf set, determines whether to store the conversation.\nfrequency_penalty\tOptional[float]\t-\tNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.\nlogit_bias\tOptional[Any]\t-\tModify the likelihood of specified tokens appearing in the completion.\nlogprobs\tOptional[bool]\t-\tWhether to return log probabilities of the output tokens.\nmax_tokens\tOptional[int]\t-\tThe maximum number of tokens to generate in the chat completion.\npresence_penalty\tOptional[float]\t-\tNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics.\nresponse_format\tOptional[Any]\t-\tAn object specifying the format that the model must output. Setting to { \"type\": \"json_object\" } enables JSON mode, which guarantees the message the model generates is valid JSON.\nseed\tOptional[int]\t-\tIf specified, OpenAI system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.\nstop\tOptional[Union[str, List[str]]]\t-\tUp to 4 sequences where the API will stop generating further tokens.\ntemperature\tOptional[float]\t-\tWhat sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.\ntop_logprobs\tOptional[int]\t-\tThe number of most likely tokens to return at each token position, along with their log probabilities.\nuser\tOptional[str]\t-\tA unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.\ntop_p\tOptional[float]\t-\tAn alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass.\nextra_headers\tOptional[Any]\t-\tAdditional headers to be included in the API request.\nextra_query\tOptional[Any]\t-\tAdditional query parameters to be included in the API request.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to be included in the API request.\napi_key\tOptional[str]\t-\tOpenAI API Key for authentication.\norganization\tOptional[str]\t-\tOpenAI organization identifier.\nbase_url\tOptional[Union[str, httpx.URL]]\t-\tBase URL for the OpenAI API.\ntimeout\tOptional[float]\t-\tTimeout for API requests in seconds.\nmax_retries\tOptional[int]\t-\tMaximum number of retries for failed API requests.\ndefault_headers\tOptional[Any]\t-\tDefault headers to be included in all API requests.\ndefault_query\tOptional[Any]\t-\tDefault query parameters to be included in all API requests.\nhttp_client\tOptional[httpx.Client]\t-\tCustom HTTP client for making API requests.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for configuring the OpenAI client.\nclient\tOptional[OpenAIClient]\t-\tCustom OpenAI client instance.\nasync_client\tOptional[AsyncOpenAIClient]\t-\tCustom asynchronous OpenAI client instance.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nAnthropic\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthentication\nExample\nParams"
  },
  {
    "title": "Zoom - Phidata",
    "url": "https://docs.phidata.com/tools/zoom",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nZoom\n​\nExample\n\nThe following agent will use Zoom to schedule a new meeting.\n\ncookbook/tools/zoom_tools.py\nimport os\nimport time\nimport requests\nfrom typing import Optional\n\nfrom phi.utils.log import logger\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.zoom import ZoomTool\n\n# Get environment variables\nACCOUNT_ID = os.getenv(\"ZOOM_ACCOUNT_ID\")\nCLIENT_ID = os.getenv(\"ZOOM_CLIENT_ID\")\nCLIENT_SECRET = os.getenv(\"ZOOM_CLIENT_SECRET\")\n\n\nclass CustomZoomTool(ZoomTool):\n    def __init__(\n        self,\n        account_id: Optional[str] = None,\n        client_id: Optional[str] = None,\n        client_secret: Optional[str] = None,\n        name: str = \"zoom_tool\",\n    ):\n        super().__init__(account_id=account_id, client_id=client_id, client_secret=client_secret, name=name)\n        self.token_url = \"https://zoom.us/oauth/token\"\n        self.access_token = None\n        self.token_expires_at = 0\n\n    def get_access_token(self) -> str:\n        \"\"\"\n        Obtain or refresh the access token for Zoom API.\n        Returns:\n            A string containing the access token or an empty string if token retrieval fails.\n        \"\"\"\n        if self.access_token and time.time() < self.token_expires_at:\n            return str(self.access_token)\n\n        headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n        data = {\"grant_type\": \"account_credentials\", \"account_id\": self.account_id}\n\n        try:\n            response = requests.post(\n                self.token_url, headers=headers, data=data, auth=(self.client_id, self.client_secret)\n            )\n            response.raise_for_status()\n\n            token_info = response.json()\n            self.access_token = token_info[\"access_token\"]\n            expires_in = token_info[\"expires_in\"]\n            self.token_expires_at = time.time() + expires_in - 60\n\n            self._set_parent_token(str(self.access_token))\n            return str(self.access_token)\n        except requests.RequestException as e:\n            logger.error(f\"Error fetching access token: {e}\")\n            return \"\"\n\n    def _set_parent_token(self, token: str) -> None:\n        \"\"\"Helper method to set the token in the parent ZoomTool class\"\"\"\n        if token:\n            self._ZoomTool__access_token = token\n\n\nzoom_tools = CustomZoomTool(account_id=ACCOUNT_ID, client_id=CLIENT_ID, client_secret=CLIENT_SECRET)\n\n\nagent = Agent(\n    name=\"Zoom Meeting Manager\",\n    agent_id=\"zoom-meeting-manager\",\n    model=OpenAIChat(model=\"gpt-4\"),\n    tools=[zoom_tools],\n    markdown=True,\n    debug_mode=True,\n    show_tool_calls=True,\n    instructions=[\n        \"You are an expert at managing Zoom meetings using the Zoom API.\",\n        \"You can:\",\n        \"1. Schedule new meetings (schedule_meeting)\",\n        \"2. Get meeting details (get_meeting)\",\n        \"3. List all meetings (list_meetings)\",\n        \"4. Get upcoming meetings (get_upcoming_meetings)\",\n        \"5. Delete meetings (delete_meeting)\",\n        \"6. Get meeting recordings (get_meeting_recordings)\",\n        \"\",\n        \"For recordings, you can:\",\n        \"- Retrieve recordings for any past meeting using the meeting ID\",\n        \"- Include download tokens if needed\",\n        \"- Get recording details like duration, size, download link and file types\",\n        \"\",\n        \"Guidelines:\",\n        \"- Use ISO 8601 format for dates (e.g., '2024-12-28T10:00:00Z')\",\n        \"- Ensure meeting times are in the future\",\n        \"- Provide meeting details after scheduling (ID, URL, time)\",\n        \"- Handle errors gracefully\",\n        \"- Confirm successful operations\",\n    ],\n)\n\n\nagent.print_response(\"Schedule a meeting titled 'Team Sync' 8th december at 2 PM UTC for 45 minutes\")\nagent.print_response(\"delete a meeting titled 'Team Sync' which scheduled tomorrow at 2 PM UTC for 45 minutes\")\nagent.print_response(\"List all my scheduled meetings\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\naccount_id\tstr\tNone\tThe Zoom account ID for authentication\nclient_id\tstr\tNone\tThe client ID for authentication\nclient_secret\tstr\tNone\tThe client secret for authentication\nname\tstr\t\"zoom_tool\"\tThe name of the tool\n​\nToolkit Functions\nFunction\tDescription\nschedule_meeting\tSchedules a new Zoom meeting\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nZendesk\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Zendesk - Phidata",
    "url": "https://docs.phidata.com/tools/zendesk",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nZendesk\n\nZendeskTools enable an Agent to access Zendesk API to search for articles.\n\n​\nPrerequisites\n\nThe following example requires the requests library and auth credentials.\n\npip install -U requests\n\nexport ZENDESK_USERNAME=***\nexport ZENDESK_PW=***\nexport ZENDESK_COMPANY_NAME=***\n\n​\nExample\n\nThe following agent will run seach Zendesk for “How do I login?” and print the response.\n\ncookbook/tools/zendesk_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.zendesk import ZendeskTools\n\nagent = Agent(tools=[ZendeskTools()], show_tool_calls=True)\nagent.print_response(\"How do I login?\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nusername\tstr\t-\tThe username used for authentication or identification purposes.\npassword\tstr\t-\tThe password associated with the username for authentication purposes.\ncompany_name\tstr\t-\tThe name of the company related to the user or the data being accessed.\n​\nToolkit Functions\nFunction\tDescription\nsearch_zendesk\tThis function searches for articles in Zendesk Help Center that match the given search string.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nYoutube\nZoom\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Youtube - Phidata",
    "url": "https://docs.phidata.com/tools/youtube",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nYoutube\n\nYouTubeTools enable an Agent to access captions and metadata of YouTube videos, when provided with a video URL.\n\n​\nPrerequisites\n\nThe following example requires the youtube_transcript_api library.\n\npip install -U youtube_transcript_api\n\n​\nExample\n\nThe following agent will provide a summary of a YouTube video.\n\ncookbook/tools/youtube_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.youtube_tools import YouTubeTools\n\nagent = Agent(\n    tools=[YouTubeTools()],\n    show_tool_calls=True,\n    description=\"You are a YouTube agent. Obtain the captions of a YouTube video and answer questions.\",\n)\n\nagent.print_response(\"Summarize this video https://www.youtube.com/watch?v=Iv9dewmcFbs&t\", markdown=True)\n\n​\nToolkit Params\nParam\tType\tDefault\tDescription\nget_video_captions\tbool\tTrue\tEnables the functionality to retrieve video captions.\nget_video_data\tbool\tTrue\tEnables the functionality to retrieve video metadata and other related data.\nlanguages\tList[str]\t-\tSpecifies the list of languages for which data should be retrieved, if applicable.\n​\nToolkit Functions\nFunction\tDescription\nget_youtube_video_captions\tThis function retrieves the captions of a YouTube video.\nget_youtube_video_data\tThis function retrieves the metadata of a YouTube video.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nYfinance\nZendesk\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Yfinance - Phidata",
    "url": "https://docs.phidata.com/tools/yfinance",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nYfinance\n\nYFinanceTools enable an Agent to access stock data, financial information and more from Yahoo Finance.\n\n​\nPrerequisites\n\nThe following example requires the yfinance library.\n\npip install -U yfinance\n\n​\nExample\n\nThe following agent will provide information about the stock price and analyst recommendations for NVDA (Nvidia Corporation).\n\ncookbook/tools/yfinance_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, stock_fundamentals=True)],\n    show_tool_calls=True,\n    description=\"You are an investment analyst that researches stock prices, analyst recommendations, and stock fundamentals.\",\n    instructions=[\"Format your response using markdown and use tables to display data where possible.\"],\n)\nagent.print_response(\"Share the NVDA stock price and analyst recommendations\", markdown=True)\n\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nstock_price\tbool\tTrue\tEnables the functionality to retrieve current stock price information.\ncompany_info\tbool\tFalse\tEnables the functionality to retrieve detailed company information.\nstock_fundamentals\tbool\tFalse\tEnables the functionality to retrieve fundamental data about a stock.\nincome_statements\tbool\tFalse\tEnables the functionality to retrieve income statements of a company.\nkey_financial_ratios\tbool\tFalse\tEnables the functionality to retrieve key financial ratios for a company.\nanalyst_recommendations\tbool\tFalse\tEnables the functionality to retrieve analyst recommendations for a stock.\ncompany_news\tbool\tFalse\tEnables the functionality to retrieve the latest news related to a company.\ntechnical_indicators\tbool\tFalse\tEnables the functionality to retrieve technical indicators for stock analysis.\nhistorical_prices\tbool\tFalse\tEnables the functionality to retrieve historical price data for a stock.\n​\nToolkit Functions\nFunction\tDescription\nget_current_stock_price\tThis function retrieves the current stock price of a company.\nget_company_info\tThis function retrieves detailed information about a company.\nget_historical_stock_prices\tThis function retrieves historical stock prices for a company.\nget_stock_fundamentals\tThis function retrieves fundamental data about a stock.\nget_income_statements\tThis function retrieves income statements of a company.\nget_key_financial_ratios\tThis function retrieves key financial ratios for a company.\nget_analyst_recommendations\tThis function retrieves analyst recommendations for a stock.\nget_company_news\tThis function retrieves the latest news related to a company.\nget_technical_indicators\tThis function retrieves technical indicators for stock analysis.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWikipedia\nYoutube\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Wikipedia - Phidata",
    "url": "https://docs.phidata.com/tools/wikipedia",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nWikipedia\n\nWikipediaTools enable an Agent to search wikipedia a website and add its contents to the knowledge base.\n\n​\nPrerequisites\n\nThe following example requires the wikipedia library.\n\npip install -U wikipedia\n\n​\nExample\n\nThe following agent will run seach wikipedia for “ai” and print the response.\n\ncookbook/tools/wikipedia_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.wikipedia import WikipediaTools\n\nagent = Agent(tools=[WikipediaTools()], show_tool_calls=True)\nagent.print_response(\"Search wikipedia for 'ai'\")\n\n​\nToolkit Params\nName\tType\tDefault\tDescription\nknowledge_base\tWikipediaKnowledgeBase\t-\tThe knowledge base associated with Wikipedia, containing various data and resources linked to Wikipedia’s content.\n​\nToolkit Functions\nFunction Name\tDescription\nsearch_wikipedia_and_update_knowledge_base\tThis function searches wikipedia for a topic, adds the results to the knowledge base and returns them.\nsearch_wikipedia\tSearches Wikipedia for a query.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWebsite\nYfinance\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Website - Phidata",
    "url": "https://docs.phidata.com/tools/website",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nWebsite\n\nWebsiteTools enable an Agent to parse a website and add its contents to the knowledge base.\n\n​\nPrerequisites\n\nThe following example requires the beautifulsoup4 library.\n\npip install -U beautifulsoup4\n\n​\nExample\n\nThe following agent will read the contents of a website and add it to the knowledge base.\n\ncookbook/tools/website_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.website import WebsiteTools\n\nagent = Agent(tools=[WebsiteTools()], show_tool_calls=True)\nagent.print_response(\"Search web page: 'https://docs.phidata.com/introduction'\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nknowledge_base\tWebsiteKnowledgeBase\t-\tThe knowledge base associated with the website, containing various data and resources linked to the website’s content.\n​\nToolkit Functions\nFunction\tDescription\nadd_website_to_knowledge_base\tThis function adds a website’s content to the knowledge base. NOTE: The website must start with https:// and should be a valid website. Use this function to get information about products from the internet.\nread_url\tThis function reads a URL and returns the contents.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTwitter\nWikipedia\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Twitter - Phidata",
    "url": "https://docs.phidata.com/tools/twitter",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nTwitter\n​\nPrerequisites\n\nThe following example requires the tweepy library.\n\npip install tweepy\n\n\nGet a Twitter API key and secret from here.\n\nexport TWITTER_CONSUMER_KEY=***\nexport TWITTER_CONSUMER_SECRET=***\nexport TWITTER_ACCESS_TOKEN=***\nexport TWITTER_ACCESS_TOKEN_SECRET=***\nexport TWITTER_BEARER_TOKEN=***\n\n​\nExample\n\nThe following agent will use Twitter to get information about a user, send a message to a user, and create a new tweet.\n\ncookbook/tools/twitter_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.twitter import TwitterTools\n\n# Initialize the Twitter toolkit\ntwitter_tools = TwitterTools()\n\n# Create an agent with the twitter toolkit\nagent = Agent(\n    instructions=[\n        \"Use your tools to interact with Twitter as the authorized user @phidatahq\",\n        \"When asked to create a tweet, generate appropriate content based on the request\",\n        \"Do not actually post tweets unless explicitly instructed to do so\",\n        \"Provide informative responses about the user's timeline and tweets\",\n        \"Respect Twitter's usage policies and rate limits\",\n    ],\n    tools=[twitter_tools],\n    show_tool_calls=True,\n)\nagent.print_response(\"Can you retrieve information about this user https://x.com/phidatahq \", markdown=True)\n\n# Example usage: Reply To a Tweet\nagent.print_response(\n    \"Can you reply to this post as a general message as to how great this project is:https://x.com/phidatahq/status/1836101177500479547\",\n    markdown=True,\n)\n# Example usage: Get your details\nagent.print_response(\"Can you return my twitter profile?\", markdown=True)\n\n# Example usage: Send a direct message\nagent.print_response(\n    \"Can a send direct message to the user: https://x.com/phidatahq assking you want learn more about them and a link to their community?\",\n    markdown=True,\n)\n# Example usage: Create a new tweet\nagent.print_response(\"Create & post a tweet about the importance of AI ethics\", markdown=True)\n\n# Example usage: Get home timeline\nagent.print_response(\"Get my timeline\", markdown=True)\n\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nbearer_token\tstr\tNone\tThe bearer token for Twitter API authentication\nconsumer_key\tstr\tNone\tThe consumer key for Twitter API authentication\nconsumer_secret\tstr\tNone\tThe consumer secret for Twitter API authentication\naccess_token\tstr\tNone\tThe access token for Twitter API authentication\naccess_token_secret\tstr\tNone\tThe access token secret for Twitter API authentication\n​\nToolkit Functions\nFunction\tDescription\ncreate_tweet\tCreates and posts a new tweet\nreply_to_tweet\tReplies to an existing tweet\nsend_dm\tSends a direct message to a Twitter user\nget_user_info\tRetrieves information about a Twitter user\nget_home_timeline\tGets the authenticated user’s home timeline\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTavily\nWebsite\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Tavily - Phidata",
    "url": "https://docs.phidata.com/tools/tavily",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nTavily\n\nTavilyTools enable an Agent to search the web using the Tavily API.\n\n​\nPrerequisites\n\nThe following examples requires the tavily-python library and an API key from Tavily.\n\npip install -U tavily-python\n\nexport TAVILY_API_KEY=***\n\n​\nExample\n\nThe following agent will run a search on Tavily for “language models” and print the response.\n\ncookbook/tools/tavily_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.tavily import TavilyTools\n\nagent = Agent(tools=[TavilyTools()], show_tool_calls=True)\nagent.print_response(\"Search tavily for 'language models'\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\t-\tAPI key for authentication. If not provided, will check TAVILY_API_KEY environment variable.\nsearch\tbool\tTrue\tEnables search functionality.\nmax_tokens\tint\t6000\tMaximum number of tokens to use in search results.\ninclude_answer\tbool\tTrue\tWhether to include an AI-generated answer summary in the response.\nsearch_depth\tLiteral['basic', 'advanced']\t'advanced'\tDepth of search - ‘basic’ for faster results or ‘advanced’ for more comprehensive search.\nformat\tLiteral['json', 'markdown']\t'markdown'\tOutput format - ‘json’ for raw data or ‘markdown’ for formatted text.\nuse_search_context\tbool\tFalse\tWhether to use Tavily’s search context API instead of regular search.\n​\nToolkit Functions\nFunction\tDescription\nweb_search_using_tavily\tSearches the web for a query using Tavily API. Takes a query string and optional max_results parameter (default 5). Returns results in specified format with titles, URLs, content and relevance scores.\nweb_search_with_tavily\tAlternative search function that uses Tavily’s search context API. Takes a query string and returns contextualized search results. Only available if use_search_context is True.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSQL\nTwitter\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "SQL - Phidata",
    "url": "https://docs.phidata.com/tools/sql",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nSQL\n\nSQLTools enable an Agent to run SQL queries and interact with databases.\n\n​\nPrerequisites\n\nThe following example requires the sqlalchemy library and a database URL.\n\npip install -U sqlalchemy\n\n\nYou will also need a database. The following example uses a Postgres database running in a Docker container.\n\n docker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\n​\nExample\n\nThe following agent will run a SQL query to list all tables in the database and describe the contents of one of the tables.\n\ncookbook/tools/sql_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.sql import SQLTools\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nagent = Agent(tools=[SQLTools(db_url=db_url)])\nagent.print_response(\"List the tables in the database. Tell me about contents of one of the tables\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\ndb_url\tstr\t-\tThe URL for connecting to the database.\ndb_engine\tEngine\t-\tThe database engine used for connections and operations.\nuser\tstr\t-\tThe username for database authentication.\npassword\tstr\t-\tThe password for database authentication.\nhost\tstr\t-\tThe hostname or IP address of the database server.\nport\tint\t-\tThe port number on which the database server is listening.\nschema\tstr\t-\tThe specific schema within the database to use.\ndialect\tstr\t-\tThe SQL dialect used by the database.\ntables\tDict[str, Any]\t-\tA dictionary mapping table names to their respective metadata or structure.\nlist_tables\tbool\tTrue\tEnables the functionality to list all tables in the database.\ndescribe_table\tbool\tTrue\tEnables the functionality to describe the schema of a specific table.\nrun_sql_query\tbool\tTrue\tEnables the functionality to execute SQL queries directly.\n​\nToolkit Functions\nFunction\tDescription\nlist_tables\tLists all tables in the database.\ndescribe_table\tDescribes the schema of a specific table.\nrun_sql_query\tExecutes SQL queries directly.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSpider\nTavily\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Spider - Phidata",
    "url": "https://docs.phidata.com/tools/spider",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nSpider\n\nSpiderTools is an open source web Scraper & Crawler that returns LLM-ready data. To start using Spider, you need an API key from the Spider dashboard.\n\n​\nPrerequisites\n\nThe following example requires the spider-client library.\n\npip install -U spider-client\n\n​\nExample\n\nThe following agent will run a search query to get the latest news in USA and scrape the first search result. The agent will return the scraped data in markdown format.\n\ncookbook/tools/spider_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.spider import SpiderTools\n\nagent = Agent(tools=[SpiderTools()])\nagent.print_response('Can you scrape the first search result from a search on \"news in USA\"?', markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nmax_results\tint\t-\tThe maximum number of search results to return\nurl\tstr\t-\tThe url to be scraped or crawled\n​\nToolkit Functions\nFunction\tDescription\nsearch\tSearches the web for the given query.\nscrape\tScrapes the given url.\ncrawl\tCrawls the given url.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSleep\nSQL\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Sleep - Phidata",
    "url": "https://docs.phidata.com/tools/sleep",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nSleep\n​\nExample\n\nThe following agent will use the sleep tool to pause execution for a given number of seconds.\n\ncookbook/tools/sleep_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.sleep import Sleep\n\n# Create an Agent with the Sleep tool\nagent = Agent(tools=[Sleep()], name=\"Sleep Agent\")\n\n# Example 1: Sleep for 2 seconds\nagent.print_response(\"Sleep for 2 seconds\")\n\n# Example 2: Sleep for a longer duration\nagent.print_response(\"Sleep for 5 seconds\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nname\tstr\t\"sleep\"\tThe name of the tool\n​\nToolkit Functions\nFunction\tDescription\nsleep\tPauses execution for a specified number of seconds\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSlack\nSpider\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Slack - Phidata",
    "url": "https://docs.phidata.com/tools/slack",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nSlack\n​\nPrerequisites\n\nThe following example requires the slack-sdk library.\n\npip install openai slack-sdk\n\n\nGet a Slack token from here.\n\nexport SLACK_TOKEN=***\n\n​\nExample\n\nThe following agent will use Slack to send a message to a channel, list all channels, and get the message history of a specific channel.\n\ncookbook/tools/slack_tools.py\nimport os\n\nfrom phi.agent import Agent\nfrom phi.tools.slack import SlackTools\n\n\nslack_token = os.getenv(\"SLACK_TOKEN\")\nif not slack_token:\n    raise ValueError(\"SLACK_TOKEN not set\")\nslack_tools = SlackTools(token=slack_token)\n\nagent = Agent(tools=[slack_tools], show_tool_calls=True)\n\n# Example 1: Send a message to a Slack channel\nagent.print_response(\"Send a message 'Hello from Phi!' to the channel #general\", markdown=True)\n\n# Example 2: List all channels in the Slack workspace\nagent.print_response(\"List all channels in our Slack workspace\", markdown=True)\n\n# Example 3: Get the message history of a specific channel\nagent.print_response(\"Get the last 10 messages from the channel #random_junk\", markdown=True)\n\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\ntoken\tstr\t-\tSlack API token for authentication\nsend_message\tbool\tTrue\tEnables the functionality to send messages to Slack channels\nlist_channels\tbool\tTrue\tEnables the functionality to list available Slack channels\nget_channel_history\tbool\tTrue\tEnables the functionality to retrieve message history from channels\n​\nToolkit Functions\nFunction\tDescription\nsend_message\tSends a message to a specified Slack channel\nlist_channels\tLists all available channels in the Slack workspace\nget_channel_history\tRetrieves message history from a specified channel\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nShell\nSleep\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Shell - Phidata",
    "url": "https://docs.phidata.com/tools/shell",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nShell\n\nShellTools enable an Agent to interact with the shell to run commands.\n\n​\nExample\n\nThe following agent will run a shell command and show contents of the current directory.\n\nMention your OS to the agent to make sure it runs the correct command.\n\ncookbook/tools/shell_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.shell import ShellTools\n\nagent = Agent(tools=[ShellTools()], show_tool_calls=True)\nagent.print_response(\"Show me the contents of the current directory\", markdown=True)\n\n​\nFunctions in Toolkit\nFunction\tDescription\nrun_shell_command\tRuns a shell command and returns the output or error.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSerpapi\nSlack\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nFunctions in Toolkit\nInformation"
  },
  {
    "title": "Serpapi - Phidata",
    "url": "https://docs.phidata.com/tools/serpapi",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nSerpapi\n\nSerpApiTools enable an Agent to search Google and YouTube for a query.\n\n​\nPrerequisites\n\nThe following example requires the google-search-results library and an API key from SerpApi.\n\npip install -U google-search-results\n\nexport SERPAPI_API_KEY=***\n\n​\nExample\n\nThe following agent will search Google for the query: “Whats happening in the USA” and share results.\n\ncookbook/tools/serpapi_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.serpapi_tools import SerpApiTools\n\nagent = Agent(tools=[SerpApiTools()])\nagent.print_response(\"Whats happening in the USA?\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\t-\tAPI key for authentication purposes.\nsearch_youtube\tbool\tFalse\tEnables the functionality to search for content on YouTube.\n​\nToolkit Functions\nFunction\tDescription\nsearch_google\tThis function searches Google for a query.\nsearch_youtube\tSearches YouTube for a query.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSearxng\nShell\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Searxng - Phidata",
    "url": "https://docs.phidata.com/tools/searxng",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nSearxng\n​\nExample\n\nSearxng enables an Agent to search the web for a query, scrape a website, or crawl a website.\n\ncookbook/tools/searxng_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.searxng import Searxng\n\n# Initialize Searxng with your Searxng instance URL\nsearxng = Searxng(\n    host=\"http://localhost:53153\",\n    engines=[],\n    fixed_max_results=5,\n    news=True,\n    science=True\n)\n\n# Create an agent with Searxng\nagent = Agent(tools=[searxng])\n\n# Example: Ask the agent to search using Searxng\nagent.print_response(\"\"\"\nPlease search for information about artificial intelligence\nand summarize the key points from the top results\n\"\"\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nhost\tstr\t-\tThe host for the connection.\nengines\tList[str]\t[]\tA list of search engines to use.\nfixed_max_results\tint\tNone\tOptional parameter to specify the fixed maximum number of results.\nimages\tbool\tFalse\tEnables searching for images.\nit\tbool\tFalse\tEnables searching for IT-related content.\nmap\tbool\tFalse\tEnables searching for maps.\nmusic\tbool\tFalse\tEnables searching for music.\nnews\tbool\tFalse\tEnables searching for news.\nscience\tbool\tFalse\tEnables searching for science-related content.\nvideos\tbool\tFalse\tEnables searching for videos.\n​\nToolkit Functions\nFunction\tDescription\nsearch\tPerforms a general web search using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the search results.\nimage_search\tPerforms an image search using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the image search results.\nit_search\tPerforms a search for IT-related information using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the IT-related search results.\nmap_search\tPerforms a search for maps using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the map search results.\nmusic_search\tPerforms a search for music-related information using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the music search results.\nnews_search\tPerforms a search for news using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the news search results.\nscience_search\tPerforms a search for science-related information using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the science search results.\nvideo_search\tPerforms a search for videos using the specified query. Parameters include query for the search term and max_results for the maximum number of results (default is 5). Returns the video search results.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nResend\nSerpapi\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Resend - Phidata",
    "url": "https://docs.phidata.com/tools/resend",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nResend\n\nResendTools enable an Agent to send emails using Resend\n\n​\nPrerequisites\n\nThe following example requires the resend library and an API key from Resend.\n\npip install -U resend\n\nexport RESEND_API_KEY=***\n\n​\nExample\n\nThe following agent will send an email using Resend\n\ncookbook/tools/resend_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.resend_tools import ResendTools\n\nfrom_email = \"<enter_from_email>\"\nto_email = \"<enter_to_email>\"\n\nagent = Agent(tools=[ResendTools(from_email=from_email)], show_tool_calls=True)\nagent.print_response(f\"Send an email to {to_email} greeting them with hello world\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\t-\tAPI key for authentication purposes.\nfrom_email\tstr\t-\tThe email address used as the sender in email communications.\n​\nToolkit Functions\nFunction\tDescription\nsend_email\tSend an email using the Resend API.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPython\nSearxng\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Python - Phidata",
    "url": "https://docs.phidata.com/tools/python",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nPython\n\nPythonTools enable an Agent to write and run python code.\n\n​\nExample\n\nThe following agent will write a python script that creates the fibonacci series, save it to a file, run it and return the result.\n\ncookbook/tools/python_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.python import PythonTools\n\nagent = Agent(tools=[PythonTools()], show_tool_calls=True)\nagent.print_response(\"Write a python script for fibonacci series and display the result till the 10th number\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nbase_dir\tPath\tNone\tSpecifies the base directory for operations. Default is None, indicating the current working directory.\nsave_and_run\tbool\tTrue\tIf True, saves and runs the code. Useful for execution of scripts after saving.\npip_install\tbool\tFalse\tEnables pip installation of required packages before running the code.\nrun_code\tbool\tFalse\tDetermines whether the code should be executed.\nlist_files\tbool\tFalse\tIf True, lists all files in the specified base directory.\nrun_files\tbool\tFalse\tIf True, runs the Python files found in the specified directory.\nread_files\tbool\tFalse\tIf True, reads the contents of the files in the specified directory.\nsafe_globals\tdict\t-\tSpecifies a dictionary of global variables that are considered safe to use during the execution.\nsafe_locals\tdict\t-\tSpecifies a dictionary of local variables that are considered safe to use during the execution.\n​\nToolkit Functions\nFunction\tDescription\nsave_to_file_and_run\tThis function saves Python code to a file called file_name and then runs it. If successful, returns the value of variable_to_return if provided otherwise returns a success message. If failed, returns an error message. Make sure the file_name ends with .py\nrun_python_file_return_variable\tThis function runs code in a Python file. If successful, returns the value of variable_to_return if provided otherwise returns a success message. If failed, returns an error message.\nread_file\tReads the contents of the file file_name and returns the contents if successful.\nlist_files\tReturns a list of files in the base directory\nrun_python_code\tThis function runs Python code in the current environment. If successful, returns the value of variable_to_return if provided otherwise returns a success message. If failed, returns an error message.\npip_install_package\tThis function installs a package using pip in the current environment. If successful, returns a success message. If failed, returns an error message.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPubmed\nResend\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Pubmed - Phidata",
    "url": "https://docs.phidata.com/tools/pubmed",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nPubmed\n\nPubmedTools enable an Agent to search for Pubmed for articles.\n\n​\nExample\n\nThe following agent will search Pubmed for articles related to “ulcerative colitis”.\n\ncookbook/tools/pubmed.py\nfrom phi.agent import Agent\nfrom phi.tools.pubmed import PubmedTools\n\nagent = Agent(tools=[PubmedTools()], show_tool_calls=True)\nagent.print_response(\"Tell me about ulcerative colitis.\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nemail\tstr\t\"your_email@example.com\"\tSpecifies the email address to use.\nmax_results\tint\tNone\tOptional parameter to specify the maximum number of results to return.\n​\nToolkit Functions\nFunction\tDescription\nsearch_pubmed\tSearches PubMed for articles based on a specified query. Parameters include query for the search term and max_results for the maximum number of results to return (default is 10). Returns a JSON string containing the search results, including publication date, title, and summary.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPostgres\nPython\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Postgres - Phidata",
    "url": "https://docs.phidata.com/tools/postgres",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nPostgres\n\nPostgresTools enable an Agent to interact with a PostgreSQL database.\n\n​\nPrerequisites\n\nThe following example requires the psycopg2 library.\n\npip install -U psycopg2\n\n\nYou will also need a database. The following example uses a Postgres database running in a Docker container.\n\ndocker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\n​\nExample\n\nThe following agent will list all tables in the database.\n\ncookbook/tools/postgres.py\nfrom phi.agent import Agent\nfrom phi.tools.postgres import PostgresTools\n\n# Initialize PostgresTools with connection details\npostgres_tools = PostgresTools(\n    host=\"localhost\",\n    port=5532,\n    db_name=\"ai\",\n    user=\"ai\", \n    password=\"ai\"\n)\n\n# Create an agent with the PostgresTools\nagent = Agent(tools=[postgres_tools])\n\n# Example: Ask the agent to run a SQL query\nagent.print_response(\"\"\"\nPlease run a SQL query to get all users from the users table \nwho signed up in the last 30 days\n\"\"\")\n\n​\nToolkit Params\nName\tType\tDefault\tDescription\nconnection\tpsycopg2.extensions.connection\tNone\tOptional database connection object.\ndb_name\tstr\tNone\tOptional name of the database to connect to.\nuser\tstr\tNone\tOptional username for database authentication.\npassword\tstr\tNone\tOptional password for database authentication.\nhost\tstr\tNone\tOptional host for the database connection.\nport\tint\tNone\tOptional port for the database connection.\nrun_queries\tbool\tTrue\tEnables running SQL queries.\ninspect_queries\tbool\tFalse\tEnables inspecting SQL queries before execution.\nsummarize_tables\tbool\tTrue\tEnables summarizing table structures.\nexport_tables\tbool\tFalse\tEnables exporting tables from the database.\n​\nToolkit Functions\nFunction\tDescription\nshow_tables\tRetrieves and displays a list of tables in the database. Returns the list of tables.\ndescribe_table\tDescribes the structure of a specified table by returning its columns, data types, and maximum character length. Parameters include ‘table’ to specify the table name. Returns the table description.\nsummarize_table\tSummarizes a table by computing aggregates such as min, max, average, standard deviation, and non-null counts for numeric columns. Parameters include ‘table’ to specify the table name, and an optional ‘table_schema’ to specify the schema (default is “public”). Returns the summary of the table.\ninspect_query\tInspects an SQL query by returning the query plan. Parameters include ‘query’ to specify the SQL query. Returns the query plan.\nexport_table_to_path\tExports a specified table in CSV format to a given path. Parameters include ‘table’ to specify the table name and an optional ‘path’ to specify where to save the file (default is the current directory). Returns the result of the export operation.\nrun_query\tExecutes an SQL query and returns the result. Parameters include ‘query’ to specify the SQL query. Returns the result of the query execution.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPhi\nPubmed\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Phi - Phidata",
    "url": "https://docs.phidata.com/tools/phi",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nPhi\n​\nExample\n\nThe following agent will use the Phi toolkit to create and manage phidata workspaces. It can create new applications from templates like llm-app, api-app, django-app, and streamlit-app. It can also start existing workspaces and validate that Phi is ready to run commands.\n\ncookbook/tools/phi_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.phi import PhiTools\n\n# Create an Agent with the Phi tool\nagent = Agent(tools=[PhiTools()], name=\"Phi Workspace Manager\")\n\n# Example 1: Create a new agent app\nagent.print_response(\"Create a new agent-app called agent-app-turing\", markdown=True)\n\n# Example 3: Start a workspace\nagent.print_response(\"Start the workspace agent-app-turing\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nname\tstr\t\"phi_tools\"\tThe name of the tool\n​\nToolkit Functions\nFunction\tDescription\nvalidate_phi_is_ready\tValidates that Phi is ready to run commands\ncreate_new_app\tCreates a new phidata workspace for a given application template\nstart_user_workspace\tStarts the workspace for a user\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPandas\nPostgres\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Pandas - Phidata",
    "url": "https://docs.phidata.com/tools/pandas",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nPandas\n\nPandasTools enable an Agent to perform data manipulation tasks using the Pandas library.\n\ncookbook/tools/pandas_tool.py\nfrom phi.agent import Agent\nfrom phi.tools.pandas import PandasTools\n\n# Create an agent with PandasTools\nagent = Agent(tools=[PandasTools()])\n\n# Example: Create a dataframe with sample data and get the first 5 rows\nagent.print_response(\"\"\"\nPlease perform these tasks:\n1. Create a pandas dataframe named 'sales_data' using DataFrame() with this sample data:\n   {'date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n    'product': ['Widget A', 'Widget B', 'Widget A', 'Widget C', 'Widget B'],\n    'quantity': [10, 15, 8, 12, 20],\n    'price': [9.99, 15.99, 9.99, 12.99, 15.99]}\n2. Show me the first 5 rows of the sales_data dataframe\n\"\"\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\ndataframes\tDict[str, pd.DataFrame]\t{}\tA dictionary to store Pandas DataFrames, keyed by their names.\ncreate_pandas_dataframe\tfunction\t-\tRegisters a function to create a Pandas DataFrame.\nrun_dataframe_operation\tfunction\t-\tRegisters a function to run operations on a Pandas DataFrame.\n​\nToolkit Functions\nFunction\tDescription\ncreate_pandas_dataframe\tCreates a Pandas DataFrame named dataframe_name by using the specified function create_using_function with parameters function_parameters. Parameters include ‘dataframe_name’ for the name of the DataFrame, ‘create_using_function’ for the function to create it (e.g., ‘read_csv’), and ‘function_parameters’ for the arguments required by the function. Returns the name of the created DataFrame if successful, otherwise returns an error message.\nrun_dataframe_operation\tRuns a specified operation operation on a DataFrame dataframe_name with the parameters operation_parameters. Parameters include ‘dataframe_name’ for the DataFrame to operate on, ‘operation’ for the operation to perform (e.g., ‘head’, ‘tail’), and ‘operation_parameters’ for the arguments required by the operation. Returns the result of the operation if successful, otherwise returns an error message.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenBB\nPhi\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "OpenBB - Phidata",
    "url": "https://docs.phidata.com/tools/openbb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nOpenBB\n\nOpenBBTools enable an Agent to provide information about stocks and companies.\n\ncookbook/tools/openbb_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.openbb_tools import OpenBBTools\n\n\nagent = Agent(tools=[OpenBBTools()], debug_mode=True, show_tool_calls=True)\n\n# Example usage showing stock analysis\nagent.print_response(\n    \"Get me the current stock price and key information for Apple (AAPL)\"\n)\n\n# Example showing market analysis\nagent.print_response(\n    \"What are the top gainers in the market today?\"\n)\n\n# Example showing economic indicators\nagent.print_response(\n    \"Show me the latest GDP growth rate and inflation numbers for the US\"\n)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nread_article\tbool\tTrue\tEnables the functionality to read the full content of an article.\ninclude_summary\tbool\tFalse\tSpecifies whether to include a summary of the article along with the full content.\narticle_length\tint\t-\tThe maximum length of the article or its summary to be processed or returned.\n​\nToolkit Functions\nFunction\tDescription\nget_stock_price\tThis function gets the current stock price for a stock symbol or list of symbols.\nsearch_company_symbol\tThis function searches for the stock symbol of a company.\nget_price_targets\tThis function gets the price targets for a stock symbol or list of symbols.\nget_company_news\tThis function gets the latest news for a stock symbol or list of symbols.\nget_company_profile\tThis function gets the company profile for a stock symbol or list of symbols.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nNewspaper4k\nPandas\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Newspaper4k - Phidata",
    "url": "https://docs.phidata.com/tools/newspaper4k",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nNewspaper4k\n\nNewspaper4k enables an Agent to read news articles using the Newspaper4k library.\n\n​\nPrerequisites\n\nThe following example requires the newspaper4k and lxml_html_clean libraries.\n\npip install -U newspaper4k lxml_html_clean\n\n​\nExample\n\nThe following agent will summarize the article: https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime.\n\ncookbook/tools/newspaper4k_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.newspaper4k import Newspaper4k\n\nagent = Agent(tools=[Newspaper4k()], debug_mode=True, show_tool_calls=True)\nagent.print_response(\"Please summarize https://www.rockymountaineer.com/blog/experience-icefields-parkway-scenic-drive-lifetime\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nread_article\tbool\tTrue\tEnables the functionality to read the full content of an article.\ninclude_summary\tbool\tFalse\tSpecifies whether to include a summary of the article along with the full content.\narticle_length\tint\t-\tThe maximum length of the article or its summary to be processed or returned.\n​\nToolkit Functions\nFunction\tDescription\nget_article_data\tThis function reads the full content and data of an article.\nread_article\tThis function reads the full content of an article.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nNewspaper\nOpenBB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Newspaper - Phidata",
    "url": "https://docs.phidata.com/tools/newspaper",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nNewspaper\n\nNewspaperTools enable an Agent to read news articles using the Newspaper4k library.\n\n​\nPrerequisites\n\nThe following example requires the newspaper3k library.\n\npip install -U newspaper3k\n\n​\nExample\n\nThe following agent will summarize the wikipedia article on language models.\n\ncookbook/tools/newspaper_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.newspaper_tools import NewspaperTools\n\nagent = Agent(tools=[NewspaperTools()])\nagent.print_response(\"Please summarize https://en.wikipedia.org/wiki/Language_model\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nget_article_text\tbool\tTrue\tEnables the functionality to retrieve the text of an article.\n​\nToolkit Functions\nFunction\tDescription\nget_article_text\tRetrieves the text of an article from a specified URL. Parameters include url for the URL of the article. Returns the text of the article or an error message if the retrieval fails.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nModelsLabs\nNewspaper4k\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "ModelsLabs - Phidata",
    "url": "https://docs.phidata.com/tools/models_labs",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nModelsLabs\n​\nPrerequisites\n\nYou need to install the requests library.\n\npip install requests\n\n\nSet the MODELS_LAB_API_KEY environment variable.\n\nexport MODELS_LAB_API_KEY=****\n\n​\nExample\n\nThe following agent will use ModelsLabs to generate a video based on a text prompt.\n\ncookbook/tools/models_labs_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.models_labs import ModelsLabs\n\n# Create an Agent with the ModelsLabs tool\nagent = Agent(tools=[ModelsLabs()], name=\"ModelsLabs Agent\")\n\nagent.print_response(\"Generate a video of a beautiful sunset over the ocean\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\tNone\tThe ModelsLab API key for authentication\nurl\tstr\t\"https://modelslab.com/api/v6/video/text2video\"\tThe API endpoint URL\nname\tstr\t\"models_labs\"\tThe name of the tool\n​\nToolkit Functions\nFunction\tDescription\ngenerate_video\tGenerates a video based on a text prompt\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nMLX Transcribe\nNewspaper\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "MLX Transcribe - Phidata",
    "url": "https://docs.phidata.com/tools/mlx_transcribe",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nMLX Transcribe\n\nMLX Transcribe is a tool for transcribing audio files using MLX Whisper.\n\n​\nPrerequisites\n\nInstall ffmpeg\n\nmacOS: brew install ffmpeg\nUbuntu: sudo apt-get install ffmpeg\nWindows: Download from https://ffmpeg.org/download.html\n\nInstall mlx-whisper library\n\npip install mlx-whisper\n\n\nPrepare audio files\n\nCreate a ‘storage/audio’ directory\nPlace your audio files in this directory\nSupported formats: mp3, mp4, wav, etc.\n\nDownload sample audio (optional)\n\nVisit: https://www.ted.com/talks/reid_hoffman_and_kevin_scott_the_evolution_of_ai_and_how_it_will_impact_human_creativity\nSave the audio file to ‘storage/audio’ directory\n​\nExample\n\nThe following agent will use MLX Transcribe to transcribe audio files.\n\ncookbook/tools/mlx_transcribe_tools.py\n\nfrom pathlib import Path\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.mlx_transcribe import MLXTranscribe\n\n# Get audio files from storage/audio directory\nphidata_root_dir = Path(__file__).parent.parent.parent.resolve()\naudio_storage_dir = phidata_root_dir.joinpath(\"storage/audio\")\nif not audio_storage_dir.exists():\n    audio_storage_dir.mkdir(exist_ok=True, parents=True)\n\nagent = Agent(\n    name=\"Transcription Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[MLXTranscribe(base_dir=audio_storage_dir)],\n    instructions=[\n        \"To transcribe an audio file, use the `transcribe` tool with the name of the audio file as the argument.\",\n        \"You can find all available audio files using the `read_files` tool.\",\n    ],\n    markdown=True,\n)\n\nagent.print_response(\"Summarize the reid hoffman ted talk, split into sections\", stream=True)\n\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nbase_dir\tPath\tPath.cwd()\tBase directory for audio files\nread_files_in_base_dir\tbool\tTrue\tWhether to register the read_files function\npath_or_hf_repo\tstr\t\"mlx-community/whisper-large-v3-turbo\"\tPath or HuggingFace repo for the model\nverbose\tbool\tNone\tEnable verbose output\ntemperature\tfloat or Tuple[float, ...]\tNone\tTemperature for sampling\ncompression_ratio_threshold\tfloat\tNone\tCompression ratio threshold\nlogprob_threshold\tfloat\tNone\tLog probability threshold\nno_speech_threshold\tfloat\tNone\tNo speech threshold\ncondition_on_previous_text\tbool\tNone\tWhether to condition on previous text\ninitial_prompt\tstr\tNone\tInitial prompt for transcription\nword_timestamps\tbool\tNone\tEnable word-level timestamps\nprepend_punctuations\tstr\tNone\tPunctuations to prepend\nappend_punctuations\tstr\tNone\tPunctuations to append\nclip_timestamps\tstr or List[float]\tNone\tClip timestamps\nhallucination_silence_threshold\tfloat\tNone\tHallucination silence threshold\ndecode_options\tdict\tNone\tAdditional decoding options\n​\nToolkit Functions\nFunction\tDescription\ntranscribe\tTranscribes an audio file using MLX Whisper\nread_files\tLists all audio files in the base directory\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nJira\nModelsLabs\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Jira - Phidata",
    "url": "https://docs.phidata.com/tools/jira",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nJira\n\nJiraTools enable an Agent to perform Jira tasks.\n\n​\nPrerequisites\n\nThe following example requires the jira library and auth credentials.\n\npip install -U jira\n\nexport JIRA_SERVER_URL=\"YOUR_JIRA_SERVER_URL\"\nexport JIRA_USERNAME=\"YOUR_USERNAME\"\nexport JIRA_API_TOKEN=\"YOUR_API_TOKEN\"\n\n​\nExample\n\nThe following agent will use Jira API to search for issues in a project.\n\ncookbook/tools/jira_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.jira_tools import JiraTools\n\nagent = Agent(tools=[JiraTools()])\nagent.print_response(\"Find all issues in project PROJ\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nserver_url\tstr\t\"\"\tThe URL of the JIRA server, retrieved from the environment variable JIRA_SERVER_URL. Default is an empty string if not set.\nusername\tstr\tNone\tThe JIRA username for authentication, retrieved from the environment variable JIRA_USERNAME. Default is None if not set.\npassword\tstr\tNone\tThe JIRA password for authentication, retrieved from the environment variable JIRA_PASSWORD. Default is None if not set.\ntoken\tstr\tNone\tThe JIRA API token for authentication, retrieved from the environment variable JIRA_TOKEN. Default is None if not set.\n​\nToolkit Functions\nFunction\tDescription\nget_issue\tRetrieves issue details from JIRA. Parameters include:\n- issue_key: the key of the issue to retrieve\nReturns a JSON string containing issue details or an error message.\ncreate_issue\tCreates a new issue in JIRA. Parameters include:\n- project_key: the project in which to create the issue\n- summary: the issue summary\n- description: the issue description\n- issuetype: the type of issue (default is “Task”)\nReturns a JSON string with the new issue’s key and URL or an error message.\nsearch_issues\tSearches for issues using a JQL query in JIRA. Parameters include:\n- jql_str: the JQL query string\n- max_results: the maximum number of results to return (default is 50)\nReturns a JSON string containing a list of dictionaries with issue details or an error message.\nadd_comment\tAdds a comment to an issue in JIRA. Parameters include:\n- issue_key: the key of the issue\n- comment: the comment text\nReturns a JSON string indicating success or an error message.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nJina Reader\nMLX Transcribe\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Jina Reader - Phidata",
    "url": "https://docs.phidata.com/tools/jina_reader",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nJina Reader\n\nJinaReaderTools enable an Agent to perform web search tasks using Jina.\n\n​\nPrerequisites\n\nThe following example requires the jina library.\n\npip install -U jina\n\n​\nExample\n\nThe following agent will use Jina API to summarize the content of https://github.com/phidatahq\n\ncookbook/tools/jinareader_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.jina_tools import JinaReaderTools\n\nagent = Agent(tools=[JinaReaderTools()])\nagent.print_response(\"Summarize: https://github.com/phidatahq\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\t-\tThe API key for authentication purposes, retrieved from the configuration.\nbase_url\tstr\t-\tThe base URL of the API, retrieved from the configuration.\nsearch_url\tstr\t-\tThe URL used for search queries, retrieved from the configuration.\nmax_content_length\tint\t-\tThe maximum length of content allowed, retrieved from the configuration.\n​\nToolkit Functions\nFunction\tDescription\nread_url\tReads the content of a specified URL using Jina Reader API. Parameters include url for the URL to read. Returns the truncated content or an error message if the request fails.\nsearch_query\tPerforms a web search using Jina Reader API based on a specified query. Parameters include query for the search term. Returns the truncated search results or an error message if the request fails.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nHacker News\nJira\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Hacker News - Phidata",
    "url": "https://docs.phidata.com/tools/hackernews",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nHacker News\n\nHackerNews enables an Agent to search Hacker News website.\n\n​\nExample\n\nThe following agent will write an engaging summary of the users with the top 2 stories on hackernews along with the stories.\n\ncookbook/tools/hackernews.py\nfrom phi.agent import Agent\nfrom phi.tools.hackernews import HackerNews\n\nagent = Agent(\n    name=\"Hackernews Team\",\n    tools=[HackerNews()],\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\n    \"Write an engaging summary of the \"\n    \"users with the top 2 stories on hackernews. \"\n    \"Please mention the stories as well.\",\n)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nget_top_stories\tbool\tTrue\tEnables fetching top stories.\nget_user_details\tbool\tTrue\tEnables fetching user details.\n​\nToolkit Functions\nFunction\tDescription\nget_top_hackernews_stories\tRetrieves the top stories from Hacker News. Parameters include num_stories to specify the number of stories to return (default is 10). Returns the top stories in JSON format.\nget_user_details\tRetrieves the details of a Hacker News user by their username. Parameters include username to specify the user. Returns the user details in JSON format.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGoogle Search\nJina Reader\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Google Search - Phidata",
    "url": "https://docs.phidata.com/tools/googlesearch",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nGoogle Search\n\nGoogleSearch enables an Agent to perform web crawling and scraping tasks.\n\n​\nPrerequisites\n\nThe following examples requires the googlesearch and pycountry libraries.\n\npip install -U googlesearch-python pycountry\n\n​\nExample\n\nThe following agent will search Google for the latest news about “Mistral AI”:\n\ncookbook/tools/googlesearch_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.googlesearch import GoogleSearch\n\nagent = Agent(\n    tools=[GoogleSearch()],\n    description=\"You are a news agent that helps users find the latest news.\",\n    instructions=[\n        \"Given a topic by the user, respond with 4 latest news items about that topic.\",\n        \"Search for 10 news items and select the top 4 unique items.\",\n        \"Search in English and in French.\",\n    ],\n    show_tool_calls=True,\n    debug_mode=True,\n)\nagent.print_response(\"Mistral AI\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nfixed_max_results\tint\tNone\tOptional fixed maximum number of results to return.\nfixed_language\tstr\tNone\tOptional fixed language for the requests.\nheaders\tAny\tNone\tOptional headers to include in the requests.\nproxy\tstr\tNone\tOptional proxy to be used for the requests.\ntimeout\tint\tNone\tOptional timeout for the requests, in seconds.\n​\nToolkit Functions\nFunction\tDescription\ngoogle_search\tSearches Google for a specified query. Parameters include query for the search term, max_results for the maximum number of results (default is 5), and language for the language of the search results (default is “en”). Returns the search results as a JSON formatted string.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGithub\nHacker News\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Github - Phidata",
    "url": "https://docs.phidata.com/tools/github",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nGithub\n\nGithubTools enables an Agent to access Github repositories and perform tasks such as listing open pull requests, issues and more.\n\n​\nPrerequisites\n\nThe following examples requires the PyGithub library and a Github access token which can be obtained from here.\n\npip install -U PyGithub\n\nexport GITHUB_ACCESS_TOKEN=***\n\n​\nExample\n\nThe following agent will search Google for the latest news about “Mistral AI”:\n\ncookbook/tools/github_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.github import GithubTools\n\nagent = Agent(\n    instructions=[\n        \"Use your tools to answer questions about the repo: phidatahq/phidata\",\n        \"Do not create any issues or pull requests unless explicitly asked to do so\",\n    ],\n    tools=[GithubTools()],\n    show_tool_calls=True,\n)\nagent.print_response(\"List open pull requests\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\naccess_token\tstr\tNone\tGithub access token for authentication. If not provided, will use GITHUB_ACCESS_TOKEN environment variable.\nbase_url\tstr\tNone\tOptional base URL for Github Enterprise installations.\nsearch_repositories\tbool\tTrue\tEnable searching Github repositories.\nlist_repositories\tbool\tTrue\tEnable listing repositories for a user/organization.\nget_repository\tbool\tTrue\tEnable getting repository details.\nlist_pull_requests\tbool\tTrue\tEnable listing pull requests for a repository.\nget_pull_request\tbool\tTrue\tEnable getting pull request details.\nget_pull_request_changes\tbool\tTrue\tEnable getting pull request file changes.\ncreate_issue\tbool\tTrue\tEnable creating issues in repositories.\n​\nToolkit Functions\nFunction\tDescription\nsearch_repositories\tSearches Github repositories based on a query.\nlist_repositories\tLists repositories for a given user or organization.\nget_repository\tGets details about a specific repository.\nlist_pull_requests\tLists pull requests for a repository.\nget_pull_request\tGets details about a specific pull request.\nget_pull_request_changes\tGets the file changes in a pull request.\ncreate_issue\tCreates a new issue in a repository.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFirecrawl\nGoogle Search\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Firecrawl - Phidata",
    "url": "https://docs.phidata.com/tools/firecrawl",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nFirecrawl\n\nFirecrawlTools enable an Agent to perform web crawling and scraping tasks.\n\n​\nPrerequisites\n\nThe following example requires the firecrawl-py library and an API key which can be obtained from Firecrawl.\n\npip install -U firecrawl-py\n\nexport FIRECRAWL_API_KEY=***\n\n​\nExample\n\nThe following agent will scrape the content from https://finance.yahoo.com/ and return a summary of the content:\n\ncookbook/tools/firecrawl_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.firecrawl import FirecrawlTools\n\nagent = Agent(tools=[FirecrawlTools(scrape=False, crawl=True)], show_tool_calls=True, markdown=True)\nagent.print_response(\"Summarize this https://finance.yahoo.com/\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\tNone\tOptional API key for authentication purposes.\nformats\tList[str]\tNone\tOptional list of formats to be used for the operation.\nlimit\tint\t10\tMaximum number of items to retrieve. The default value is 10.\nscrape\tbool\tTrue\tEnables the scraping functionality. Default is True.\ncrawl\tbool\tFalse\tEnables the crawling functionality. Default is False.\n​\nToolkit Functions\nFunction\tDescription\nscrape_website\tScrapes a website using Firecrawl. Parameters include url to specify the URL to scrape. The function supports optional formats if specified. Returns the results of the scraping in JSON format.\ncrawl_website\tCrawls a website using Firecrawl. Parameters include url to specify the URL to crawl, and an optional limit to define the maximum number of pages to crawl. The function supports optional formats and returns the crawling results in JSON format.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFile\nGithub\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "File - Phidata",
    "url": "https://docs.phidata.com/tools/file",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nFile\n\nFileTools enable an Agent to read and write files on the local file system.\n\n​\nExample\n\nThe following agent will generate an answer and save it in a file.\n\ncookbook/tools/file_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.file import FileTools\n\nagent = Agent(tools=[FileTools()], show_tool_calls=True)\nagent.print_response(\"What is the most advanced LLM currently? Save the answer to a file.\", markdown=True)\n\n​\nToolkit Params\nName\tType\tDefault\tDescription\nbase_dir\tPath\t-\tSpecifies the base directory path for file operations.\nsave_files\tbool\tTrue\tDetermines whether files should be saved during the operation.\nread_files\tbool\tTrue\tAllows reading from files during the operation.\nlist_files\tbool\tTrue\tEnables listing of files in the specified directory.\n​\nToolkit Functions\nName\tDescription\nsave_file\tSaves the contents to a file called file_name and returns the file name if successful.\nread_file\tReads the contents of the file file_name and returns the contents if successful.\nlist_files\tReturns a list of files in the base directory\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nExa\nFirecrawl\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Exa - Phidata",
    "url": "https://docs.phidata.com/tools/exa",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nExa\n\nExaTools enable an Agent to search the web using Exa.\n\n​\nPrerequisites\n\nThe following examples requires the exa-client library and an API key which can be obtained from Exa.\n\npip install -U exa-client\n\nexport EXA_API_KEY=***\n\n​\nExample\n\nThe following agent will run seach exa for AAPL news and print the response.\n\ncookbook/tools/exa_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.exa import ExaTools\n\nagent = Agent(tools=[ExaTools(include_domains=[\"cnbc.com\", \"reuters.com\", \"bloomberg.com\"])], show_tool_calls=True)\nagent.print_response(\"Search for AAPL news\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\t-\tAPI key for authentication purposes.\nsearch\tbool\tFalse\tDetermines whether to enable search functionality.\nsearch_with_contents\tbool\tTrue\tIndicates whether to include contents in the search results.\nshow_results\tbool\tFalse\tControls whether to display search results directly.\n​\nToolkit Functions\nFunction\tDescription\nsearch_exa\tSearches Exa for a query.\nsearch_exa_with_contents\tSearches Exa for a query and returns the contents from the search results.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nEmail\nFile\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Email - Phidata",
    "url": "https://docs.phidata.com/tools/email",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nEmail\n\nEmailTools enable an Agent to send an email to a user. The Agent can send an email to a user with a specific subject and body.\n\n​\nExample\ncookbook/tools/email_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.email import EmailTools\n\nreceiver_email = \"<receiver_email>\"\nsender_email = \"<sender_email>\"\nsender_name = \"<sender_name>\"\nsender_passkey = \"<sender_passkey>\"\n\nagent = Agent(\n    tools=[\n        EmailTools(\n            receiver_email=receiver_email,\n            sender_email=sender_email,\n            sender_name=sender_name,\n            sender_passkey=sender_passkey,\n        )\n    ]\n)\nagent.print_response(\"send an email to <receiver_email>\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nreceiver_email\tstr\t-\tThe email address of the receiver.\nsender_name\tstr\t-\tThe name of the sender.\nsender_email\tstr\t-\tThe email address of the sender.\nsender_passkey\tstr\t-\tThe passkey for the sender’s email.\n​\nToolkit Functions\nFunction\tDescription\nemail_user\tEmails the user with the given subject and body. Currently works with Gmail.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDuckDuckGo\nExa\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "DuckDuckGo - Phidata",
    "url": "https://docs.phidata.com/tools/duckduckgo",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nDuckDuckGo\n\nDuckDuckGo enables an Agent to search the web for information.\n\n​\nPrerequisites\n\nThe following example requires the duckduckgo-search library. To install DuckDuckGo, run the following command:\n\npip install -U duckduckgo-search\n\n​\nExample\ncookbook/tools/duckduckgo.py\nfrom phi.agent import Agent\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nagent = Agent(tools=[DuckDuckGo()], show_tool_calls=True)\nagent.print_response(\"Whats happening in France?\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nsearch\tbool\tTrue\tEnables the use of the duckduckgo_search function to search DuckDuckGo for a query.\nnews\tbool\tTrue\tEnables the use of the duckduckgo_news function to fetch the latest news via DuckDuckGo.\nfixed_max_results\tint\t-\tSets a fixed number of maximum results to return. No default is provided, must be specified if used.\nheaders\tAny\t-\tAccepts any type of header values to be sent with HTTP requests.\nproxy\tstr\t-\tSpecifies a single proxy address as a string to be used for the HTTP requests.\nproxies\tAny\t-\tAccepts a dictionary of proxies to be used for HTTP requests.\ntimeout\tint\t10\tSets the timeout for HTTP requests, in seconds.\n​\nToolkit Functions\nFunction\tDescription\nduckduckgo_search\tUse this function to search DuckDuckGo for a query.\nduckduckgo_news\tUse this function to get the latest news from DuckDuckGo.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDuckDb\nEmail\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "DuckDb - Phidata",
    "url": "https://docs.phidata.com/tools/duckdb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nDuckDb\n\nDuckDbTools enable an Agent to run SQL and analyze data using DuckDb.\n\n​\nPrerequisites\n\nThe following example requires DuckDB library. To install DuckDB, run the following command:\n\npip install duckdb\n\n\nFor more installation options, please refer to DuckDB documentation.\n\n​\nExample\n\nThe following agent will analyze the movies file using SQL and return the result.\n\ncookbook/tools/duckdb_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.duckdb import DuckDbTools\n\nagent = Agent(\n    tools=[DuckDbTools()],\n    show_tool_calls=True,\n    system_prompt=\"Use this file for Movies data: https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n)\nagent.print_response(\"What is the average rating of movies?\", markdown=True, stream=False)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\ndb_path\tstr\t-\tSpecifies the path to the database file.\nconnection\tDuckDBPyConnection\t-\tProvides an existing DuckDB connection object.\ninit_commands\tList\t-\tA list of initial SQL commands to run on database connection.\nread_only\tbool\tFalse\tConfigures the database connection to be read-only.\nconfig\tdict\t-\tConfiguration options for the database connection.\nrun_queries\tbool\tTrue\tDetermines whether to run SQL queries during the operation.\ninspect_queries\tbool\tFalse\tEnables inspection of SQL queries without executing them.\ncreate_tables\tbool\tTrue\tAllows creation of tables in the database during the operation.\nsummarize_tables\tbool\tTrue\tEnables summarization of table data during the operation.\nexport_tables\tbool\tFalse\tAllows exporting tables to external formats during the operation.\n​\nToolkit Functions\nFunction\tDescription\nshow_tables\tFunction to show tables in the database\ndescribe_table\tFunction to describe a table\ninspect_query\tFunction to inspect a query and return the query plan. Always inspect your query before running them.\nrun_query\tFunction that runs a query and returns the result.\nsummarize_table\tFunction to compute a number of aggregates over a table. The function launches a query that computes a number of aggregates over all columns, including min, max, avg, std and approx_unique.\nget_table_name_from_path\tGet the table name from a path\ncreate_table_from_path\tCreates a table from a path\nexport_table_to_path\tSave a table in a desired format (default: parquet). If the path is provided, the table will be saved under that path. Eg: If path is /tmp, the table will be saved as /tmp/table.parquet. Otherwise it will be saved in the current directory\nload_local_path_to_table\tLoad a local file into duckdb\nload_local_csv_to_table\tLoad a local CSV file into duckdb\nload_s3_path_to_table\tLoad a file from S3 into duckdb\nload_s3_csv_to_table\tLoad a CSV file from S3 into duckdb\ncreate_fts_index\tCreate a full text search index on a table\nfull_text_search\tFull text Search in a table column for a specific text/keyword\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDalle\nDuckDuckGo\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Dalle - Phidata",
    "url": "https://docs.phidata.com/tools/dalle",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nDalle\n​\nPrerequisites\n\nYou need to install the openai library.\n\npip install openai\n\n\nSet the OPENAI_API_KEY environment variable.\n\nexport OPENAI_API_KEY=****\n\n​\nExample\n\nThe following agent will use DALL-E to generate an image based on a text prompt.\n\ncookbook/tools/dalle_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.dalle import Dalle\n\n# Create an Agent with the DALL-E tool\nagent = Agent(tools=[Dalle()], name=\"DALL-E Image Generator\")\n\n# Example 1: Generate a basic image with default settings\nagent.print_response(\"Generate an image of a futuristic city with flying cars and tall skyscrapers\", markdown=True)\n\n# Example 2: Generate an image with custom settings\ncustom_dalle = Dalle(model=\"dall-e-3\", size=\"1792x1024\", quality=\"hd\", style=\"natural\")\n\nagent_custom = Agent(\n    tools=[custom_dalle],\n    name=\"Custom DALL-E Generator\",\n    show_tool_calls=True,\n)\n\nagent_custom.print_response(\"Create a panoramic nature scene showing a peaceful mountain lake at sunset\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"dall-e-3\"\tThe DALL-E model to use\nn\tint\t1\tNumber of images to generate\nsize\tstr\t\"1024x1024\"\tImage size (256x256, 512x512, 1024x1024, 1792x1024, or 1024x1792)\nquality\tstr\t\"standard\"\tImage quality (standard or hd)\nstyle\tstr\t\"vivid\"\tImage style (vivid or natural)\napi_key\tstr\tNone\tThe OpenAI API key for authentication\n​\nToolkit Functions\nFunction\tDescription\ngenerate_image\tGenerates an image based on a text prompt\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCSV\nDuckDb\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "CSV - Phidata",
    "url": "https://docs.phidata.com/tools/csv",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nCSV\n\nCsvTools enable an Agent to read and write CSV files.\n\n​\nExample\n\nThe following agent will download the IMDB csv file and allow the user to query it using a CLI app.\n\ncookbook/tools/csv_tools.py\nimport httpx\nfrom pathlib import Path\nfrom phi.agent import Agent\nfrom phi.tools.csv_tools import CsvTools\n\nurl = \"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\"\nresponse = httpx.get(url)\n\nimdb_csv = Path(__file__).parent.joinpath(\"wip\").joinpath(\"imdb.csv\")\nimdb_csv.parent.mkdir(parents=True, exist_ok=True)\nimdb_csv.write_bytes(response.content)\n\nagent = Agent(\n    tools=[CsvTools(csvs=[imdb_csv])],\n    markdown=True,\n    show_tool_calls=True,\n    instructions=[\n        \"First always get the list of files\",\n        \"Then check the columns in the file\",\n        \"Then run the query to answer the question\",\n    ],\n)\nagent.cli_app(stream=False)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\ncsvs\tList[Union[str, Path]]\t-\tA list of CSV files or paths to be processed or read.\nrow_limit\tint\t-\tThe maximum number of rows to process from each CSV file.\nread_csvs\tbool\tTrue\tEnables the functionality to read data from specified CSV files.\nlist_csvs\tbool\tTrue\tEnables the functionality to list all available CSV files.\nquery_csvs\tbool\tTrue\tEnables the functionality to execute queries on data within CSV files.\nread_column_names\tbool\tTrue\tEnables the functionality to read the column names from the CSV files.\nduckdb_connection\tAny\t-\tSpecifies a connection instance for DuckDB database operations.\nduckdb_kwargs\tDict[str, Any]\t-\tA dictionary of keyword arguments for configuring DuckDB operations.\n​\nToolkit Functions\nFunction\tDescription\nlist_csv_files\tLists all available CSV files.\nread_csv_file\tThis function reads the contents of a csv file\nget_columns\tThis function returns the columns of a csv file\nquery_csv_file\tThis function queries the contents of a csv file\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCrawl4AI\nDalle\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Crawl4AI - Phidata",
    "url": "https://docs.phidata.com/tools/crawl4ai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nCrawl4AI\n\nCrawl4aiTools enable an Agent to perform web crawling and scraping tasks using the Crawl4ai library.\n\n​\nPrerequisites\n\nThe following example requires the crawl4ai library.\n\npip install -U crawl4ai\n\n​\nExample\n\nThe following agent will scrape the content from the https://github.com/phidatahq/phidata webpage:\n\ncookbook/tools/crawl4ai_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.crawl4ai_tools import Crawl4aiTools\n\nagent = Agent(tools=[Crawl4aiTools(max_length=None)], show_tool_calls=True)\nagent.print_response(\"Tell me about https://github.com/phidatahq/phidata.\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nmax_length\tint\t1000\tSpecifies the maximum length of the text from the webpage to be returned.\n​\nToolkit Functions\nFunction\tDescription\nweb_crawler\tCrawls a website using crawl4ai’s WebCrawler. Parameters include ‘url’ for the URL to crawl and an optional ‘max_length’ to limit the length of extracted content. The default value for ‘max_length’ is 1000.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nComposio\nCSV\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Composio - Phidata",
    "url": "https://docs.phidata.com/tools/composio",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nComposio\n\nComposioTools enable an Agent to work with tools like Gmail, Salesforce, Github, etc.\n\n​\nPrerequisites\n\nThe following example requires the composio-phidata library.\n\npip install composio-phidata\ncomposio add github # Login into Github\n\n​\nExample\n\nThe following agent will use Github Tool from Composio Toolkit to star a repo.\n\ncookbook/tools/composio_tools.py\nfrom phi.agent import Agent\nfrom composio_phidata import Action, ComposioToolSet\n\n\ntoolset = ComposioToolSet()\ncomposio_tools = toolset.get_tools(\n  actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]\n)\n\nagent = Agent(tools=composio_tools, show_tool_calls=True)\nagent.print_response(\"Can you star phidatahq/phidata repo?\")\n\n​\nToolkit Params\n\nThe following parameters are used when calling the GitHub star repository action:\n\nParameter\tType\tDefault\tDescription\nowner\tstr\t-\tThe owner of the repository to star.\nrepo\tstr\t-\tThe name of the repository to star.\n​\nToolkit Functions\n\nComposio Toolkit provides 1000+ functions to connect to different software tools. Open this link to view the complete list of functions.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCalculator\nCrawl4AI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions"
  },
  {
    "title": "Calculator - Phidata",
    "url": "https://docs.phidata.com/tools/calculator",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nCalculator\n\nCalculator enables an Agent to perform mathematical calculations.\n\n​\nExample\n\nThe following agent will calculate the result of 10*5 and then raise it to the power of 2:\n\ncookbook/tools/calculator_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.calculator import Calculator\n\nagent = Agent(\n    tools=[\n        Calculator(\n            add=True,\n            subtract=True,\n            multiply=True,\n            divide=True,\n            exponentiate=True,\n            factorial=True,\n            is_prime=True,\n            square_root=True,\n        )\n    ],\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"What is 10*5 then to the power of 2, do it step by step\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nadd\tbool\tTrue\tEnables the functionality to perform addition.\nsubtract\tbool\tTrue\tEnables the functionality to perform subtraction.\nmultiply\tbool\tTrue\tEnables the functionality to perform multiplication.\ndivide\tbool\tTrue\tEnables the functionality to perform division.\nexponentiate\tbool\tFalse\tEnables the functionality to perform exponentiation.\nfactorial\tbool\tFalse\tEnables the functionality to calculate the factorial of a number.\nis_prime\tbool\tFalse\tEnables the functionality to check if a number is prime.\nsquare_root\tbool\tFalse\tEnables the functionality to calculate the square root of a number.\n​\nToolkit Functions\nFunction\tDescription\nadd\tAdds two numbers and returns the result.\nsubtract\tSubtracts the second number from the first and returns the result.\nmultiply\tMultiplies two numbers and returns the result.\ndivide\tDivides the first number by the second and returns the result. Handles division by zero.\nexponentiate\tRaises the first number to the power of the second number and returns the result.\nfactorial\tCalculates the factorial of a number and returns the result. Handles negative numbers.\nis_prime\tChecks if a number is prime and returns the result.\nsquare_root\tCalculates the square root of a number and returns the result. Handles negative numbers.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAWS Lambda\nComposio\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "AWS Lambda - Phidata",
    "url": "https://docs.phidata.com/tools/aws_lambda",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nAWS Lambda\n​\nPrerequisites\n\nThe following example requires the boto3 library.\n\npip install openai boto3\n\n​\nExample\n\nThe following agent will use AWS Lambda to list all Lambda functions in our AWS account and invoke a specific Lambda function.\n\ncookbook/tools/aws_lambda_tools.py\n\nfrom phi.agent import Agent\nfrom phi.tools.aws_lambda import AWSLambdaTool\n\n\n# Create an Agent with the AWSLambdaTool\nagent = Agent(\n    tools=[AWSLambdaTool(region_name=\"us-east-1\")],\n    name=\"AWS Lambda Agent\",\n    show_tool_calls=True,\n)\n\n# Example 1: List all Lambda functions\nagent.print_response(\"List all Lambda functions in our AWS account\", markdown=True)\n\n# Example 2: Invoke a specific Lambda function\nagent.print_response(\"Invoke the 'hello-world' Lambda function with an empty payload\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nregion_name\tstr\t\"us-east-1\"\tAWS region name where Lambda functions are located.\n​\nToolkit Functions\nFunction\tDescription\nlist_functions\tLists all Lambda functions available in the AWS account.\ninvoke_function\tInvokes a specific Lambda function with an optional payload. Takes function_name and optional payload parameters.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nArxiv\nCalculator\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Airflow - Phidata",
    "url": "https://docs.phidata.com/tools/airflow",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nAirflow\n​\nExample\n\nThe following agent will use Airflow to save and read a DAG file.\n\ncookbook/tools/airflow_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.airflow import AirflowToolkit\n\nagent = Agent(\n    tools=[AirflowToolkit(dags_dir=\"dags\", save_dag=True, read_dag=True)], show_tool_calls=True, markdown=True\n)\n\n\ndag_content = \"\"\"\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom datetime import datetime, timedelta\ndefault_args = {\n    'owner': 'airflow',\n    'depends_on_past': False,\n    'start_date': datetime(2024, 1, 1),\n    'email_on_failure': False,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5),\n}\n# Using 'schedule' instead of deprecated 'schedule_interval'\nwith DAG(\n    'example_dag',\n    default_args=default_args,\n    description='A simple example DAG',\n    schedule='@daily',  # Changed from schedule_interval\n    catchup=False\n) as dag:\n    def print_hello():\n        print(\"Hello from Airflow!\")\n        return \"Hello task completed\"\n    task = PythonOperator(\n        task_id='hello_task',\n        python_callable=print_hello,\n        dag=dag,\n    )\n\"\"\"\n\nagent.run(f\"Save this DAG file as 'example_dag.py': {dag_content}\")\n\n\nagent.print_response(\"Read the contents of 'example_dag.py'\")\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\ndags_dir\tPath or str\tPath.cwd()\tDirectory for DAG files\nsave_dag\tbool\tTrue\tWhether to register the save_dag_file function\nread_dag\tbool\tTrue\tWhether to register the read_dag_file function\nname\tstr\t\"AirflowTools\"\tThe name of the tool\n​\nToolkit Functions\nFunction\tDescription\nsave_dag_file\tSaves python code for an Airflow DAG to a file\nread_dag_file\tReads an Airflow DAG file and returns the contents\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWriting your own Toolkit\nApify\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Arxiv - Phidata",
    "url": "https://docs.phidata.com/tools/arxiv",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nArxiv\n\nArxivTools enable an Agent to search for publications on Arxiv.\n\n​\nPrerequisites\n\nThe following example requires the arxiv and pypdf libraries.\n\npip install -U arxiv pypdf\n\n​\nExample\n\nThe following agent will run seach arXiv for “language models” and print the response.\n\ncookbook/tools/arxiv_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.arxiv_toolkit import ArxivToolkit\n\nagent = Agent(tools=[ArxivToolkit()], show_tool_calls=True)\nagent.print_response(\"Search arxiv for 'language models'\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\nsearch_arxiv\tbool\tTrue\tEnables the functionality to search the arXiv database.\nread_arxiv_papers\tbool\tTrue\tAllows reading of arXiv papers directly.\ndownload_dir\tPath\t-\tSpecifies the directory path where downloaded files will be saved.\n​\nToolkit Functions\nFunction\tDescription\nsearch_arxiv_and_update_knowledge_base\tThis function searches arXiv for a topic, adds the results to the knowledge base and returns them.\nsearch_arxiv\tSearches arXiv for a query.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nApify\nAWS Lambda\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Apify - Phidata",
    "url": "https://docs.phidata.com/tools/apify",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nApify\n\nApifyTools enable an Agent to access the Apify API and run actors.\n\n​\nPrerequisites\n\nThe following example requires the apify-client library and an API token which can be obtained from Apify.\n\npip install -U apify-client\n\nexport MY_APIFY_TOKEN=***\n\n​\nExample\n\nThe following agent will use Apify to crawl the webpage: https://docs.phidata.com/introduction and summarize it.\n\ncookbook/tools/apify_tools.py\nfrom phi.agent import Agent\nfrom phi.tools.apify import ApifyTools\n\nagent = Agent(tools=[ApifyTools()], show_tool_calls=True)\nagent.print_response(\"Tell me about https://docs.phidata.com/introduction\", markdown=True)\n\n​\nToolkit Params\nParameter\tType\tDefault\tDescription\napi_key\tstr\t-\tAPI key for authentication purposes.\nwebsite_content_crawler\tbool\tTrue\tEnables the functionality to crawl a website using website-content-crawler actor.\nweb_scraper\tbool\tFalse\tEnables the functionality to crawl a website using web_scraper actor.\n​\nToolkit Functions\nFunction\tDescription\nwebsite_content_crawler\tCrawls a website using Apify’s website-content-crawler actor.\nweb_scrapper\tScrapes a website using Apify’s web-scraper actor.\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAirflow\nArxiv\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPrerequisites\nExample\nToolkit Params\nToolkit Functions\nInformation"
  },
  {
    "title": "Writing your own Toolkit - Phidata",
    "url": "https://docs.phidata.com/tools/custom-toolkits",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nWriting your own Toolkit\n\nMany advanced use-cases will require writing custom Toolkits. Here’s the general flow:\n\nCreate a class inheriting the phi.tools.Toolkit class.\nAdd your functions to the class.\nImportant: Register the functions using self.register(function_name)\n\nNow your Toolkit is ready to use with an Agent. For example:\n\nshell_toolkit.py\nfrom typing import List\n\nfrom phi.tools import Toolkit\nfrom phi.utils.log import logger\n\n\nclass ShellTools(Toolkit):\n    def __init__(self):\n        super().__init__(name=\"shell_tools\")\n        self.register(self.run_shell_command)\n\n    def run_shell_command(self, args: List[str], tail: int = 100) -> str:\n        \"\"\"Runs a shell command and returns the output or error.\n\n        Args:\n            args (List[str]): The command to run as a list of strings.\n            tail (int): The number of lines to return from the output.\n        Returns:\n            str: The output of the command.\n        \"\"\"\n        import subprocess\n\n        logger.info(f\"Running shell command: {args}\")\n        try:\n            logger.info(f\"Running shell command: {args}\")\n            result = subprocess.run(args, capture_output=True, text=True)\n            logger.debug(f\"Result: {result}\")\n            logger.debug(f\"Return code: {result.returncode}\")\n            if result.returncode != 0:\n                return f\"Error: {result.stderr}\"\n            # return only the last n lines of the output\n            return \"\\n\".join(result.stdout.split(\"\\n\")[-tail:])\n        except Exception as e:\n            logger.warning(f\"Failed to run shell command: {e}\")\n            return f\"Error: {e}\"\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nToolkits\nAirflow\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/tools/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nIntroduction\n\nTools are functions that an Agent can run like searching the web, running SQL, sending an email or calling APIs. Use tools integrate Agents with external systems. You can use any python function as a tool or use a pre-built toolkit. The general syntax is:\n\nfrom phi.agent import Agent\n\nagent = Agent(\n    # Add functions or Toolkits\n    tools=[...],\n    # Show tool calls in the Agent response\n    show_tool_calls=True\n)\n\n\nRead more about:\n\nAvailable Toolkits\nUsing functions as tools\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nNvidia\nFunctions\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Qdrant FastEmbed Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/qdrant_fastembed",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nQdrant FastEmbed Embedder\n\nThe FastEmbedEmbedder class is used to embed text data into vectors using the FastEmbed.\n\n​\nUsage\ncookbook/embedders/qdrant_fastembed.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.fastembed import FastEmbedEmbedder\n\nembeddings = FastEmbedEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"qdrant_embeddings\",\n        embedder=FastEmbedEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ndimensions\tint\t-\tThe dimensionality of the generated embeddings\nmodel\tstr\tBAAI/bge-small-en-v1.5\tThe name of the qdrant_fastembed model to use\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nHuggingFace\nSentenceTransformers\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "HuggingFace Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/huggingface",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nHuggingFace Embedder\n\nThe HuggingfaceCustomEmbedder class is used to embed text data into vectors using the Hugging Face API. You can get one from here.\n\n​\nUsage\ncookbook/embedders/huggingface_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.huggingface import HuggingfaceCustomEmbedder\n\nembeddings = HuggingfaceCustomEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"huggingface_embeddings\",\n        embedder=HuggingfaceCustomEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ndimensions\tint\t-\tThe dimensionality of the generated embeddings\nmodel\tstr\tall-MiniLM-L6-v2\tThe name of the HuggingFace model to use\napi_key\tstr\t-\tThe API key used for authenticating requests\nclient_params\tOptional[Dict[str, Any]]\t-\tOptional dictionary of parameters for the HuggingFace client\nhuggingface_client\tAny\t-\tOptional pre-configured HuggingFace client instance\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTogether\nQdrant FastEmbed\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Together Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/together",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nTogether Embedder\n\nThe TogetherEmbedder can be used to embed text data into vectors using the Together API. Together uses the OpenAI API specification, so the TogetherEmbedder class is similar to the OpenAIEmbedder class, incorporating adjustments to ensure compatibility with the Together platform. Get your key from here.\n\n​\nUsage\ncookbook/embedders/together_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.together import TogetherEmbedder\n\nembeddings = TogetherEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"together_embeddings\",\n        embedder=TogetherEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"nomic-ai/nomic-embed-text-v1.5\"\tThe name of the model used for generating embeddings.\ndimensions\tint\t768\tThe dimensionality of the embeddings generated by the model.\napi_key\tstr\t\tThe API key used for authenticating requests.\nbase_url\tstr\t\"https://api.Together.ai/inference/v1\"\tThe base URL for the API endpoint.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFireworks\nHuggingFace\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Fireworks Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/fireworks",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nFireworks Embedder\n\nThe FireworksEmbedder can be used to embed text data into vectors using the Fireworks API. Fireworks uses the OpenAI API specification, so the FireworksEmbedder class is similar to the OpenAIEmbedder class, incorporating adjustments to ensure compatibility with the Fireworks platform. Get your key from here.\n\n​\nUsage\ncookbook/embedders/fireworks_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.fireworks import FireworksEmbedder\n\nembeddings = FireworksEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"fireworks_embeddings\",\n        embedder=FireworksEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"nomic-ai/nomic-embed-text-v1.5\"\tThe name of the model used for generating embeddings.\ndimensions\tint\t768\tThe dimensionality of the embeddings generated by the model.\napi_key\tstr\t-\tThe API key used for authenticating requests.\nbase_url\tstr\t\"https://api.fireworks.ai/inference/v1\"\tThe base URL for the API endpoint.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nMistral\nTogether\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Mistral Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/mistral",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nMistral Embedder\n\nThe MistralEmbedder class is used to embed text data into vectors using the Mistral API. Get your key from here.\n\n​\nUsage\ncookbook/embedders/mistral_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.mistral import MistralEmbedder\n\nembeddings = MistralEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"mistral_embeddings\",\n        embedder=MistralEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"mistral-embed\"\tThe name of the model used for generating embeddings.\ndimensions\tint\t1024\tThe dimensionality of the embeddings generated by the model.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the API request. Optional.\napi_key\tstr\t-\tThe API key used for authenticating requests.\nendpoint\tstr\t-\tThe endpoint URL for the API requests.\nmax_retries\tOptional[int]\t-\tThe maximum number of retries for API requests. Optional.\ntimeout\tOptional[int]\t-\tThe timeout duration for API requests. Optional.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for configuring the API client. Optional.\nmistral_client\tOptional[MistralClient]\t-\tAn instance of the MistralClient to use for making API requests. Optional.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAzure OpenAI\nFireworks\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Azure OpenAI Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/azure_openai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nAzure OpenAI Embedder\n\nThe AzureOpenAIEmbedder class is used to embed text data into vectors using the Azure OpenAI API. Get your key from here.\n\n​\nUsage\ncookbook/embedders/azure_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.azure_openai import AzureOpenAIEmbedder\n\nembeddings = AzureOpenAIEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"azure_openai_embeddings\",\n        embedder=AzureOpenAIEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"text-embedding-ada-002\"\tThe name of the model used for generating embeddings.\ndimensions\tint\t1536\tThe dimensionality of the embeddings generated by the model.\nencoding_format\tLiteral['float', 'base64']\t\"float\"\tThe format in which the embeddings are encoded. Options are “float” or “base64”.\nuser\tstr\t-\tThe user associated with the API request.\napi_key\tstr\t-\tThe API key used for authenticating requests.\napi_version\tstr\t\"2024-02-01\"\tThe version of the API to use for the requests.\nazure_endpoint\tstr\t-\tThe Azure endpoint for the API requests.\nazure_deployment\tstr\t-\tThe Azure deployment name for the API requests.\nbase_url\tstr\t-\tThe base URL for the API endpoint.\nazure_ad_token\tstr\t-\tThe Azure Active Directory token for authentication.\nazure_ad_token_provider\tAny\t-\tThe provider for obtaining the Azure AD token.\norganization\tstr\t-\tThe organization associated with the API request.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the API request. Optional.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for configuring the API client. Optional.\nopenai_client\tOptional[AzureOpenAIClient]\t-\tAn instance of the AzureOpenAIClient to use for making API requests. Optional.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nVoyage AI\nMistral\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Voyage AI Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/voyageai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nVoyage AI Embedder\n\nThe VoyageAIEmbedder class is used to embed text data into vectors using the Voyage AI API. Get your key from here.\n\n​\nUsage\ncookbook/embedders/voyageai_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.voyageai import VoyageAIEmbedder\n\nembeddings = VoyageAIEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"voyageai_embeddings\",\n        embedder=VoyageAIEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"voyage-2\"\tThe name of the model used for generating embeddings.\ndimensions\tint\t1024\tThe dimensionality of the embeddings generated by the model.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the API request. Optional.\napi_key\tstr\t-\tThe API key used for authenticating requests.\nbase_url\tstr\t\"https://api.voyageai.com/v1/embeddings\"\tThe base URL for the API endpoint.\nmax_retries\tOptional[int]\t-\tThe maximum number of retries for API requests. Optional.\ntimeout\tOptional[float]\t-\tThe timeout duration for API requests. Optional.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for configuring the API client. Optional.\nvoyage_client\tOptional[Client]\t-\tAn instance of the Client to use for making API requests. Optional.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOllama\nAzure OpenAI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Ollama Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/ollama",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nOllama Embedder\n\nThe OllamaEmbedder can be used to embed text data into vectors locally using Ollama.\n\nThe model used for generating embeddings needs to run locally.\n​\nUsage\ncookbook/embedders/ollama_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.ollama import OllamaEmbedder\n\nembeddings = OllamaEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"ollama_embeddings\",\n        embedder=OllamaEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"openhermes\"\tThe name of the model used for generating embeddings.\ndimensions\tint\t4096\tThe dimensionality of the embeddings generated by the model.\nhost\tstr\t-\tThe host address for the API endpoint.\ntimeout\tAny\t-\tThe timeout duration for API requests.\noptions\tAny\t-\tAdditional options for configuring the API request.\nclient_kwargs\tOptional[Dict[str, Any]]\t-\tAdditional keyword arguments for configuring the API client. Optional.\nollama_client\tOptional[OllamaClient]\t-\tAn instance of the OllamaClient to use for making API requests. Optional.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGemini\nVoyage AI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Gemini Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/gemini",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nGemini Embedder\n\nThe GeminiEmbedder class is used to embed text data into vectors using the Gemini API. You can get one from here.\n\n​\nUsage\ncookbook/embedders/gemini_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.google import GeminiEmbedder\n\nembeddings = GeminiEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"gemini_embeddings\",\n        embedder=GeminiEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ndimensions\tint\t768\tThe dimensionality of the generated embeddings\nmodel\tstr\tmodels/text-embedding-004\tThe name of the Gemini model to use\ntask_type\tstr\t-\tThe type of task for which embeddings are being generated\ntitle\tstr\t-\tOptional title for the embedding task\napi_key\tstr\t-\tThe API key used for authenticating requests.\nrequest_params\tOptional[Dict[str, Any]]\t-\tOptional dictionary of parameters for the embedding request\nclient_params\tOptional[Dict[str, Any]]\t-\tOptional dictionary of parameters for the Gemini client\ngemini_client\tOptional[Client]\t-\tOptional pre-configured Gemini client instance\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenAI\nOllama\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "OpenAI Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/openai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nOpenAI Embedder\n\nPhidata uses OpenAIEmbedder as the default embeder for the vector database. The OpenAIEmbedder class is used to embed text data into vectors using the OpenAI API. Get your key from here.\n\n​\nUsage\ncookbook/embedders/openai_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.openai import OpenAIEmbedder\n\nembeddings = OpenAIEmbedder().get_embedding(\"Embed me\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"openai_embeddings\",\n        embedder=OpenAIEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\nmodel\tstr\t\"text-embedding-ada-002\"\tThe name of the model used for generating embeddings.\ndimensions\tint\t1536\tThe dimensionality of the embeddings generated by the model.\nencoding_format\tLiteral['float', 'base64']\t\"float\"\tThe format in which the embeddings are encoded. Options are “float” or “base64”.\nuser\tstr\t-\tThe user associated with the API request.\napi_key\tstr\t-\tThe API key used for authenticating requests.\norganization\tstr\t-\tThe organization associated with the API request.\nbase_url\tstr\t-\tThe base URL for the API endpoint.\nrequest_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters to include in the API request.\nclient_params\tOptional[Dict[str, Any]]\t-\tAdditional parameters for configuring the API client.\nopenai_client\tOptional[OpenAIClient]\t-\tAn instance of the OpenAIClient to use for making API requests.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nGemini\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/embedder/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nIntroduction\n\nAn Embedder converts complex information into vector representations, allowing it to be stored in a vector database. By transforming data into embeddings, the embedder enables efficient searching and retrieval of contextually relevant information. This process enhances the responses of language models by providing them with the necessary business context, ensuring they are context-aware. Phidata uses OpenAIEmbedder as the default embedder, but other embedders are supported as well. Here is an example:\n\nfrom phi.agent import Agent, AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.openai import OpenAIEmbedder\n\n# Create knowledge base\nknowledge_base=AgentKnowledge(\n    vector_db=PgVector(\n        db_url=db_url,\n        table_name=embeddings_table,\n        embedder=OpenAIEmbedder(),\n    ),\n    # 2 references are added to the prompt\n    num_documents=2,\n),\n\n# Add information to the knowledge base\nknowledge_base.load_text(\"The sky is blue\")\n\n# Add the knowledge base to the Agent\nagent = Agent(knowledge_base=knowledge_base)\n\n\nThe following embedders are supported:\n\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDynamoDB\nOpenAI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Investment Team - Phidata",
    "url": "https://docs.phidata.com/examples/teams/investment",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nResearch Team\nJournalist Team\nInvestment Team\nHackernews Team\nUse Cases\nHow To\nClone Cookbook\nAgent Teams\nInvestment Team\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nJournalist Team\nHackernews Team\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Journalist Team - Phidata",
    "url": "https://docs.phidata.com/examples/teams/journalist",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nResearch Team\nJournalist Team\nInvestment Team\nHackernews Team\nUse Cases\nHow To\nClone Cookbook\nAgent Teams\nJournalist Team\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nResearch Team\nInvestment Team\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Sambanova - Phidata",
    "url": "https://docs.phidata.com/reference/model/sambanova",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nSambanova\nagent.py\nfrom phi.agent import Agent\nfrom phi.model.sambanova import Sambanova\n\nagent = Agent(model=Sambanova(), markdown=True)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story\")\n\n\n​\nSambanova Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"Meta-Llama-3.1-8B-Instruct\"\tThe id of the Sambanova model to use\nname\tstr\t\"Sambanova\"\tThe name of this chat model instance\nprovider\tstr\t\"Sambanova\"\tThe provider of the model\napi_key\tOptional[str]\tNone\tThe API key for authenticating with Sambanova (defaults to environment variable SAMBANOVA_API_KEY)\nbase_url\tstr\t\"https://api.sambanova.ai/v1\"\tThe base URL for API requests\n​\nModel Params\n\nSambanova is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenRouter\nPostgreSQL\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSambanova Params\nModel Params"
  },
  {
    "title": "OpenRouter - Phidata",
    "url": "https://docs.phidata.com/reference/model/openrouter",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nOpenRouter\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.openrouter import OpenRouter\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=OpenRouter(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response in the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nOpenRouter Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"gpt-4o\"\tThe model id\nname\tstr\t\"OpenRouter\"\tThe model name\nprovider\tstr\t\"OpenRouter: \" + id\tThe provider name\napi_key\tOptional[str]\tNone\tThe API key (defaults to environment variable OPENROUTER_API_KEY)\nbase_url\tstr\t\"https://openrouter.ai/api/v1\"\tThe base URL for API requests\nmax_tokens\tint\t1024\tThe maximum number of tokens\n​\nModel Params\n\nOpenRouter is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDeepSeek\nSambanova\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nOpenRouter Params\nModel Params"
  },
  {
    "title": "DeepSeek - Phidata",
    "url": "https://docs.phidata.com/reference/model/deepseek",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nDeepSeek\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.deepseek import DeepSeekChat\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=DeepSeekChat(api_key=\"\"), # enter your api key\n    tools=[\n        YFinanceTools(\n            company_info=True,\n            stock_fundamentals=True,\n        )\n    ],\n    show_tool_calls=True,\n    debug_mode=True,\n    markdown=True,\n)\n\n# Print the response on the terminal\nagent.print_response(\"Give me in-depth analysis of NVDA and TSLA\")\n\n\n​\nDeepSeek Params\nParameter\tType\tDefault\tDescription\nname\tstr\t\"DeepSeekChat\"\tName of the DeepSeek model\nid\tstr\t\"deepseek-chat\"\tThe specific model ID to use from DeepSeek\nprovider\tstr\t\"DeepSeek\"\tThe provider of the model\napi_key\tOptional[str]\tNone\tDeepSeek API key (defaults to DEEPSEEK_API_KEY environment variable)\nbase_url\tstr\t\"https://api.deepseek.com\"\tThe base URL for DeepSeek API\n​\nModel Params\n\nDeepSeek is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCohere\nOpenRouter\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nDeepSeek Params\nModel Params"
  },
  {
    "title": "Cohere - Phidata",
    "url": "https://docs.phidata.com/reference/model/cohere",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nCohere\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.cohere import CohereChat\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=CohereChat(id=\"command-r-08-2024\"),\n    tools=[\n        YFinanceTools(\n            company_info=True,\n            stock_fundamentals=True,\n        )\n    ],\n    show_tool_calls=True,\n    debug_mode=True,\n    markdown=True,\n)\n\n# Print the response on the terminal\nagent.print_response(\"Give me in-depth analysis of NVDA and TSLA\")\n\n\n​\nCohere Params\nParameter\tType\tDefault\tDescription\nname\tstr\t\"cohere\"\tName of the Cohere model\nid\tstr\t\"command-r-plus\"\tThe specific model ID to use from Cohere\nprovider\tstr\t\"Cohere\"\tThe provider of the model\ntemperature\tOptional[float]\tNone\tControls randomness in output generation\nmax_tokens\tOptional[int]\tNone\tMaximum number of tokens to generate\ntop_k\tOptional[int]\tNone\tLimits token selection to top K options\ntop_p\tOptional[float]\tNone\tNucleus sampling threshold\nfrequency_penalty\tOptional[float]\tNone\tPenalizes frequent tokens\npresence_penalty\tOptional[float]\tNone\tPenalizes repeated tokens\nrequest_params\tOptional[Dict[str, Any]]\tNone\tAdditional request parameters\nadd_chat_history\tbool\tFalse\tWhether to add chat history to Cohere messages\napi_key\tOptional[str]\tNone\tCohere API key\nclient_params\tOptional[Dict[str, Any]]\tNone\tAdditional client parameters\ncohere_client\tOptional[CohereClient]\tNone\tManually provided Cohere client\n​\nModel Params\n\nCohere is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nClaude\nDeepSeek\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nCohere Params\nModel Params"
  },
  {
    "title": "Claude - Phidata",
    "url": "https://docs.phidata.com/reference/model/claude",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nClaude\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.anthropic import Claude\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response in the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nClaude Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"claude-3-5-sonnet-20240620\"\tThe id of the Anthropic Claude model to use\nname\tstr\t\"Claude\"\tThe name of the model\nprovider\tstr\t\"Anthropic\"\tThe provider of the model\nmax_tokens\tOptional[int]\t1024\tMaximum number of tokens to generate in the chat completion\ntemperature\tOptional[float]\tNone\tControls randomness in the model’s output\nstop_sequences\tOptional[List[str]]\tNone\tA list of strings that the model should stop generating text at\ntop_p\tOptional[float]\tNone\tControls diversity via nucleus sampling\ntop_k\tOptional[int]\tNone\tControls diversity via top-k sampling\nrequest_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters to include in the request\napi_key\tOptional[str]\tNone\tThe API key for authenticating with Anthropic\nclient_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters for client configuration\nclient\tOptional[AnthropicClient]\tNone\tA pre-configured instance of the Anthropic client\n​\nModel Params\n\nClaude is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAzure\nCohere\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nClaude Params\nModel Params"
  },
  {
    "title": "Azure - Phidata",
    "url": "https://docs.phidata.com/reference/model/azure",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nAzure\n​\nExample\n​\nAzure Params\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tThe model name to use.\nname\tstr\t\"AzureOpenAIChat\"\tThe name of the Azure OpenAI Chat model.\nprovider\tstr\t\"Azure\"\tThe provider to use.\napi_key\tOptional[str]\tgetenv(\"AZURE_OPENAI_API_KEY\")\tThe API key for Azure OpenAI.\napi_version\tstr\tgetenv(\"AZURE_OPENAI_API_VERSION\", \"2024-02-01\")\tThe API version to use for Azure OpenAI.\nazure_endpoint\tOptional[str]\tgetenv(\"AZURE_OPENAI_ENDPOINT\")\tThe Azure endpoint to use.\nazure_deployment\tOptional[str]\tgetenv(\"AZURE_DEPLOYMENT\")\tThe Azure deployment name for the model.\nbase_url\tOptional[str]\tNone\tThe base URL for the Azure OpenAI API.\nazure_ad_token\tOptional[str]\tNone\tThe Azure AD token for authentication.\nazure_ad_token_provider\tOptional[Any]\tNone\tThe Azure AD token provider to use.\norganization\tOptional[str]\tNone\tThe organization to use.\nopenai_client\tOptional[AzureOpenAIClient]\tNone\tAn instance of AzureOpenAIClient, if already created.\n​\nModel Params\n\nAzure is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGemini\nClaude\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nAzure Params\nModel Params"
  },
  {
    "title": "Gemini - Phidata",
    "url": "https://docs.phidata.com/reference/model/gemini",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nGemini\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.google import Gemini\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Gemini(id=\"gemini-1.5-flash\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response in the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nGemini Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"gemini-1.5-flash\"\tThe specific Gemini model ID to use.\nname\tstr\t\"Gemini\"\tThe name of this Gemini model instance.\nprovider\tstr\t\"Google\"\tThe provider of the model.\nfunction_declarations\tOptional[List[FunctionDeclaration]]\tNone\tList of function declarations for the model.\ngeneration_config\tOptional[Any]\tNone\tConfiguration for text generation.\nsafety_settings\tOptional[Any]\tNone\tSafety settings for the model.\ngenerative_model_kwargs\tOptional[Dict[str, Any]]\tNone\tAdditional keyword arguments for the generative model.\napi_key\tOptional[str]\tNone\tAPI key for authentication.\nclient_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters for the client.\nclient\tOptional[GenerativeModel]\tNone\tThe underlying generative model client.\n​\nModel Params\n\nGemini is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGroq\nAzure\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nGemini Params\nModel Params"
  },
  {
    "title": "Groq - Phidata",
    "url": "https://docs.phidata.com/reference/model/groq",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nGroq\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.groq import Groq\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Groq(id=\"llama3-groq-70b-8192-tool-use-preview\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response on the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nGroq Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"llama3-groq-70b-8192-tool-use-preview\"\tThe model ID to use\nname\tstr\t\"Groq\"\tThe name of the Groq model instance\nprovider\tstr\t\"Groq\"\tThe provider of the model\nfrequency_penalty\tOptional[float]\tNone\tNumber between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model’s likelihood to repeat the same line verbatim.\nlogit_bias\tOptional[Any]\tNone\tModify the likelihood of specified tokens appearing in the completion.\nlogprobs\tOptional[bool]\tNone\tWhether to return log probabilities of the output tokens.\nmax_tokens\tOptional[int]\tNone\tThe maximum number of tokens to generate in the chat completion.\npresence_penalty\tOptional[float]\tNone\tNumber between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model’s likelihood to talk about new topics.\nresponse_format\tOptional[Dict[str, Any]]\tNone\tAn object specifying the format that the model must output.\nseed\tOptional[int]\tNone\tIf specified, the system will make a best effort to sample deterministically.\nstop\tOptional[Union[str, List[str]]]\tNone\tUp to 4 sequences where the API will stop generating further tokens.\ntemperature\tOptional[float]\tNone\tWhat sampling temperature to use, between 0 and 2. Higher values make the output more random, while lower values make it more focused and deterministic.\ntop_logprobs\tOptional[int]\tNone\tThe number of most likely tokens to return at each token position, along with their log probabilities.\ntop_p\tOptional[float]\tNone\tAn alternative to sampling with temperature, called nucleus sampling.\nuser\tOptional[str]\tNone\tA unique identifier representing your end-user, which can help to monitor and detect abuse.\nextra_headers\tOptional[Any]\tNone\tAdditional headers to send with the request.\nextra_query\tOptional[Any]\tNone\tAdditional query parameters to send with the request.\nrequest_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters to include in the request.\napi_key\tOptional[str]\tNone\tAPI key for Groq\nbase_url\tOptional[Union[str, httpx.URL]]\tNone\tBase URL for the Groq API\ntimeout\tOptional[int]\tNone\tTimeout for API requests in seconds\nmax_retries\tOptional[int]\tNone\tMaximum number of retries for API requests\ndefault_headers\tOptional[Any]\tNone\tDefault headers to send with every request\ndefault_query\tOptional[Any]\tNone\tDefault query parameters to send with every request\nclient_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters for configuring the client\ngroq_client\tOptional[GroqClient]\tNone\tCustom Groq client, if provided\n​\nModel Params\n\nGroq is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nMistral\nGemini\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nGroq Params\nModel Params"
  },
  {
    "title": "Mistral - Phidata",
    "url": "https://docs.phidata.com/reference/model/mistral",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nMistral\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nimport os\n\nfrom phi.agent import Agent\nfrom phi.model.mistral import MistralChat\nfrom phi.tools.yfinance import YFinanceTools\n\nmistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n\nagent = Agent(\n    model=MistralChat(\n        id=\"mistral-large-latest\",\n        api_key=mistral_api_key,\n    ),\n    tools=[\n        YFinanceTools(\n            company_info=True,\n            stock_fundamentals=True,\n        )\n    ],\n    show_tool_calls=True,\n    debug_mode=True,\n    markdown=True,\n)\n\n# Print the response on the terminal\nagent.print_response(\"Give me in-depth analysis of NVDA and TSLA\")\n\n\n​\nMistral Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"mistral-large-latest\"\tThe ID of the model.\nname\tstr\t\"MistralChat\"\tThe name of the model.\nprovider\tstr\t\"Mistral\"\tThe provider of the model.\ntemperature\tOptional[float]\tNone\tControls randomness in output generation.\nmax_tokens\tOptional[int]\tNone\tMaximum number of tokens to generate.\ntop_p\tOptional[float]\tNone\tControls diversity of output generation.\nrandom_seed\tOptional[int]\tNone\tSeed for random number generation.\nsafe_mode\tbool\tFalse\tEnables content filtering.\nsafe_prompt\tbool\tFalse\tApplies content filtering to prompts.\nresponse_format\tOptional[Union[Dict[str, Any], ChatCompletionResponse]]\tNone\tSpecifies the desired response format.\nrequest_params\tOptional[Dict[str, Any]]\tNone\tAdditional request parameters.\napi_key\tOptional[str]\tNone\tYour Mistral API key.\nendpoint\tOptional[str]\tNone\tCustom API endpoint URL.\nmax_retries\tOptional[int]\tNone\tMaximum number of API call retries.\ntimeout\tOptional[int]\tNone\tTimeout for API calls in seconds.\nclient_params\tOptional[Dict[str, Any]]\tNone\tAdditional client parameters.\nmistral_client\tOptional[Mistral]\tNone\tCustom Mistral client instance.\n​\nModel Params\n\nMistral is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFireworks\nGroq\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nMistral Params\nModel Params"
  },
  {
    "title": "Fireworks - Phidata",
    "url": "https://docs.phidata.com/reference/model/fireworks",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nFireworks\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.fireworks import Fireworks\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Fireworks(id=\"accounts/fireworks/models/firefunction-v2\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response in the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nFireworks Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"accounts/fireworks/models/firefunction-v2\"\tThe model ID to use\nname\tstr\t\"Fireworks: \" + id\tThe name of the Fireworks LLM instance\nprovider\tstr\t\"Fireworks\"\tThe provider of the model\napi_key\tOptional[str]\tNone\tYour Fireworks API key (defaults to FIREWORKS_API_KEY environment variable)\nbase_url\tstr\t\"https://api.fireworks.ai/inference/v1\"\tThe base URL for Fireworks API\n​\nModel Params\n\nFireworks is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOllama\nMistral\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nFireworks Params\nModel Params"
  },
  {
    "title": "Ollama - Phidata",
    "url": "https://docs.phidata.com/reference/model/ollama",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nOllama\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.ollama import Ollama\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Ollama(id=\"llama3.2\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response in the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nOllama Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"llama3.2\"\tThe ID of the model to use.\nname\tstr\t\"Ollama\"\tThe name of the model.\nprovider\tstr\t\"Ollama llama3.2\"\tThe provider of the model.\nformat\tOptional[str]\tNone\tThe format of the response.\noptions\tOptional[Any]\tNone\tAdditional options to pass to the model.\nkeep_alive\tOptional[Union[float, str]]\tNone\tThe keep alive time for the model.\nrequest_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters to pass to the request.\nhost\tOptional[str]\tNone\tThe host to connect to.\ntimeout\tOptional[Any]\tNone\tThe timeout for the connection.\nclient_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters to pass to the client.\nclient\tOptional[OllamaClient]\tNone\tA pre-configured instance of the Ollama client.\nasync_client\tOptional[AsyncOllamaClient]\tNone\tA pre-configured instance of the asynchronous Ollama client.\n​\nModel Params\n\nOllama is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTogether\nFireworks\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nOllama Params\nModel Params"
  },
  {
    "title": "Together - Phidata",
    "url": "https://docs.phidata.com/reference/model/together",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nTogether\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.together import Together\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Together(id=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response on the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nTogether Params\nParameter\tType\tDefault\tDescription\nid\tstr\t\"mistralai/Mixtral-8x7B-Instruct-v0.1\"\tThe id of the Together model to use.\nname\tstr\t\"Together\"\tThe name of this chat model instance.\nprovider\tstr\t\"Together \" + id\tThe provider of the model.\napi_key\tOptional[str]\tNone\tThe API key to authorize requests to Together. Defaults to environment variable TOGETHER_API_KEY.\nbase_url\tstr\t\"https://api.together.xyz/v1\"\tThe base URL for API requests.\nmonkey_patch\tbool\tFalse\tWhether to apply monkey patching.\n​\nModel Params\n\nTogether is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAWS Bedrock\nOllama\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nTogether Params\nModel Params"
  },
  {
    "title": "Aws Bedrock - Phidata",
    "url": "https://docs.phidata.com/reference/model/aws",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nAws Bedrock\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.aws.claude import Claude\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=Claude(id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n    debug_mode=True,\n)\n\n# Print the response in the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n​\nAWS Bedrock Params\nParameter\tType\tDefault\tDescription\nname\tstr\t\"AwsBedrock\"\tName of the AWS Bedrock model\nmodel\tstr\t\"anthropic.claude-v2\"\tThe specific model to use from AWS Bedrock\naws_region\tOptional[str]\tNone\tThe AWS region to use\naws_profile\tOptional[str]\tNone\tThe AWS profile to use\naws_client\tOptional[AwsApiClient]\tNone\tThe AWS client to use\nrequest_params\tOptional[Dict[str, Any]]\tNone\tThe request parameters to use\n​\nModel Params\n\nAwsBedrock is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenAI\nTogether\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAWS Bedrock Params\nModel Params"
  },
  {
    "title": "OpenAI - Phidata",
    "url": "https://docs.phidata.com/reference/model/openai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nOpenAI\n​\nExample\nagent.py\n\"\"\"Run `pip install yfinance` to install dependencies.\"\"\"\n\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Print the response in the terminal\nagent.print_response(\"What is the stock price of NVDA and TSLA\")\n\n\n​\nOpenAI Params\nName\tType\tDefault\tDescription\nid\tstr\t\"gpt-4o\"\tThe id of the OpenAI model to use.\nname\tstr\t\"OpenAIChat\"\tThe name of this chat model instance.\nprovider\tstr\t\"OpenAI \" + id\tThe provider of the model.\nstore\tOptional[bool]\tNone\tWhether or not to store the output of this chat completion request for use in the model distillation or evals products.\nfrequency_penalty\tOptional[float]\tNone\tPenalizes new tokens based on their frequency in the text so far.\nlogit_bias\tOptional[Any]\tNone\tModifies the likelihood of specified tokens appearing in the completion.\nlogprobs\tOptional[bool]\tNone\tInclude the log probabilities on the logprobs most likely tokens.\nmax_tokens\tOptional[int]\tNone\tThe maximum number of tokens to generate in the chat completion.\npresence_penalty\tOptional[float]\tNone\tPenalizes new tokens based on whether they appear in the text so far.\nresponse_format\tOptional[Any]\tNone\tAn object specifying the format that the model must output.\nseed\tOptional[int]\tNone\tA seed for deterministic sampling.\nstop\tOptional[Union[str, List[str]]]\tNone\tUp to 4 sequences where the API will stop generating further tokens.\ntemperature\tOptional[float]\tNone\tControls randomness in the model's output.\ntop_logprobs\tOptional[int]\tNone\tHow many log probability results to return per token.\nuser\tOptional[str]\tNone\tA unique identifier representing your end-user.\ntop_p\tOptional[float]\tNone\tControls diversity via nucleus sampling.\nextra_headers\tOptional[Any]\tNone\tAdditional headers to send with the request.\nextra_query\tOptional[Any]\tNone\tAdditional query parameters to send with the request.\nrequest_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters to include in the request.\napi_key\tOptional[str]\tNone\tThe API key for authenticating with OpenAI.\norganization\tOptional[str]\tNone\tThe organization to use for API requests.\nbase_url\tOptional[Union[str, httpx.URL]]\tNone\tThe base URL for API requests.\ntimeout\tOptional[float]\tNone\tThe timeout for API requests.\nmax_retries\tOptional[int]\tNone\tThe maximum number of retries for failed requests.\ndefault_headers\tOptional[Any]\tNone\tDefault headers to include in all requests.\ndefault_query\tOptional[Any]\tNone\tDefault query parameters to include in all requests.\nhttp_client\tOptional[httpx.Client]\tNone\tAn optional pre-configured HTTP client.\nclient_params\tOptional[Dict[str, Any]]\tNone\tAdditional parameters for client configuration.\nclient\tOptional[OpenAIClient]\tNone\tThe OpenAI client instance.\nasync_client\tOptional[AsyncOpenAIClient]\tNone\tThe asynchronous OpenAI client instance.\nstructured_outputs\tbool\tFalse\tWhether to use the structured outputs from the Model.\nsupports_structured_outputs\tbool\tTrue\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tTrue\tWhether to add images to the message content.\n\nFor more information, please refer to the OpenAI docs as well.\n\n​\nModel Params\n\nOpenAIChat is a subclass of the Model class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nBase\nAWS Bedrock\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nOpenAI Params\nModel Params"
  },
  {
    "title": "Research Team - Phidata",
    "url": "https://docs.phidata.com/examples/teams/research",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nResearch Team\nJournalist Team\nInvestment Team\nHackernews Team\nUse Cases\nHow To\nClone Cookbook\nAgent Teams\nResearch Team\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPortkey\nJournalist Team\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/models/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nIntroduction\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nDeepSeek\nSambanova\nAWS Bedrock Claude\nTogether\nFireworks\nMistral\nGemini - AI Studio\nxAI\nAzure\nHuggingFace\nOpenRouter\nNvidia\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nModels\nIntroduction\n\nLanguage Models are machine-learning programs that are trained to understand natural language and code. They provide reasoning and planning capabilities to Agents.\n\nUse any model with an Agent like:\n\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"Share 15 minute healthy recipes.\",\n    markdown=True,\n)\nagent.print_response(\"Share a breakfast recipe.\", stream=True)\n\n\nPhidata supports the following model providers:\n\nOpenAI\nAnthropic\nCohere\nOllama\nGroq\nOpenAI Like\nAWS Bedrock\nTogether\nFireworks\nMistral\nGemini - AI Studio\nAzure\nDeepSeek\nSambanova\nOpenRouter\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTeams\nOpenAI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Functions - Phidata",
    "url": "https://docs.phidata.com/tools/functions",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nFunctions\n\nAny python function can be used as a tool by an Agent. We highly recommend creating functions specific to your workflow and adding them to your Agents.\n\nFor example, here’s how to use a get_top_hackernews_stories function as a tool:\n\nhn_agent.py\nimport json\nimport httpx\n\nfrom phi.agent import Agent\n\n\ndef get_top_hackernews_stories(num_stories: int = 10) -> str:\n    \"\"\"Use this function to get top stories from Hacker News.\n\n    Args:\n        num_stories (int): Number of stories to return. Defaults to 10.\n\n    Returns:\n        str: JSON string of top stories.\n    \"\"\"\n\n    # Fetch top story IDs\n    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n    story_ids = response.json()\n\n    # Fetch story details\n    stories = []\n    for story_id in story_ids[:num_stories]:\n        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')\n        story = story_response.json()\n        if \"text\" in story:\n            story.pop(\"text\", None)\n        stories.append(story)\n    return json.dumps(stories)\n\nagent = Agent(tools=[get_top_hackernews_stories], show_tool_calls=True, markdown=True)\nagent.print_response(\"Summarize the top 5 stories on hackernews?\", stream=True)\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nToolkits\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Toolkits - Phidata",
    "url": "https://docs.phidata.com/tools/toolkits",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nIntroduction\nFunctions\nToolkits\nWriting your own Toolkit\nAirflow\nApify\nArxiv\nAWS Lambda\nCalculator\nComposio\nCrawl4AI\nCSV\nDalle\nDuckDb\nDuckDuckGo\nEmail\nExa\nFile\nFirecrawl\nGithub\nGoogle Search\nHacker News\nJina Reader\nJira\nMLX Transcribe\nModelsLabs\nNewspaper\nNewspaper4k\nOpenBB\nPandas\nPhi\nPostgres\nPubmed\nPython\nResend\nSearxng\nSerpapi\nShell\nSlack\nSleep\nSpider\nSQL\nTavily\nTwitter\nWebsite\nWikipedia\nYfinance\nYoutube\nZendesk\nZoom\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nTools\nToolkits\n\nA Toolkit is a collection of functions that can be added to an Agent. The functions in a Toolkit are designed to work together, share internal state and provide a better development experience.\n\nThe following Toolkits are available to use\n\nApify\n\nTools to use Apify Actors.\n\nArxiv\n\nTools to read arXiv papers.\n\nCalculator\n\nTools to perform calculations.\n\nComposio\n\nTools to compose complex workflows.\n\nCrawl4AI\n\nTools to crawl web data.\n\nCSV\n\nTools to work with CSV files.\n\nDuckDb\n\nTools to run SQL using DuckDb.\n\nDuckDuckGo\n\nTools to search the web using DuckDuckGo.\n\nEmail\n\nTools to send emails.\n\nExa\n\nTools to search the web using Exa.\n\nFile\n\nTools to read and write files.\n\nFirecrawl\n\nTools to crawl the web using Firecrawl.\n\nGitHub\n\nTools to interact with GitHub.\n\nGoogle Search\n\nTools to search Google.\n\nHackerNews\n\nTools to read Hacker News articles.\n\nJina Reader\n\nTools for neural search and AI services using Jina.\n\nJira\n\nTools to interact with Jira.\n\nNewspaper\n\nTools to read news articles.\n\nNewspaper4k\n\nTools to read articles using Newspaper4k.\n\nOpenBB\n\nTools to search for stock data using OpenBB.\n\nPandas\n\nTools to manipulate data using Pandas.\n\nPostgres\n\nTools to interact with PostgreSQL databases.\n\nPubmed\n\nTools to search Pubmed.\n\nPython\n\nTools to write and run Python code.\n\nResend\n\nTools to send emails using Resend.\n\nSearxNG\n\nTools to search the web using SearxNG.\n\nSerpapi\n\nTools to search Google, YouTube, and more using Serpapi.\n\nShell\n\nTools to run shell commands.\n\nSpider\n\nTools to crawl websites.\n\nSQL\n\nTools to run SQL queries.\n\nTavily\n\nTools to search the web using Tavily.\n\nWebsite\n\nTools to scrape websites.\n\nWikipedia\n\nTools to search Wikipedia.\n\nYFinance\n\nTools to search Yahoo Finance.\n\nYouTube\n\nTools to search YouTube.\n\nZendesk\n\nTools to search Zendesk.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFunctions\nWriting your own Toolkit\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "SentenceTransformers Embedder - Phidata",
    "url": "https://docs.phidata.com/embedder/sentencetransformers",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nIntroduction\nOpenAI\nGemini\nOllama\nVoyage AI\nAzure OpenAI\nMistral\nFireworks\nTogether\nHuggingFace\nQdrant FastEmbed\nSentenceTransformers\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nEmbeddings\nSentenceTransformers Embedder\n\nThe SentenceTransformerEmbedder class is used to embed text data into vectors using the SentenceTransformers library.\n\n​\nUsage\ncookbook/embedders/sentence_transformer_embedder.py\nfrom phi.agent import AgentKnowledge\nfrom phi.vectordb.pgvector import PgVector\nfrom phi.embedder.sentence_transformer import SentenceTransformerEmbedder\n\nembeddings = SentenceTransformerEmbedder().get_embedding(\"The quick brown fox jumps over the lazy dog.\")\n\n# Print the embeddings and their dimensions\nprint(f\"Embeddings: {embeddings[:5]}\")\nprint(f\"Dimensions: {len(embeddings)}\")\n\n# Example usage:\nknowledge_base = AgentKnowledge(\n    vector_db=PgVector(\n        db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\",\n        table_name=\"sentence_transformer_embeddings\",\n        embedder=SentenceTransformerEmbedder(),\n    ),\n    num_documents=2,\n)\n\n​\nParams\nParameter\tType\tDefault\tDescription\ndimensions\tint\t-\tThe dimensionality of the generated embeddings\nmodel\tstr\tall-mpnet-base-v2\tThe name of the SentenceTransformers model to use\nsentence_transformer_client\tOptional[Client]\t-\tOptional pre-configured SentenceTransformers client instance\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nQdrant FastEmbed\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nParams"
  },
  {
    "title": "Hackernews Team - Phidata",
    "url": "https://docs.phidata.com/examples/teams/hackernews",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nResearch Team\nJournalist Team\nInvestment Team\nHackernews Team\nUse Cases\nHow To\nClone Cookbook\nAgent Teams\nHackernews Team\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nInvestment Team\nSql Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Model Base - Phidata",
    "url": "https://docs.phidata.com/reference/model/base",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nBase\nOpenAI\nAWS Bedrock\nTogether\nOllama\nFireworks\nMistral\nGroq\nGemini\nAzure\nClaude\nCohere\nDeepSeek\nOpenRouter\nSambanova\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nModels\nModel Base\n​\nBase Params\nParameter\tType\tDefault\tDescription\nid\tstr\t-\tID of the model to use. Alias: \"model\"\nname\tOptional[str]\tNone\tName for this Model. Not sent to the Model API.\nprovider\tOptional[str]\tNone\tProvider for this Model. Not sent to the Model API.\nmetrics\tDict[str, Any]\t{}\tMetrics collected for this Model. Not sent to the Model API.\nresponse_format\tOptional[Any]\tNone\tFormat of the response.\ntools\tOptional[List[Union[Tool, Dict]]]\tNone\tA list of tools provided to the Model.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) function is called by the model.\nrun_tools\tbool\tTrue\tIf True, runs the tool before sending back the response content.\nshow_tool_calls\tOptional[bool]\tNone\tIf True, shows function calls in the response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\nfunctions\tOptional[Dict[str, Function]]\tNone\tFunctions extracted from the tools. Not sent to the Model API.\nfunction_call_stack\tOptional[List[FunctionCall]]\tNone\tFunction call stack.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt from the model added to the Agent.\ninstructions\tOptional[List[str]]\tNone\tInstructions from the model added to the Agent.\nsession_id\tOptional[str]\tNone\tSession ID of the calling Agent or Workflow.\nstructured_outputs\tOptional[bool]\tNone\tWhether to use the structured outputs with this Model.\nsupports_structured_outputs\tbool\tFalse\tWhether the Model supports structured outputs.\nadd_images_to_message_content\tbool\tFalse\tWhether to add images to the message content.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDuckDb\nOpenAI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nBase Params"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  },
  {
    "title": "RDS - Phidata",
    "url": "https://docs.phidata.com/templates/resources/aws/rds",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nAWS\nECS\nRDS\nAWS\nRDS\n\nThis guide is in the works\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nECS\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  },
  {
    "title": "Portkey - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/portkey",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nPortkey\n\nEnhance your Phidata agents with Portkey for reliability, efficiency, and advanced features\n\n​\nPortkey Integration with Phidata\n\nPortkey is a 2-line upgrade to make your Phidata agents reliable, cost-efficient, and fast.\n\nPortkey adds 4 core production capabilities to any Phidata agent:\n\nRouting to 200+ LLMs\nMaking each LLM call more robust\nFull-stack tracing & cost, performance analytics\nReal-time guardrails to enforce behavior\n​\nGetting Started\nInstall Required Packages:\npip install phidata portkey-ai\n\nConfigure Phidata with Portkey:\nfrom phi.llm.openai import OpenAIChat\nfrom portkey_ai import PORTKEY_GATEWAY_URL, createHeaders\n\nllm = OpenAIChat(\n     base_url=PORTKEY_GATEWAY_URL,\n     api_key=\"OPENAI_API_KEY\", #Replace with Your OpenAI Key\n     default_headers=createHeaders(\n         provider=\"openai\",\n         api_key=PORTKEY_API_KEY  # Replace with your Portkey API key\n     )\n )\n\n\nGenerate your API key in the Portkey Dashboard.\n\nAnd, that’s it! With just this, you can start logging all of your Phidata requests and make them reliable.\n\nLet’s Run your Agent\nfrom phi.agent import Agent\n\nagent = Agent(\n    llm=llm,\n    description=\"You help people with their health and fitness goals.\",\n    instructions=[\"Recipes should be under 5 ingredients\"],\n)\n# -*- Print a response to the client\nagent.print_response(\"Share a breakfast recipe.\", markdown=True)\n\n\nHere’s the output from your Agent’s run on Portkey’s dashboard.\n\n​\nKey Features\n\nPortkey offers a range of advanced features to enhance your Phidata agents. Here’s an overview:\n\nFeature\tDescription\n🌐 Multi-LLM Integration\tAccess 200+ LLMs with simple configuration changes\n🛡️ Enhanced Reliability\tImplement fallbacks, load balancing, retries, and much more\n📊 Advanced Metrics\tTrack costs, tokens, latency, and 40+ custom metrics effortlessly\n🔍 Detailed Traces and Logs\tGain insights into every agent action and decision\n🚧 Guardrails\tEnforce agent behavior with real-time checks on inputs and outputs\n🔄 Continuous Optimization\tCapture user feedback for ongoing agent improvements\n💾 Smart Caching\tReduce costs and latency with built-in caching mechanisms\n🔐 Enterprise-Grade Security\tSet budget limits and implement fine-grained access controls\n​\nColab Notebook\n\nFor a hands-on example of integrating Portkey with Phidata, check out our notebook:\n\n​\nAdvanced Features\n​\nInteroperability\n\nEasily switch between 200+ LLMs by changing the provider and API key in your configuration.\n\n​\nExample: Switching from OpenAI to Azure OpenAI\nconfig = [\n    {\n        \"api_key\": \"api-key\",\n        \"model\": \"gpt-3.5-turbo\",\n        \"base_url\": PORTKEY_GATEWAY_URL,\n        \"api_type\": \"openai\",\n        \"default_headers\": createHeaders(\n            api_key=\"YOUR_PORTKEY_API_KEY\",\n            provider=\"azure-openai\",\n            virtual_key=\"AZURE_VIRTUAL_KEY\"\n        )\n    }\n]\n\n​\nReliability\n\nImplement fallbacks, load balancing, and automatic retries to make your agents more resilient.\n\nportkey_config = {\n  \"retry\": {\n    \"attempts\": 5\n  },\n  \"strategy\": {\n    \"mode\": \"loadbalance\"  # Options: \"loadbalance\" or \"fallback\"\n  },\n  \"targets\": [\n    {\n      \"provider\": \"openai\",\n      \"api_key\": \"OpenAI_API_Key\"\n    },\n    {\n      \"provider\": \"anthropic\",\n      \"api_key\": \"Anthropic_API_Key\"\n    }\n  ]\n}\n\n​\nMetrics\n\nAgent runs are complex. Portkey automatically logs 40+ comprehensive metrics for your AI agents, including cost, tokens used, latency, etc. Whether you need a broad overview or granular insights into your agent runs, Portkey’s customizable filters provide the metrics you need.\n\nPortkey's Observability Dashboard\n\n​\nComprehensive Logging\n\nAccess detailed logs and traces of agent activities, function calls, and errors. Filter logs based on multiple parameters for in-depth analysis.\n\nTraces\n\nLogs\n\n​\nGuardrails\n\nPhidata agents, while powerful, can sometimes produce unexpected or undesired outputs. Portkey’s Guardrails feature helps enforce agent behavior in real-time, ensuring your Phidata agents operate within specified parameters. Verify both the inputs to and outputs from your agents to ensure they adhere to specified formats and content guidelines.\n\nLearn more about Portkey’s Guardrails here.\n\n​\nContinuous Improvement\n\nCapture qualitative and quantitative user feedback on your requests to continuously enhance your agent performance.\n\n​\nCaching\n\nReduce costs and latency with Portkey’s built-in caching system.\n\nportkey_config = {\n \"cache\": {\n    \"mode\": \"semantic\"  # Options: \"simple\" or \"semantic\"\n }\n}\n\n​\nSecurity and Compliance\n\nSet budget limits on provider API keys and implement fine-grained user roles and permissions for both your application and the Portkey APIs.\n\n​\nAdditional Resources\n📘 Portkey Documentation\n🐦 Twitter\n💬 Discord Community\n📊 Portkey App\n\nFor more information on using these features and setting up your Config, please refer to the Portkey documentation.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nChromaDB\nResearch Team\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nPortkey Integration with Phidata\nGetting Started\nKey Features\nColab Notebook\nAdvanced Features\nInteroperability\nExample: Switching from OpenAI to Azure OpenAI\nReliability\nMetrics\nComprehensive Logging\nGuardrails\nContinuous Improvement\nCaching\nSecurity and Compliance\nAdditional Resources"
  },
  {
    "title": "ECS - Phidata",
    "url": "https://docs.phidata.com/templates/resources/aws/ecs",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nAWS\nECS\nRDS\nAWS\nECS\n\nThis guide is in the works\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAWS\nRDS\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Container - Phidata",
    "url": "https://docs.phidata.com/templates/resources/docker/container",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nDocker\nContainer\nAWS\nDocker\nContainer\n\nThis guide is in the works\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDocker\nAWS\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "ChromaDB Integration - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/chroma",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nChromaDB Integration\n​\nExample\nimport typer\nfrom rich.prompt import Prompt\nfrom typing import Optional\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.chroma import ChromaDb\n\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=ChromaDb(collection=\"recipes\"),\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=False)\n\n\ndef pdf_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        use_tools=True,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(pdf_agent)\n\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U chromadb pypdf openai phidata\n\n3\n\nRun ChromaDB Agent\n\nMac\nWindows\npython cookbook/integrations/chromadb/agent.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nQdrant\nPortkey\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Qdrant Integration - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/qdrant",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nQdrant Integration\n​\nExample\nimport os\nimport typer\nfrom typing import Optional\nfrom rich.prompt import Prompt\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.qdrant import Qdrant\n\napi_key = os.getenv(\"QDRANT_API_KEY\")\nqdrant_url = os.getenv(\"QDRANT_URL\")\ncollection_name = \"thai-recipe-index\"\n\nvector_db = Qdrant(\n    collection=collection_name,\n    url=qdrant_url,\n    api_key=api_key,\n)\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db,\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=True, upsert=True)\n\n\ndef qdrant_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge_base=knowledge_base,\n        tool_calls=True,\n        use_tools=True,\n        show_tool_calls=True,\n        debug_mode=True,\n        # Uncomment the following line to use traditional RAG\n        # add_references_to_prompt=True,\n    )\n\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(qdrant_agent)\n\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U qdrant-client pypdf openai phidata\n\n3\n\nRun Qdrant Agent\n\nMac\nWindows\npython cookbook/integrations/qdrant/agent.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPinecone\nChromaDB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Pinecone Integration - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/pinecone",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nPinecone Integration\n​\nExample\nimport os\nimport typer\nfrom typing import Optional\nfrom rich.prompt import Prompt\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pineconedb import PineconeDB\n\napi_key = os.getenv(\"PINECONE_API_KEY\")\nindex_name = \"thai-recipe-hybrid-search\"\n\nvector_db = PineconeDB(\n    name=index_name,\n    dimension=1536,\n    metric=\"cosine\",\n    spec={\"serverless\": {\"cloud\": \"aws\", \"region\": \"us-east-1\"}},\n    api_key=api_key,\n    use_hybrid_search=True,\n    hybrid_alpha=0.5,\n)\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db,\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=True, upsert=True)\n\n\ndef pinecone_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge=knowledge_base,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(pinecone_agent)\n\n\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U pinecone pypdf openai phidata\n\n3\n\nRun Pinecone Agent\n\nMac\nWindows\npython cookbook/integrations/pinecone/agent.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nLanceDB\nQdrant\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "LanceDB Integration - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/lancedb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nLanceDB Integration\n​\nExample\nimport typer\nfrom typing import Optional\nfrom rich.prompt import Prompt\n\nfrom phi.agent import Agent\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb\nfrom phi.vectordb.search import SearchType\n\n# LanceDB Vector DB\nvector_db = LanceDb(\n    table_name=\"recipes\",\n    uri=\"/tmp/lancedb\",\n    search_type=SearchType.keyword,\n)\n\n# Knowledge Base\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=vector_db,\n)\n\n# Comment out after first run\nknowledge_base.load(recreate=True)\n\n\ndef lancedb_agent(user: str = \"user\"):\n    run_id: Optional[str] = None\n\n    agent = Agent(\n        run_id=run_id,\n        user_id=user,\n        knowledge=knowledge_base,\n        show_tool_calls=True,\n        debug_mode=True,\n    )\n\n    if run_id is None:\n        run_id = agent.run_id\n        print(f\"Started Run: {run_id}\\n\")\n    else:\n        print(f\"Continuing Run: {run_id}\\n\")\n\n    while True:\n        message = Prompt.ask(f\"[bold] :sunglasses: {user} [/bold]\")\n        if message in (\"exit\", \"bye\"):\n            break\n        agent.print_response(message)\n\n\nif __name__ == \"__main__\":\n    typer.run(lancedb_agent)\n\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U lancedb pypdf pandas openai phidata\n\n3\n\nRun LanceDB Agent\n\nMac\nWindows\npython cookbook/integrations/lancedb/agent.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSingleStore\nPinecone\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "SingleStore - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/singlestore",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nSingleStore\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPgVector\nLanceDB\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Composio - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/composio",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nComposio\n\nComposioTools enables an Agent to work with sofware tools like Gmail, Salesforce, Github, etc.\n\n​\nExample\n\nThe following agent will use Github Tool from Composio Toolkit to star a repo.\n\nRun the following commands to setup the agent\npip install composio-phidata\ncomposio add github # Launches GitHub login in browser\n\nfrom phi.agent import Agent\nfrom composio_phidata import Action, ComposioToolSet\n\n\ntoolset = ComposioToolSet()\ncomposio_tools = toolset.get_tools(\n  actions=[Action.GITHUB_STAR_A_REPOSITORY_FOR_THE_AUTHENTICATED_USER]\n) # get starring action for Github\n\nagent = Agent(tools=composio_tools, show_tool_calls=True)\n\nagent.print_response(\"Can you star phidatahq/phidata repo?\")\n\n​\nToolkit Params\n\nThe following parameters are used when calling the GitHub star repository action:\n\nParameter\tType\tDefault\tDescription\nowner\tstr\t-\tThe owner of the repository to star.\nrepo\tstr\t-\tThe name of the repository to star.\n​\nToolkit Functions\n\nComposio Toolkit provides 1000+ functions to connect to different software tools. Open this link to view the complete list of functions.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nxAI\nPgVector\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nToolkit Params\nToolkit Functions"
  },
  {
    "title": "Teams - Phidata",
    "url": "https://docs.phidata.com/agents/teams",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nTeams\n\nWe can combine multiple Agents to form a team and tackle tasks as a cohesive unit. Here’s a simple example that uses a team of agents to write an article about the top stories on hackernews.\n\nhn_team.py\nfrom phi.agent import Agent\nfrom phi.tools.hackernews import HackerNews\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.newspaper4k import Newspaper4k\n\nhn_researcher = Agent(\n    name=\"HackerNews Researcher\",\n    role=\"Gets top stories from hackernews.\",\n    tools=[HackerNews()],\n)\n\nweb_searcher = Agent(\n    name=\"Web Searcher\",\n    role=\"Searches the web for information on a topic\",\n    tools=[DuckDuckGo()],\n    add_datetime_to_instructions=True,\n)\n\narticle_reader = Agent(\n    name=\"Article Reader\",\n    role=\"Reads articles from URLs.\",\n    tools=[Newspaper4k()],\n)\n\nhn_team = Agent(\n    name=\"Hackernews Team\",\n    team=[hn_researcher, web_searcher, article_reader],\n    instructions=[\n        \"First, search hackernews for what the user is asking about.\",\n        \"Then, ask the article reader to read the links for the stories to get more information.\",\n        \"Important: you must provide the article reader with the links to read.\",\n        \"Then, ask the web searcher to search for each story to get more information.\",\n        \"Finally, provide a thoughtful and engaging summary.\",\n    ],\n    show_tool_calls=True,\n    markdown=True,\n)\nhn_team.print_response(\"Write an article about the top 2 stories on hackernews\", stream=True)\n\n\nRun the script to see the output.\n\npip install -U openai duckduckgo-search newspaper4k lxml_html_clean phidata\n\npython hn_team.py\n\n​\nHow to build Agent Teams\nAdd a name and role parameter to the member Agents.\nCreate a Team Leader that can delegate tasks to team-members.\nUse your Agent team just like you would use a regular Agent.\n\nOpen-ended Agentic teams are great to play with, but are not reliable for real-world problems that require high reliability.\n\nThey need constant oversight and can get confused on very complex tasks. This drawback should improve as models get better (eagerly waiting for gpt-5o).\n\nIn our experience, Agent teams work best for simple tasks that require a small number of steps. We highly recommend using Workflows for production applications.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nReasoning\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nHow to build Agent Teams"
  },
  {
    "title": "Reasoning - Phidata",
    "url": "https://docs.phidata.com/agents/reasoning",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nReasoning\n\nReasoning is an experimental feature that enables an Agent to think through a problem step-by-step before jumping into a response. The Agent works through different ideas, validating and correcting as needed. Once it reaches a final answer, it will validate and provide a response. Let’s give it a try. Create a file reasoning_agent.py\n\nreasoning_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = (\n    \"Three missionaries and three cannibals need to cross a river. \"\n    \"They have a boat that can carry up to two people at a time. \"\n    \"If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. \"\n    \"How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram\"\n)\n\nreasoning_agent = Agent(model=OpenAIChat(id=\"gpt-4o\"), reasoning=True, markdown=True, structured_outputs=True)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n\nRun the Reasoning Agent:\n\npip install -U phidata openai\n\nexport OPENAI_API_KEY=***\n\npython reasoning_agent.py\n\n\nReasoning is currently limited to OpenAI models and will break about 20% of the time. It is not a replacement for o1.\n\nIt is an experiment fueled by curiosity, combining COT and tool use. Set your expectations very low for this initial release. For example: It will not be able to count ‘r’s in ‘strawberry’.\n\n​\nHow to use reasoning\n\nTo add reasoning, set reasoning=True. When using reasoning with tools, do not use structured_outputs=True as gpt-4o cannot use tools with structured outputs.\n\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    reasoning=True,\n    markdown=True,\n    structured_outputs=True,\n)\nreasoning_agent.print_response(\"How many 'r' are in the word 'supercalifragilisticexpialidocious'?\", stream=True, show_full_reasoning=True)\n\n​\nReasoning with tools\n\nYou can also use tools with a reasoning agent, but do not use structured_outputs=True as gpt-4o cannot use tools with structured outputs. Lets create a finance agent that can reason.\n\nReasoning with tools is currently limited to OpenAI models and will break about 20% of the time.\n\nfinance_reasoning.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to show data\"],\n    show_tool_calls=True,\n    markdown=True,\n    reasoning=True,\n)\nreasoning_agent.print_response(\"Write a report comparing NVDA to TSLA\", stream=True, show_full_reasoning=True)\n\n\nRun the script to see the output.\n\npip install -U phidata openai yfinance\n\nexport OPENAI_API_KEY=***\n\npython finance_reasoning.py\n\n​\nMore reasoning examples\n​\nLogical puzzles\nlogical_puzzle.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = (\n    \"Three missionaries and three cannibals need to cross a river. \"\n    \"They have a boat that can carry up to two people at a time. \"\n    \"If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. \"\n    \"How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram\"\n)\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"), reasoning=True, markdown=True, structured_outputs=True\n)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n\nRun the script to see the output.\n\npip install -U phidata openai\n\nexport OPENAI_API_KEY=***\n\npython logical_puzzle.py\n\n​\nMathematical proofs\nmathematical_proof.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = \"Prove that for any positive integer n, the sum of the first n odd numbers is equal to n squared. Provide a detailed proof.\"\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"), reasoning=True, markdown=True, structured_outputs=True\n)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n\nRun the script to see the output.\n\npip install -U phidata openai\n\nexport OPENAI_API_KEY=***\n\npython mathematical_proof.py\n\n​\nScientific research\nscientific_research.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = (\n    \"Read the following abstract of a scientific paper and provide a critical evaluation of its methodology,\"\n    \"results, conclusions, and any potential biases or flaws:\\n\\n\"\n    \"Abstract: This study examines the effect of a new teaching method on student performance in mathematics. \"\n    \"A sample of 30 students was selected from a single school and taught using the new method over one semester. \"\n    \"The results showed a 15% increase in test scores compared to the previous semester. \"\n    \"The study concludes that the new teaching method is effective in improving mathematical performance among high school students.\"\n)\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"), reasoning=True, markdown=True, structured_outputs=True\n)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n\nRun the script to see the output.\n\npip install -U phidata openai\n\nexport OPENAI_API_KEY=***\n\npython scientific_research.py\n\n​\nEthical dilemma\nethical_dilemma.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = (\n    \"You are a train conductor faced with an emergency: the brakes have failed, and the train is heading towards \"\n    \"five people tied on the track. You can divert the train onto another track, but there is one person tied there. \"\n    \"Do you divert the train, sacrificing one to save five? Provide a well-reasoned answer considering utilitarian \"\n    \"and deontological ethical frameworks. \"\n    \"Provide your answer also as an ascii art diagram.\"\n)\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"), reasoning=True, markdown=True, structured_outputs=True\n)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n\nRun the script to see the output.\n\npip install -U phidata openai\n\nexport OPENAI_API_KEY=***\n\npython ethical_dilemma.py\n\n​\nPlanning an itinerary\nplanning_itinerary.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = \"Plan an itinerary from Los Angeles to Las Vegas\"\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"), reasoning=True, markdown=True, structured_outputs=True\n)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n\nRun the script to see the output.\n\npip install -U phidata openai\n\nexport OPENAI_API_KEY=***\n\npython planning_itinerary.py\n\n​\nCreative writing\ncreative_writing.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = \"Write a short story about life in 5000000 years\"\nreasoning_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"), reasoning=True, markdown=True, structured_outputs=True\n)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n\nRun the script to see the output.\n\npip install -U phidata openai\n\nexport OPENAI_API_KEY=***\n\npython creative_writing.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nStructured Output\nTeams\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nHow to use reasoning\nReasoning with tools\nMore reasoning examples\nLogical puzzles\nMathematical proofs\nScientific research\nEthical dilemma\nPlanning an itinerary\nCreative writing"
  },
  {
    "title": "Memory - Phidata",
    "url": "https://docs.phidata.com/agents/memory",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nMemory\n\nPhidata provides 3 types of memories for building a great Agent experience (AX):\n\nChat History: previous messages from the conversation, we recommend sending the last 3-5 messages to the model.\nUser Memories: notes and insights about the user, this helps the model personalize the response to the user.\nSummaries: a summary of the conversation, which is added to the prompt when chat history gets too long.\n\nBefore we dive in, let’s understand the terminology:\n\nSession: Each conversation with an Agent is called a session. Sessions are identified by a session_id.\nRun: Every interaction (i.e. chat) within a session is called a run. Runs are identified by a run_id.\nMessages: are the individual messages sent to and received from the model. They have a role (system, user or assistant) and content.\n\nSessions are equivalent to threads in the OpenAI Assistant API.\n\n​\nBuilt-in Memory\n\nEvery Agent comes with built-in memory that can be used to access the historical runs and messages. Access it using agent.memory\n\nShow AgentMemory\n\n​\nExample\nagent_memory.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom rich.pretty import pprint\n\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.\n    add_history_to_messages=True,\n    # Number of historical responses to add to the messages.\n    num_history_responses=3,\n    description=\"You are a helpful assistant that always responds in a polite, upbeat and positive manner.\",\n)\n\n# -*- Create a run\nagent.print_response(\"Share a 2 sentence horror story\", stream=True)\n# -*- Print the messages in the memory\npprint([m.model_dump(include={\"role\", \"content\"}) for m in agent.memory.messages])\n\n# -*- Ask a follow up question that continues the conversation\nagent.print_response(\"What was my first message?\", stream=True)\n# -*- Print the messages in the memory\npprint([m.model_dump(include={\"role\", \"content\"}) for m in agent.memory.messages])\n\n​\nPersistent Memory\n\nThe built-in memory only lasts while the session is active. To persist memory across sessions, we can store Agent sessions in a database using AgentStorage.\n\nStorage is a necessary component when building user facing AI products as any production application will require users to be able to “continue” their conversation with the Agent.\n\nLet’s test this out, create a file persistent_memory.py with the following code:\n\npersistent_memory.py\nimport json\n\nfrom rich.console import Console\nfrom rich.panel import Panel\nfrom rich.json import JSON\n\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.storage.agent.sqlite import SqlAgentStorage\n\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Store agent sessions in a database\n    storage=SqlAgentStorage(table_name=\"agent_sessions\", db_file=\"tmp/agent_storage.db\"),\n    # Set add_history_to_messages=true to add the previous chat history to the messages sent to the Model.\n    add_history_to_messages=True,\n    # Number of historical responses to add to the messages.\n    num_history_responses=3,\n    # The session_id is used to identify the session in the database\n    # You can resume any session by providing a session_id\n    # session_id=\"xxxx-xxxx-xxxx-xxxx\",\n    # Description creates a system prompt for the agent\n    description=\"You are a helpful assistant that always responds in a polite, upbeat and positive manner.\",\n)\n\nconsole = Console()\n\n\ndef print_chat_history(agent):\n    # -*- Print history\n    console.print(\n        Panel(\n            JSON(json.dumps([m.model_dump(include={\"role\", \"content\"}) for m in agent.memory.messages]), indent=4),\n            title=f\"Chat History for session_id: {agent.session_id}\",\n            expand=True,\n        )\n    )\n\n\n# -*- Create a run\nagent.print_response(\"Share a 2 sentence horror story\", stream=True)\n# -*- Print the chat history\nprint_chat_history(agent)\n\n# -*- Ask a follow up question that continues the conversation\nagent.print_response(\"What was my first message?\", stream=True)\n# -*- Print the chat history\nprint_chat_history(agent)\n\n​\nRun the agent\n\nInstall dependencies and run the agent:\n\npip install openai sqlalchemy phidata\n\npython persistent_memory.py\n\n\nYou can view the agent sessions in the sqlite database and continue any conversation by providing the same session_id.\n\nRead more in the storage section.\n\n​\nUser preferences and conversation summaries\n\nAlong with storing chat history and run messages, AgentMemory can be extended to automatically classify and store user preferences and conversation summaries.\n\nTo do this, add a db to AgentMemory and set create_user_memories=True and create_session_summary=True\n\nUser memories are stored in the AgentMemory whereas session summaries are stored in the AgentStorage table with the rest of the session information.\n\nUser preferences and conversation summaries are currently only compatible with OpenAI and OpenAILike models. While Persistent Memory is compatible with all model providers.\n\n​\nExample\npersonalized_memories_and_summaries.py\nfrom rich.pretty import pprint\n\nfrom phi.agent import Agent, AgentMemory\nfrom phi.model.openai import OpenAIChat\nfrom phi.memory.db.postgres import PgMemoryDb\nfrom phi.storage.agent.postgres import PgAgentStorage\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Store the memories and summary in a database\n    memory=AgentMemory(\n        db=PgMemoryDb(table_name=\"agent_memory\", db_url=db_url), create_user_memories=True, create_session_summary=True\n    ),\n    # Store agent sessions in a database\n    storage=PgAgentStorage(table_name=\"personalized_agent_sessions\", db_url=db_url),\n    # Show debug logs so you can see the memory being created\n    # debug_mode=True,\n)\n\n# -*- Share personal information\nagent.print_response(\"My name is john billings?\", stream=True)\n# -*- Print memories\npprint(agent.memory.memories)\n# -*- Print summary\npprint(agent.memory.summary)\n\n# -*- Share personal information\nagent.print_response(\"I live in nyc?\", stream=True)\n# -*- Print memories\npprint(agent.memory.memories)\n# -*- Print summary\npprint(agent.memory.summary)\n\n# -*- Share personal information\nagent.print_response(\"I'm going to a concert tomorrow?\", stream=True)\n# -*- Print memories\npprint(agent.memory.memories)\n# -*- Print summary\npprint(agent.memory.summary)\n\n# Ask about the conversation\nagent.print_response(\"What have we been talking about, do you know my name?\", stream=True)\n\n​\nAttributes\nParameter\tType\tDefault\tDescription\nmemory\tAgentMemory\tAgentMemory()\tAgent’s memory object used for storing and retrieving information.\nadd_history_to_messages\tbool\tFalse\tIf true, adds the chat history to the messages sent to the Model. Also known as add_chat_history_to_messages.\nnum_history_responses\tint\t3\tNumber of historical responses to add to the messages.\ncreate_user_memories\tbool\tFalse\tIf true, create and store personalized memories for the user.\nupdate_user_memories_after_run\tbool\tTrue\tIf true, update memories for the user after each run.\ncreate_session_summary\tbool\tFalse\tIf true, create and store session summaries.\nupdate_session_summary_after_run\tbool\tTrue\tIf true, update session summaries after each run.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nKnowledge\nStorage\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nBuilt-in Memory\nExample\nPersistent Memory\nRun the agent\nUser preferences and conversation summaries\nExample\nAttributes"
  },
  {
    "title": "Structured Output - Phidata",
    "url": "https://docs.phidata.com/agents/structured-output",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nStructured Output\n\nOne of our favorite features is using Agents to generate structured data (i.e. a pydantic model). Use this feature to extract features, classify data, produce fake data etc. The best part is that they work with function calls, knowledge bases and all other features.\n\n​\nExample\n\nLet’s create an Movie Agent to write a MovieScript for us.\n\nmovie_agent.py\nfrom typing import List\nfrom rich.pretty import pprint\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openai import OpenAIChat\n\n\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(\n        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n    )\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\n\n# Get the response in a variable\n# json_mode_response: RunResponse = json_mode_agent.run(\"New York\")\n# pprint(json_mode_response.content)\n# structured_output_response: RunResponse = structured_output_agent.run(\"New York\")\n# pprint(structured_output_response.content)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n\nRun the script to see the output.\n\npip install -U phidata openai\n\npython movie_agent.py\n\n\nThe output is an object of the MovieScript class, here’s how it looks:\n\n# Using JSON mode\nMovieScript(\n│   setting='The bustling streets of New York City, filled with skyscrapers, secret alleyways, and hidden underground passages.',\n│   ending='The protagonist manages to thwart an international conspiracy, clearing his name and winning the love of his life back.',\n│   genre='Thriller',\n│   name='Shadows in the City',\n│   characters=['Alex Monroe', 'Eva Parker', 'Detective Rodriguez', 'Mysterious Mr. Black'],\n│   storyline=\"When Alex Monroe, an ex-CIA operative, is framed for a crime he didn't commit, he must navigate the dangerous streets of New York to clear his name. As he uncovers a labyrinth of deceit involving the city's most notorious crime syndicate, he enlists the help of an old flame, Eva Parker. Together, they race against time to expose the true villain before it's too late.\"\n)\n\n# Use the structured output\nMovieScript(\n│   setting='In the bustling streets and iconic skyline of New York City.',\n│   ending='Isabella and Alex, having narrowly escaped the clutches of the Syndicate, find themselves standing at the top of the Empire State Building. As the glow of the setting sun bathes the city, they share a victorious kiss. Newly emboldened and as an unstoppable duo, they vow to keep NYC safe from any future threats.',\n│   genre='Action Thriller',\n│   name='The NYC Chronicles',\n│   characters=['Isabella Grant', 'Alex Chen', 'Marcus Kane', 'Detective Ellie Monroe', 'Victor Sinclair'],\n│   storyline='Isabella Grant, a fearless investigative journalist, uncovers a massive conspiracy involving a powerful syndicate plotting to control New York City. Teaming up with renegade cop Alex Chen, they must race against time to expose the culprits before the city descends into chaos. Dodging danger at every turn, they fight to protect the city they love from imminent destruction.'\n)\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nStorage\nReasoning\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample"
  },
  {
    "title": "Storage - Phidata",
    "url": "https://docs.phidata.com/agents/storage",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nStorage\n\nAgents use storage to persist sessions by storing them in a database..\n\nAgents come with built-in memory but it only lasts while the session is active. To continue conversations across sessions, we store Agent sessions in a database like PostgreSQL.\n\nThe general syntax for adding storage to an Agent looks like:\n\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.storage.agent.postgres import PgAgentStorage\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    storage=PgAgentStorage(table_name=\"agent_sessions\", db_url=\"postgresql+psycopg://ai:ai@localhost:5532/ai\"),\n    tools=[DuckDuckGo()],\n    show_tool_calls=True,\n    add_history_to_messages=True,\n)\nagent.print_response(\"How many people live in Canada?\")\nagent.print_response(\"What is their national anthem called?\")\nagent.print_response(\"Which country are we speaking about?\")\n\n​\nExample\n1\n\nRun Postgres\n\nInstall docker desktop and run Postgres on port 5532 using:\n\ndocker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\n2\n\nCreate an Agent with Storage\n\nCreate a file agent_with_storage.py with the following contents\n\nimport typer\nfrom typing import Optional, List\nfrom phi.agent import Agent\nfrom phi.storage.agent.postgres import PgAgentStorage\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector, SearchType\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url, search_type=SearchType.hybrid),\n)\n# Load the knowledge base: Comment after first run\nknowledge_base.load(upsert=True)\nstorage = PgAgentStorage(table_name=\"pdf_agent\", db_url=db_url)\n\ndef pdf_agent(new: bool = False, user: str = \"user\"):\n    session_id: Optional[str] = None\n\n    if not new:\n        existing_sessions: List[str] = storage.get_all_session_ids(user)\n        if len(existing_sessions) > 0:\n            session_id = existing_sessions[0]\n\n    agent = Agent(\n        session_id=session_id,\n        user_id=user,\n        knowledge=knowledge_base,\n        storage=storage,\n        # Show tool calls in the response\n        show_tool_calls=True,\n        # Enable the agent to read the chat history\n        read_chat_history=True,\n        # We can also automatically add the chat history to the messages sent to the model\n        # But giving the model the chat history is not always useful, so we give it a tool instead\n        # to only use when needed.\n        # add_history_to_messages=True,\n        # Number of historical responses to add to the messages.\n        # num_history_responses=3,\n    )\n    if session_id is None:\n        session_id = agent.session_id\n        print(f\"Started Session: {session_id}\\n\")\n    else:\n        print(f\"Continuing Session: {session_id}\\n\")\n\n    # Runs the agent as a cli app\n    agent.cli_app(markdown=True)\n\n\nif __name__ == \"__main__\":\n    typer.run(pdf_agent)\n\n3\n\nRun the agent\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai pgvector pypdf \"psycopg[binary]\" sqlalchemy\n\n\nRun the agent\n\npython agent_with_storage.py\n\n\nNow the agent continues across sessions. Ask a question:\n\nHow do I make pad thai?\n\n\nThen message bye to exit, start the app again and ask:\n\nWhat was my last message?\n\n4\n\nStart a new run\n\nRun the agent_with_storage.py file with the --new flag to start a new run.\n\npython agent_with_storage.py --new\n\n​\nParams\nParameter\tType\tDefault\tDescription\nstorage\tOptional[AgentStorage]\tNone\tStorage mechanism for the agent, if applicable.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nMemory\nStructured Output\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nParams"
  },
  {
    "title": "Knowledge - Phidata",
    "url": "https://docs.phidata.com/agents/knowledge",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nKnowledge\n\nAgents use knowledge to supplement their training data with domain expertise.\n\nKnowledge is stored in a vector database and provides agents with business context at query time, helping them respond in a context-aware manner. The general syntax is:\n\nfrom phi.agent import Agent, AgentKnowledge\n\n# Create a knowledge base for the Agent\nknowledge_base = AgentKnowledge(vector_db=...)\n\n# Add information to the knowledge base\nknowledge_base.load_text(\"The sky is blue\")\n\n# Add the knowledge base to the Agent and\n# give it a tool to search the knowledge base as needed\nagent = Agent(knowledge=knowledge_base, search_knowledge=True)\n\n​\nVector Databases\n\nWhile any type of storage can act as a knowledge base, vector databases offer the best solution for retrieving relevant results from dense information quickly. Here’s how vector databases are used with Agents:\n\n1\n\nChunk the information\n\nBreak down the knowledge into smaller chunks to ensure our search query returns only relevant results.\n\n2\n\nLoad the knowledge base\n\nConvert the chunks into embedding vectors and store them in a vector database.\n\n3\n\nSearch the knowledge base\n\nWhen the user sends a message, we convert the input message into an embedding and “search” for nearest neighbors in the vector database.\n\n​\nExample: RAG Agent with a PDF Knowledge Base\n\nLet’s build a RAG Agent that answers questions from a PDF.\n\n​\nStep 1: Run PgVector\n\nLet’s use PgVector as our vector db as it can also provide storage for our Agents.\n\nInstall docker desktop and run PgVector on port 5532 using:\n\ndocker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\n​\nStep 2: Traditional RAG\n\nRetrieval Augmented Generation (RAG) means “stuffing the prompt with relevant information” to improve the model’s response. This is a 2 step process:\n\nRetrieve relevant information from the knowledge base.\nAugment the prompt to provide context to the model.\n\nLet’s build a traditional RAG Agent that answers questions from a PDF of recipes.\n\n1\n\nInstall libraries\n\nInstall the required libraries using pip\n\nMac\nWindows\npip install -U pgvector pypdf \"psycopg[binary]\" sqlalchemy\n\n2\n\nCreate a Traditional RAG Agent\n\nCreate a file traditional_rag.py with the following contents\n\ntraditional_rag.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector, SearchType\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\nknowledge_base = PDFUrlKnowledgeBase(\n    # Read PDF from this URL\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Store embeddings in the `ai.recipes` table\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url, search_type=SearchType.hybrid),\n)\n# Load the knowledge base: Comment after first run\nknowledge_base.load(upsert=True)\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    knowledge=knowledge_base,\n    # Enable RAG by adding references from AgentKnowledge to the user prompt.\n    add_context=True,\n    # Set as False because Agents default to `search_knowledge=True`\n    search_knowledge=False,\n    markdown=True,\n    # debug_mode=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\")\n\n3\n\nRun the agent\n\nRun the agent (it takes a few seconds to load the knowledge base).\n\nMac\nWindows\npython traditional_rag.py\n\n\n\n\nHow to use local PDFs\n\n​\nStep 3: Agentic RAG\n\nWith traditional RAG above, add_context=True always adds information from the knowledge base to the prompt, regardless of whether it is relevant to the question or helpful.\n\nWith Agentic RAG, we let the Agent decide if it needs to access the knowledge base and what search parameters it needs to query the knowledge base.\n\nSet search_knowledge=True and read_chat_history=True, giving the Agent tools to search its knowledge and chat history on demand.\n\n1\n\nCreate an Agentic RAG Agent\n\nCreate a file agentic_rag.py with the following contents\n\nagentic_rag.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector, SearchType\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url, search_type=SearchType.hybrid),\n)\n# Load the knowledge base: Comment out after first run\nknowledge_base.load(upsert=True)\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    knowledge=knowledge_base,\n    # Add a tool to search the knowledge base which enables agentic RAG.\n    search_knowledge=True,\n    # Add a tool to read chat history.\n    read_chat_history=True,\n    show_tool_calls=True,\n    markdown=True,\n    # debug_mode=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\nagent.print_response(\"What was my last question?\", markdown=True)\n\n2\n\nRun the agent\n\nRun the agent\n\nMac\nWindows\npython agentic_rag.py\n\n\nNotice how it searches the knowledge base and chat history when needed\n\n​\nAttributes\nParameter\tType\tDefault\tDescription\nknowledge\tAgentKnowledge\tNone\tProvides the knowledge base used by the agent.\nsearch_knowledge\tbool\tTrue\tAdds a tool that allows the Model to search the knowledge base (aka Agentic RAG). Enabled by default when knowledge is provided.\nadd_context\tbool\tFalse\tEnable RAG by adding references from AgentKnowledge to the user prompt.\nretriever\tCallable[..., Optional[list[dict]]]\tNone\tFunction to get context to add to the user message. This function is called when add_context is True.\ncontext_format\tLiteral['json', 'yaml']\tjson\tSpecifies the format for RAG, either “json” or “yaml”.\nadd_context_instructions\tbool\tFalse\tIf True, add instructions for using the context to the system prompt (if knowledge is also provided). For example: add an instruction to prefer information from the knowledge base over its training data.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTools\nMemory\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nVector Databases\nExample: RAG Agent with a PDF Knowledge Base\nStep 1: Run PgVector\nStep 2: Traditional RAG\nStep 3: Agentic RAG\nAttributes"
  },
  {
    "title": "Tools - Phidata",
    "url": "https://docs.phidata.com/agents/tools",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nTools\n\nAgents use tools to take actions and interact with external systems.\n\nTools are functions that an Agent can run to achieve tasks. For example: searching the web, running SQL, sending an email or calling APIs. You can use any python function as a tool or use a pre-built toolkit. The general syntax is:\n\nfrom phi.agent import Agent\n\nagent = Agent(\n    # Add functions or Toolkits\n    tools=[...],\n    # Show tool calls in the Agent response\n    show_tool_calls=True\n)\n\n​\nUsing a Toolkit\n\nPhidata provides many pre-built toolkits that you can add to your Agents. For example, let’s use the DuckDuckGo toolkit to search the web.\n\nYou can find more toolkits in the Toolkits guide.\n1\n\nCreate Web Search Agent\n\nCreate a file web_search.py\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nagent = Agent(tools=[DuckDuckGo()], show_tool_calls=True, markdown=True)\nagent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install openai duckduckgo-search phidata\n\n\nRun the agent\n\npython web_search.py\n\n​\nWriting your own Tools\n\nFor more control, write your own python functions and add them as tools to an Agent. For example, here’s how to add a get_top_hackernews_stories tool to an Agent.\n\nhn_agent.py\nimport json\nimport httpx\n\nfrom phi.agent import Agent\n\n\ndef get_top_hackernews_stories(num_stories: int = 10) -> str:\n    \"\"\"Use this function to get top stories from Hacker News.\n\n    Args:\n        num_stories (int): Number of stories to return. Defaults to 10.\n\n    Returns:\n        str: JSON string of top stories.\n    \"\"\"\n\n    # Fetch top story IDs\n    response = httpx.get('https://hacker-news.firebaseio.com/v0/topstories.json')\n    story_ids = response.json()\n\n    # Fetch story details\n    stories = []\n    for story_id in story_ids[:num_stories]:\n        story_response = httpx.get(f'https://hacker-news.firebaseio.com/v0/item/{story_id}.json')\n        story = story_response.json()\n        if \"text\" in story:\n            story.pop(\"text\", None)\n        stories.append(story)\n    return json.dumps(stories)\n\nagent = Agent(tools=[get_top_hackernews_stories], show_tool_calls=True, markdown=True)\nagent.print_response(\"Summarize the top 5 stories on hackernews?\", stream=True)\n\n\nRead more about:\n\nAvailable toolkits\nUsing functions as tools\n​\nAttributes\n\nThe following attributes allow an Agent to use tools\n\nParameter\tType\tDefault\tDescription\ntools\tList[Union[Tool, Toolkit, Callable, Dict, Function]]\t-\tA list of tools provided to the Model. Tools are functions the model may generate JSON inputs for.\nshow_tool_calls\tbool\tFalse\tPrint the signature of the tool calls in the Model response.\ntool_call_limit\tint\t-\tMaximum number of tool calls allowed.\ntool_choice\tUnion[str, Dict[str, Any]]\t-\tControls which (if any) tool is called by the model. “none” means the model will not call a tool and instead generates a message. “auto” means the model can pick between generating a message or calling a tool. Specifying a particular function via {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}} forces the model to call that tool. “none” is the default when no tools are present. “auto” is the default if tools are present.\nread_chat_history\tbool\tFalse\tAdd a tool that allows the Model to read the chat history.\nsearch_knowledge\tbool\tFalse\tAdd a tool that allows the Model to search the knowledge base (aka Agentic RAG).\nupdate_knowledge\tbool\tFalse\tAdd a tool that allows the Model to update the knowledge base.\nread_tool_call_history\tbool\tFalse\tAdd a tool that allows the Model to get the tool call history.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPrompts\nKnowledge\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsing a Toolkit\nWriting your own Tools\nAttributes"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/workflows/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nIntroduction\nSession State\nStreaming\nAdvanced Example - News Report Generator\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nWorkflows\nIntroduction\n\nWorkflows are deterministic, stateful, multi-agent pipelines that power many of our production use cases. They are incredibly powerful and offer the following benefits:\n\nControl and Flexibility: You have full control over the multi-agent process, how the input is processed, which agents are used and in what order.\nBuilt-in Memory: You can store state and cache results in a database at any time, meaning your agents can re-use results from previous steps.\nDefined as a python class: You do not need to learn a new framework, its just python.\n\nHow to build a workflow:\n\nDefine your workflow as a class by inheriting from the Workflow class\nAdd one or more agents to the workflow\nImplement your logic in the run() method\nCache results in the session_state as needed\nRun the workflow using the .run() method\n​\nExample: Blog Post Generator\n\nLet’s create a blog post generator that can search the web, read the top links and write a blog post for us. We’ll cache intermediate results in the database to improve performance.\n\n​\nCreate the Workflow\n\nCreate a file blog_post_generator.py\n\nblog_post_generator.py\nimport json\nfrom typing import Optional, Iterator\n\nfrom pydantic import BaseModel, Field\n\nfrom phi.agent import Agent\nfrom phi.workflow import Workflow, RunResponse, RunEvent\nfrom phi.storage.workflow.sqlite import SqlWorkflowStorage\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.utils.pprint import pprint_run_response\nfrom phi.utils.log import logger\n\n\nclass NewsArticle(BaseModel):\n    title: str = Field(..., description=\"Title of the article.\")\n    url: str = Field(..., description=\"Link to the article.\")\n    summary: Optional[str] = Field(..., description=\"Summary of the article if available.\")\n\n\nclass SearchResults(BaseModel):\n    articles: list[NewsArticle]\n\n\nclass BlogPostGenerator(Workflow):\n    searcher: Agent = Agent(\n        tools=[DuckDuckGo()],\n        instructions=[\"Given a topic, search for 20 articles and return the 5 most relevant articles.\"],\n        response_model=SearchResults,\n    )\n\n    writer: Agent = Agent(\n        instructions=[\n            \"You will be provided with a topic and a list of top articles on that topic.\",\n            \"Carefully read each article and generate a New York Times worthy blog post on that topic.\",\n            \"Break the blog post into sections and provide key takeaways at the end.\",\n            \"Make sure the title is catchy and engaging.\",\n            \"Always provide sources, do not make up information or sources.\",\n        ],\n    )\n\n    def run(self, topic: str, use_cache: bool = True) -> Iterator[RunResponse]:\n        logger.info(f\"Generating a blog post on: {topic}\")\n\n        # Use the cached blog post if use_cache is True\n        if use_cache and \"blog_posts\" in self.session_state:\n            logger.info(\"Checking if cached blog post exists\")\n            for cached_blog_post in self.session_state[\"blog_posts\"]:\n                if cached_blog_post[\"topic\"] == topic:\n                    logger.info(\"Found cached blog post\")\n                    yield RunResponse(\n                        run_id=self.run_id,\n                        event=RunEvent.workflow_completed,\n                        content=cached_blog_post[\"blog_post\"],\n                    )\n                    return\n\n        # Step 1: Search the web for articles on the topic\n        num_tries = 0\n        search_results: Optional[SearchResults] = None\n        # Run until we get a valid search results\n        while search_results is None and num_tries < 3:\n            try:\n                num_tries += 1\n                searcher_response: RunResponse = self.searcher.run(topic)\n                if (\n                    searcher_response\n                    and searcher_response.content\n                    and isinstance(searcher_response.content, SearchResults)\n                ):\n                    logger.info(f\"Searcher found {len(searcher_response.content.articles)} articles.\")\n                    search_results = searcher_response.content\n                else:\n                    logger.warning(\"Searcher response invalid, trying again...\")\n            except Exception as e:\n                logger.warning(f\"Error running searcher: {e}\")\n\n        # If no search_results are found for the topic, end the workflow\n        if search_results is None or len(search_results.articles) == 0:\n            yield RunResponse(\n                run_id=self.run_id,\n                event=RunEvent.workflow_completed,\n                content=f\"Sorry, could not find any articles on the topic: {topic}\",\n            )\n            return\n\n        # Step 2: Write a blog post\n        logger.info(\"Writing blog post\")\n        # Prepare the input for the writer\n        writer_input = {\n            \"topic\": topic,\n            \"articles\": [v.model_dump() for v in search_results.articles],\n        }\n        # Run the writer and yield the response\n        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)\n\n        # Save the blog post in the session state for future runs\n        if \"blog_posts\" not in self.session_state:\n            self.session_state[\"blog_posts\"] = []\n        self.session_state[\"blog_posts\"].append({\"topic\": topic, \"blog_post\": self.writer.run_response.content})\n\n\n# The topic to generate a blog post on\ntopic = \"US Elections 2024\"\n\n# Create the workflow\ngenerate_blog_post = BlogPostGenerator(\n    session_id=f\"generate-blog-post-on-{topic}\",\n    storage=SqlWorkflowStorage(\n        table_name=\"generate_blog_post_workflows\",\n        db_file=\"tmp/workflows.db\",\n    ),\n)\n\n# Run workflow\nblog_post: Iterator[RunResponse] = generate_blog_post.run(topic=topic, use_cache=True)\n\n# Print the response\npprint_run_response(blog_post, markdown=True)\n\n​\nRun the workflow\n\nInstall libraries\n\npip install phidata openai duckduckgo-search sqlalchemy phidata\n\n\nRun the workflow\n\npython blog_post_generator.py\n\n\nNow the results are cached in the database and can be re-used for future runs. Run the workflow again to view the cached results.\n\npython blog_post_generator.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSentenceTransformers\nSession State\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample: Blog Post Generator\nCreate the Workflow\nRun the workflow"
  },
  {
    "title": "Prompts - Phidata",
    "url": "https://docs.phidata.com/agents/prompts",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nPrompts\n\nWe prompt Agents using description and instructions and a number of other settings. These settings are used to build the system prompt that is sent to the language model.\n\nUnderstanding how these prompts are created will help you build better Agents.\n\nThe 2 key parameters are:\n\nDescription: A description that guides the overall behaviour of the agent.\nInstructions: A list of precise, task-specific instructions on how to achieve its goal.\n\nDescription and instructions only provide a formatting benefit, we do not alter or abstract any information and you can always use system_prompt to provide your own system prompt.\n\n​\nSystem message\n\nThe system message is created using description, instructions and a number of other settings. The description is added to the start of the system message and instructions are added as a list after ## Instructions. For example:\n\ninstructions.py\nfrom phi.agent import Agent\n\nagent = Agent(\n    description=\"You are a famous short story writer asked to write for a magazine\",\n    instructions=[\"You are a pilot on a plane flying from Hawaii to Japan.\"],\n    markdown=True,\n    debug_mode=True,\n)\nagent.print_response(\"Tell me a 2 sentence horror story.\", stream=True)\n\n\nWill translate to (set debug_mode=True to view the logs):\n\nDEBUG    ============== system ==============\nDEBUG    You are a famous short story writer asked to write for a magazine\n\n         ## Instructions\n         - You are a pilot on a plane flying from Hawaii to Japan.\n         - Use markdown to format your answers.\nDEBUG    ============== user ==============\nDEBUG    Tell me a 2 sentence horror story.\nDEBUG    ============== assistant ==============\nDEBUG    As the autopilot disengaged inexplicably mid-flight over the Pacific, the pilot glanced at the copilot's seat\n         only to find it empty despite his every recall of a full crew boarding. Hands trembling, he looked into the\n         cockpit's rearview mirror and found his own reflection grinning back with blood-red eyes, whispering,\n         \"There's no escape, not at 30,000 feet.\"\nDEBUG    **************** METRICS START ****************\nDEBUG    * Time to first token:         0.4518s\nDEBUG    * Time to generate response:   1.2594s\nDEBUG    * Tokens per second:           63.5243 tokens/s\nDEBUG    * Input tokens:                59\nDEBUG    * Output tokens:               80\nDEBUG    * Total tokens:                139\nDEBUG    * Prompt tokens details:       {'cached_tokens': 0}\nDEBUG    * Completion tokens details:   {'reasoning_tokens': 0}\nDEBUG    **************** METRICS END ******************\n\n​\nSet the system message directly\n\nYou can manually set the system message using the system_prompt parameter.\n\nfrom phi.agent import Agent\n\nagent = Agent(system_prompt=\"Share a 2 sentence story about\")\nagent.print_response(\"Love in the year 12000.\")\n\n​\nUser message\n\nThe input message sent to the Agent.run() or Agent.print_response() functions is used as the user message.\n\n​\nUser message when enable_rag=True\n\nIf the Agent is provided knowledge, and the enable_rag=True, the user message is set to:\n\nuser_prompt += f\"\"\"Use the following information from the knowledge base if it helps:\"\n\n## Context\n{context}\n\"\"\"\n\n​\nDefault system message\n\nThe Agent creates a default system message that can be customized using the following parameters:\n\nParameter\tType\tDefault\tDescription\ndescription\tstr\tNone\tA description of the Agent that is added to the start of the system message.\ntask\tstr\tNone\tDescribe the task the agent should achieve.\ninstructions\tList[str]\tNone\tList of instructions added to the system prompt in <instructions> tags. Default instructions are also created depending on values for markdown, output_model etc.\nadditional_context\tstr\tNone\tAdditional context added to the end of the system message.\nexpected_output\tstr\tNone\tProvide the expected output from the Agent. This is added to the end of the system message.\nextra_instructions\tList[str]\tNone\tList of extra instructions added to the default system prompt. Use these when you want to add some extra instructions at the end of the default instructions.\nprevent_hallucinations\tbool\tFalse\tIf True, add instructions to return “I don’t know” when the agent does not know the answer.\nprevent_prompt_injection\tbool\tFalse\tIf True, add instructions to prevent prompt injection attacks.\nlimit_tool_access\tbool\tFalse\tIf True, add instructions for limiting tool access to the default system prompt if tools are provided\nmarkdown\tbool\tFalse\tAdd an instruction to format the output using markdown.\nadd_datetime_to_instructions\tbool\tFalse\tIf True, add the current datetime to the prompt to give the agent a sense of time. This allows for relative times like “tomorrow” to be used in the prompt\nsystem_prompt\tstr\tNone\tSystem prompt: provide the system prompt as a string\nsystem_prompt_template\tPromptTemplate\tNone\tProvide the system prompt as a PromptTemplate.\nuse_default_system_message\tbool\tTrue\tIf True, build a default system message using agent settings and use that.\nsystem_message_role\tstr\tsystem\tRole for the system message.\n\nDisable the default system message by setting use_default_system_message=False.\n\n​\nDefault user message\n\nThe Agent creates a default user message, which is either the input message or a message with the context if enable_rag=True. The default user message can be customized using:\n\nParameter\tType\tDefault\tDescription\nenable_rag\tbool\tFalse\tEnable RAG by adding references from the knowledge base to the prompt.\nadd_rag_instructions\tbool\tFalse\tIf True, adds instructions for using the RAG to the system prompt (if knowledge is also provided). For example: add an instruction to prefer information from the knowledge base over its training data.\nadd_history_to_messages\tbool\tFalse\tIf true, adds the chat history to the messages sent to the Model.\nnum_history_responses\tint\t3\tNumber of historical responses to add to the messages.\nuser_prompt\tUnion[List, Dict, str]\tNone\tProvide the user prompt as a string. Note: this will ignore the message sent to the run function.\nuser_prompt_template\tPromptTemplate\tNone\tProvide the user prompt as a PromptTemplate.\nuse_default_user_message\tbool\tTrue\tIf True, build a default user prompt using references and chat history.\nuser_message_role\tstr\tuser\tRole for the user message.\n\nDisable the default user message by setting use_default_user_message=False.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nTools\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSystem message\nSet the system message directly\nUser message\nUser message when enable_rag=True\nDefault system message\nDefault user message"
  },
  {
    "title": "xAI - Phidata",
    "url": "https://docs.phidata.com/examples/provider/xai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nxAI\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.xai import xAI\n\nagent = Agent(\n    model=xAI(id=\"grok-beta\"),\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nUsage\n\nGet your API key from xAI here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U openai phidata\n\n3\n\nExport `XAI_API_KEY`\n\nexport XAI_API_KEY=***\n\n4\n\nRun xAI Agent\n\npython cookbook/providers/xai/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSambanova\nComposio\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Sambanova - Phidata",
    "url": "https://docs.phidata.com/examples/provider/sambanova",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nSambanova\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.sambanova import Sambanova\n\nagent = Agent(model=Sambanova(), markdown=True)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story\")\n\n​\nUsage\n\nGet your key from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U openai phidata\n\n3\n\nExport `SAMBANOVA_API_KEY`\n\nexport SAMBANOVA_API_KEY=***\n\n4\n\nRun Sambanova Agent\n\npython cookbook/providers/sambanova/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenRouter\nxAI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "OpenRouter - Phidata",
    "url": "https://docs.phidata.com/examples/provider/openrouter",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nOpenRouter\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openrouter import OpenRouter\n\nagent = Agent(\n    model=OpenRouter(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True)],\n    show_tool_calls=True,\n    markdown=True,\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nUsage\n\nGet your key from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U openai phidata\n\n3\n\nExport `OPENROUTER_API_KEY`\n\nexport OPENROUTER_API_KEY=***\n\n4\n\nRun OpenRouter Agent\n\npython cookbook/providers/openrouter/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nNvidia\nSambanova\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Nvidia - Phidata",
    "url": "https://docs.phidata.com/examples/provider/nvidia",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nNvidia\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.nvidia import Nvidia\n\nagent = Agent(model=Nvidia(), markdown=True)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story\")\n\n\n​\nUsage\n\nGet your key from Nvidia here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U openai phidata\n\n3\n\nExport `NVIDIA_API_KEY`\n\nexport NVIDIA_API_KEY=xxx\n\n4\n\nRun Nvidia Agent\n\npython cookbook/providers/nvidia/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nHuggingFace\nOpenRouter\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "HuggingFace - Phidata",
    "url": "https://docs.phidata.com/examples/provider/huggingface",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nHuggingFace\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.huggingface import HuggingFaceChat\n\nagent = Agent(\n    model=HuggingFaceChat(\n        id=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n        max_tokens=4096,\n    ),\n    markdown=True\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nUsage\n\nGet your API key from HuggingFace here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U huggingface_hub phidata\n\n3\n\nExport Environment Variables\n\nexport HF_TOKEN=***\n\n4\n\nRun HuggingFace Agent\n\npython cookbook/providers/huggingface/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDeepSeek\nNvidia\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "DeepSeek - Phidata",
    "url": "https://docs.phidata.com/examples/provider/deepseek",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nDeepSeek\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.deepseek import DeepSeekChat\n\nagent = Agent(model=DeepSeekChat(), markdown=True)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nUsage\n\nGet your key from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U openai phidata\n\n3\n\nExport Environment Variables\n\n  export DEEPSEEK_API_KEY=***\n\n4\n\nRun DeepSeek Agent\n\npython cookbook/providers/deepseek/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAWS Bedrock\nHuggingFace\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "AWS Bedrock - Phidata",
    "url": "https://docs.phidata.com/examples/provider/aws_bedrock",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nAWS Bedrock\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.aws.claude import Claude\n\nagent = Agent(\n    model=Claude(id=\"anthropic.claude-3-5-sonnet-20240620-v1:0\")\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nUsage\n\nGet your keys from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U boto3 phidata\n\n3\n\nExport Environment Variables\n\n  export AWS_ACCESS_KEY_ID=***\n  export AWS_SECRET_ACCESS_KEY=***\n  export AWS_DEFAULT_REGION=***\n\n4\n\nRun AWS Bedrock Agent\n\npython cookbook/providers/bedrock/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTogether\nDeepSeek\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Together - Phidata",
    "url": "https://docs.phidata.com/examples/provider/together",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nTogether\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.together import Together\n\nagent = Agent(\n    model=Together(id=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\"),\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nUsage\n\nGet your key from Together here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U together openai phidata\n\n3\n\nExport `TOGETHER_API_KEY`\n\nexport TOGETHER_API_KEY=xxx\n\n4\n\nRun Together Agent\n\npython cookbook/providers/together/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOllama\nAWS Bedrock\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Ollama - Phidata",
    "url": "https://docs.phidata.com/examples/provider/ollama",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nOllama\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.ollama import Ollama\n\nagent = Agent(\n    model=Ollama(id=\"llama3.1\")\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nUsage\n\nInstall ollama and run a model.\n\n1\n\nRun your chat model\n\nollama run llama3.1\n\n\nMessage /bye to exit the chat model\n\n2\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n3\n\nInstall libraries\n\npip install -U ollama phidata\n\n4\n\nRun Ollama Agent\n\npython cookbook/providers/ollama/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nMistral\nTogether\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Mistral - Phidata",
    "url": "https://docs.phidata.com/examples/provider/mistral",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nMistral\n​\nExample\n​\nUsage\n\nGet your key from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\n2\n\nInstall libraries\n\npip install -U mistralai phidata\n\n3\n\nExport `MISTRAL_API_KEY`\n\nexport MISTRAL_API_KEY=xxx\n\n4\n\nRun Mistral Agent\n\npython cookbook/providers/mistral/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGroq\nOllama\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Groq - Phidata",
    "url": "https://docs.phidata.com/examples/provider/groq",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nGroq\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.groq import Groq\n\nagent = Agent(\n    model=Groq(id=\"llama3-groq-70b-8192-tool-use-preview\"),\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nUsage\n\nGet your key from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U groq phidata\n\n3\n\nExport `GROQ_API_KEY`\n\nexport GROQ_API_KEY=xxx\n\n4\n\nRun Groq Agent\n\npython cookbook/providers/groq/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGemini\nMistral\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Gemini - Phidata",
    "url": "https://docs.phidata.com/examples/provider/gemini",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nGemini\n​\nExample\n​\nUsage\n\nGet your key from Google here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\n2\n\nInstall libraries\n\npip install -U google-generativeai phidata\n\n3\n\nExport `GOOGLE_API_KEY`\n\nexport GOOGLE_API_KEY=***\n\n4\n\nRun Gemini Agent\n\npython cookbook/providers/google/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFireworks\nGroq\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Fireworks - Phidata",
    "url": "https://docs.phidata.com/examples/provider/fireworks",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nFireworks\n​\nExample\n​\nUsage\n\nGet your key from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\n2\n\nInstall libraries\n\npip install -U fireworks phidata\n\n3\n\nExport `FIREWORKS_API_KEY`\n\nexport FIREWORKS_API_KEY=xxx\n\n4\n\nRun fireworks Agent\n\npython cookbook/providers/fireworks/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCohere\nGemini\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Cohere - Phidata",
    "url": "https://docs.phidata.com/examples/provider/cohere",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nCohere\n​\nExample\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.cohere import CohereChat\n\nagent = Agent(\n    model=CohereChat(id=\"command-r-08-2024\"),\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nUsage\n\nGet your key from here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U cohere phidata\n\n3\n\nExport `CO_API_KEY`\n\nexport CO_API_KEY=xxx\n\n4\n\nRun Cohere Agent\n\npython cookbook/providers/cohere/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nClaude\nFireworks\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Claude - Phidata",
    "url": "https://docs.phidata.com/examples/provider/claude",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nClaude\n​\nExample\n\nUse Claude with your Agent:\n\nagent.py\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.anthropic import Claude\n\nagent = Agent(\n    model=Claude(id=\"claude-3-5-sonnet-20240620\"),\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nUsage\n\nYou can get your API key from Anthropic here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U anthropic phidata\n\n3\n\nExport `ANTHROPIC_API_KEY`\n\nexport ANTHROPIC_API_KEY=xxx\n\n4\n\nRun Claude Agent\n\npython cookbook/providers/claude/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAzure\nCohere\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Azure - Phidata",
    "url": "https://docs.phidata.com/examples/provider/azure",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nAzure\n​\nExample\nagent.py\nimport os\nfrom typing import Iterator\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.azure import AzureOpenAIChat\n\nazure_model = AzureOpenAIChat(\n    id=os.getenv(\"AZURE_OPENAI_MODEL_NAME\"),\n    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n)\n\nagent = Agent(\n    model=azure_model,\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response on the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U openai phidata\n\n3\n\nExport Environment Variables\n\n  export AZURE_OPENAI_API_KEY=***\n  export AZURE_OPENAI_ENDPOINT=***\n  export AZURE_OPENAI_MODEL_NAME=***\n  export AZURE_OPENAI_DEPLOYMENT=***\n  # Optional:\n  # export AZURE_OPENAI_API_VERSION=***\n\n4\n\nRun azure Agent\n\npython cookbook/providers/azure_openai/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nOpenAI\nClaude\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Streaming - Phidata",
    "url": "https://docs.phidata.com/workflows/streaming",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nIntroduction\nSession State\nStreaming\nAdvanced Example - News Report Generator\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nWorkflows\nStreaming\n\nWorkflows are all about control and flexibility. You have full control over the multi-agent process, how the input is processed, which agents are used and in what order.\n\nYou also have full control over how the output is streamed.\n\n​\nStreaming\n\nTo stream the output, yield an Iterator[RunResponse] from the run() method of your workflow.\n\nnews_report_generator.py\n# Define the workflow\nclass GenerateNewsReport(Workflow):\n    agent_1: Agent = ...\n\n    agent_2: Agent = ...\n\n    agent_3: Agent = ...\n\n    def run(self, ...) -> Iterator[RunResponse]:\n        # Run agents and gather the response\n        # These can be batch responses, you can also stream intermediate results if you want\n        final_agent_input = ...\n\n        # Generate the final response from the writer agent\n        agent_3_response_stream: Iterator[RunResponse] = self.agent_3.run(final_agent_input, stream=True)\n\n        # Yield the response\n        yield agent_3_response_stream\n\n\n# Instantiate the workflow\ngenerate_news_report = GenerateNewsReport()\n\n# Run workflow and get the response as an iterator of RunResponse objects\nreport_stream: Iterator[RunResponse] = generate_news_report.run(...)\n\n# Print the response\npprint_run_response(report_stream, markdown=True)\n\n​\nBatch\n\nSimply return a RunResponse object from the run() method of your workflow to return a single output.\n\nnews_report_generator.py\n# Define the workflow\nclass GenerateNewsReport(Workflow):\n    agent_1: Agent = ...\n\n    agent_2: Agent = ...\n\n    agent_3: Agent = ...\n\n    def run(self, ...) -> RunResponse:\n        # Run agents and gather the response\n        final_agent_input = ...\n\n        # Generate the final response from the writer agent\n        agent_3_response: RunResponse = self.agent_3.run(final_agent_input)\n\n        # Return the response\n        return agent_3_response\n\n\n# Instantiate the workflow\ngenerate_news_report = GenerateNewsReport()\n\n# Run workflow and get the response as a RunResponse object\nreport: RunResponse = generate_news_report.run(...)\n\n# Print the response\npprint_run_response(report, markdown=True)\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSession State\nAdvanced Example - News Report Generator\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nStreaming\nBatch"
  },
  {
    "title": "Session State - Phidata",
    "url": "https://docs.phidata.com/workflows/session-state",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nIntroduction\nSession State\nStreaming\nAdvanced Example - News Report Generator\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nWorkflows\nSession State\n\nUse the session_state to cache intermediate results in a database.\n\nAll Workflows come with a session_state dictionary that you can use to cache intermediate results. Provide your workflows with storage and a session_id to enable caching.\n\nFor example, you can use the SqlWorkflowStorage to cache results in a Sqlite database.\n\n# Create the workflow\ngenerate_blog_post = BlogPostGenerator(\n    session_id=\"my-session-id\",\n    storage=SqlWorkflowStorage(\n        table_name=\"generate_blog_post_workflows\",\n        db_file=\"tmp/workflows.db\",\n    ),\n)\n\n\nThen in the run() method, you can read from and add to the session_state as needed.\n\n\nclass BlogPostGenerator(Workflow):\n    # ... agents\n    def run(self, topic: str, use_cache: bool = True) -> Iterator[RunResponse]:\n        # Read from the session state cache\n        if use_cache and \"blog_posts\" in self.session_state:\n            logger.info(\"Checking if cached blog post exists\")\n            for cached_blog_post in self.session_state[\"blog_posts\"]:\n                if cached_blog_post[\"topic\"] == topic:\n                    logger.info(\"Found cached blog post\")\n                    yield RunResponse(\n                        run_id=self.run_id,\n                        event=RunEvent.workflow_completed,\n                        content=cached_blog_post[\"blog_post\"],\n                    )\n                    return\n\n        # ... generate the blog post\n\n        # Save to session state for future runs\n        if \"blog_posts\" not in self.session_state:\n            self.session_state[\"blog_posts\"] = []\n        self.session_state[\"blog_posts\"].append({\"topic\": topic, \"blog_post\": self.writer.run_response.content})\n\n\nWhen the workflow starts, the session_state for that particular session_id is read from the database and when the workflow ends, the session_state is stored in the database.\n\nYou can always call self.write_to_storage() to save the session_state to the database at any time. Incase you need to abort the workflow but want to store the intermediate results.\n\nView the Blog Post Generator for an example of how to use session state for caching.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nStreaming\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "World Building - Phidata",
    "url": "https://docs.phidata.com/examples/use-case/worldbuilding",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nUse Cases\nSql Agent\nWorld Building\nArXiv Research Agent\nHow To\nClone Cookbook\nUse Cases\nWorld Building\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSql Agent\nArXiv Research Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Database Tables - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/database-tables",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nDatabase Tables\n\nPhidata templates come pre-configured with SqlAlchemy and alembic to manage databases. The general workflow to add a table is:\n\nAdd table definition to the db/tables directory.\nImport the table class in the db/tables/__init__.py file.\nCreate a database migration.\nRun database migration.\n​\nTable Definition\n\nLet’s create a UsersTable, copy the following code to db/tables/user.py\n\ndb/tables/user.py\nfrom datetime import datetime\nfrom typing import Optional\n\nfrom sqlalchemy.orm import Mapped, mapped_column\nfrom sqlalchemy.sql.expression import text\nfrom sqlalchemy.types import BigInteger, DateTime, String\n\nfrom db.tables.base import Base\n\n\nclass UsersTable(Base):\n    \"\"\"Table for storing user data.\"\"\"\n\n    __tablename__ = \"dim_users\"\n\n    id_user: Mapped[int] = mapped_column(\n        BigInteger, primary_key=True, autoincrement=True, nullable=False, index=True\n    )\n    email: Mapped[str] = mapped_column(String)\n    is_active: Mapped[bool] = mapped_column(default=True)\n    created_at: Mapped[datetime] = mapped_column(\n        DateTime(timezone=True), server_default=text(\"now()\")\n    )\n    updated_at: Mapped[Optional[datetime]] = mapped_column(\n        DateTime(timezone=True), onupdate=text(\"now()\")\n    )\n\n\nUpdate the db/tables/__init__.py file:\n\ndb/tables/__init__.py\nfrom db.tables.base import Base\nfrom db.tables.user import UsersTable\n\n​\nCreat a database revision\n\nRun the alembic command to create a database migration in the dev container:\n\ndocker exec -it ai-api alembic -c db/alembic.ini revision --autogenerate -m \"Initialize DB\"\n\n​\nMigrate dev database\n\nRun the alembic command to migrate the dev database:\n\ndocker exec -it ai-api alembic -c db/alembic.ini upgrade head\n\n​\nOptional: Add test user\n\nNow lets’s add a test user. Copy the following code to db/tables/test_add_user.py\n\ndb/tables/test_add_user.py\nfrom typing import Optional\nfrom sqlalchemy.orm import Session\n\nfrom db.session import SessionLocal\nfrom db.tables.user import UsersTable\nfrom utils.log import logger\n\n\ndef create_user(db_session: Session, email: str) -> UsersTable:\n    \"\"\"Create a new user.\"\"\"\n    new_user = UsersTable(email=email)\n    db_session.add(new_user)\n    return new_user\n\n\ndef get_user(db_session: Session, email: str) -> Optional[UsersTable]:\n    \"\"\"Get a user by email.\"\"\"\n    return db_session.query(UsersTable).filter(UsersTable.email == email).first()\n\n\nif __name__ == \"__main__\":\n    test_user_email = \"test@test.com\"\n    with SessionLocal() as sess, sess.begin():\n        logger.info(f\"Creating user: {test_user_email}\")\n        create_user(db_session=sess, email=test_user_email)\n        logger.info(f\"Getting user: {test_user_email}\")\n        user = get_user(db_session=sess, email=test_user_email)\n        if user:\n            logger.info(f\"User created: {user.id_user}\")\n        else:\n            logger.info(f\"User not found: {test_user_email}\")\n\n\n\nRun the script to add a test adding a user:\n\ndocker exec -it ai-api python db/tables/test_add_user.py\n\n​\nMigrate production database\n\nWe recommended migrating the production database by setting the environment variable MIGRATE_DB = True and restarting the production service. This runs alembic -c db/alembic.ini upgrade head from the entrypoint script at container startup.\n\n​\nUpdate the workspace/prd_resources.py file\nworkspace/prd_resources.py\n...\n# -*- Build container environment\ncontainer_env = {\n    ...\n    # Migrate database on startup using alembic\n    \"MIGRATE_DB\": ws_settings.prd_db_enabled,\n}\n...\n\n​\nUpdate the ECS Task Definition\n\nBecause we updated the Environment Variables, we need to update the Task Definition:\n\nterminal\nshorthand\nphi ws patch --env prd --infra aws --name td\n\n​\nUpdate the ECS Service\n\nAfter updating the task definition, redeploy the production application:\n\nterminal\nshorthand\nphi ws patch --env prd --infra aws --name service\n\n​\nManually migrate prodution database\n\nAnother approach is to SSH into the production container to run the migration manually. Your ECS tasks are already enabled with SSH access. Run the alembic command to migrate the production database:\n\nECS_CLUSTER=ai-app-prd-cluster\nTASK_ARN=$(aws ecs list-tasks --cluster ai-app-prd-cluster --query \"taskArns[0]\" --output text)\nCONTAINER_NAME=ai-api-prd\n\naws ecs execute-command --cluster $ECS_CLUSTER \\\n    --task $TASK_ARN \\\n    --container $CONTAINER_NAME \\\n    --interactive \\\n    --command \"alembic -c db/alembic.ini upgrade head\"\n\n​\nHow the migrations directory was created\n\nThese commands have been run and are described for completeness\n\nThe migrations directory was created using:\n\ndocker exec -it ai-api cd db && alembic init migrations\n\nAfter running the above command, the db/migrations directory should be created.\nUpdate alembic.ini\nset script_location = db/migrations\nuncomment black hook in [post_write_hooks]\nUpdate db/migrations/env.py file following this link\nAdd the following function to configure to only include tables in the target_metadata\ndb/migrations/env.py\n# -*- Only include tables that are in the target_metadata\ndef include_name(name, type_, parent_names):\n    if type_ == \"table\":\n        return name in target_metadata.tables\n    else:\n        return True\n...\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nEnvironment variables\nCI/CD\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nTable Definition\nCreat a database revision\nMigrate dev database\nOptional: Add test user\nMigrate production database\nUpdate the workspace/prd_resources.py file\nUpdate the ECS Task Definition\nUpdate the ECS Service\nManually migrate prodution database\nHow the migrations directory was created"
  },
  {
    "title": "Sql Agent - Phidata",
    "url": "https://docs.phidata.com/examples/use-case/sql",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nUse Cases\nSql Agent\nWorld Building\nArXiv Research Agent\nHow To\nClone Cookbook\nUse Cases\nSql Agent\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nHackernews Team\nWorld Building\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "CI/CD - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/ci-cd",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nCI/CD\n\nPhidata templates come pre-configured with Github Actions for CI/CD. We can\n\nTest and Validate on every PR\nBuild Docker Images with Github Releases\nBuild ECR Images with Github Releases\n​\nTest and Validate on every PR\n\nWhenever a PR is opened against the main branch, a validate script runs that ensures\n\nThe changes are formatted using ruff\nAll unit-tests pass\nThe changes don’t have any typing or linting errors.\n\nCheckout the .github/workflows/validate.yml file for more information.\n\n​\nBuild Docker Images with Github Releases\n\nIf you’re using Dockerhub for images, you can buld and push the images throug a Github Release. This action is defined in the .github/workflows/docker-images.yml file.\n\nCreate a Docker Access Token for Github Actions\nCreate secret variables DOCKERHUB_REPO, DOCKERHUB_TOKEN and DOCKERHUB_USERNAME in your github repo. These variables are used by the action in .github/workflows/docker-images.yml\nRun workflow using a Github Release\n\nThis workflow is configured to run when a release is created. Create a new release using:\n\nConfirm the image name in the .github/workflows/docker-images.yml file before running\n\nMac\nWindows\ngh release create v0.1.0 --title \"v0.1.0\" -n \"\"\n\n\nYou can also run the workflow using gh workflow run\n\n​\nBuild ECR Images with Github Releases\n\nIf you’re using ECR for images, you can buld and push the images through a Github Release. This action is defined in the .github/workflows/ecr-images.yml file and uses the new OpenID Connect (OIDC) approach to request the access token, without using IAM access keys.\n\nWe will follow this guide to create an IAM role which will be used by the github action.\n\nOpen the IAM console.\nIn the left navigation menu, choose Identity providers.\nIn the Identity providers pane, choose Add provider.\nFor Provider type, choose OpenID Connect.\nFor Provider URL, enter the URL of the GitHub OIDC IdP: https://token.actions.githubusercontent.com\nGet thumbprint to verify the server certificate\nFor Audience, enter sts.amazonaws.com.\n\nVerify the information matches the screenshot below and Add provider\n\nAssign a Role to the provider.\nCreate a new role.\nConfirm that Web identity is already selected as the trusted entity and the Identity provider field is populated with the IdP. In the Audience list, select sts.amazonaws.com, and then select Next.\n\nAdd the AmazonEC2ContainerRegistryPowerUser permission to this role.\n\nCreate the role with the name GithubActionsRole.\n\nFind the role GithubActionsRole and copy the ARN.\n\nCreate the ECR Repositories: llm and jupyter-llm which are built by the workflow.\nUpdate the workflow with the GithubActionsRole ARN and ECR Repository.\n.github/workflows/ecr-images.yml\nname: Build ECR Images\n\non:\n  release:\n    types: [published]\n\npermissions:\n  # For AWS OIDC Token access as per https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services#updating-your-github-actions-workflow\n  id-token: write # This is required for requesting the JWT\n  contents: read # This is required for actions/checkout\n\nenv:\n  ECR_REPO: [YOUR_ECR_REPO]\n  # Create role using https://aws.amazon.com/blogs/security/use-iam-roles-to-connect-github-actions-to-actions-in-aws/\n  AWS_ROLE: [GITHUB_ACTIONS_ROLE_ARN]\n  AWS_REGION: us-east-1\n\nUpdate the docker-images workflow to NOT run on a release\n.github/workflows/docker-images.yml\nname: Build Docker Images\n\non: workflow_dispatch\n\nRun workflow using a Github Release\nMac\nWindows\ngh release create v0.2.0 --title \"v0.2.0\" -n \"\"\n\n\nYou can also run the workflow using gh workflow run\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDatabase Tables\nCustom Domain & HTTPS\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nTest and Validate on every PR\nBuild Docker Images with Github Releases\nBuild ECR Images with Github Releases"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  },
  {
    "title": "Environment variables - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/env-vars",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nEnvironment variables\n\nEnvironment variables can be added to resources using the env_vars parameter or the env_file parameter pointing to a yaml file. Examples\n\ndev_resources.py\ndev_fastapi = FastApi(\n    ...\n    env_vars={\n        \"RUNTIME_ENV\": \"dev\",\n        # Get the OpenAI API key from the local environment\n        \"OPENAI_API_KEY\": getenv(\"OPENAI_API_KEY\"),\n        # Database configuration\n        \"DB_HOST\": dev_db.get_db_host(),\n        \"DB_PORT\": dev_db.get_db_port(),\n        \"DB_USER\": dev_db.get_db_user(),\n        \"DB_PASS\": dev_db.get_db_password(),\n        \"DB_DATABASE\": dev_db.get_db_database(),\n        # Wait for database to be available before starting the application\n        \"WAIT_FOR_DB\": ws_settings.dev_db_enabled,\n        # Migrate database on startup using alembic\n        # \"MIGRATE_DB\": ws_settings.prd_db_enabled,\n    },\n    ...\n)\n\nprd_resources.py\nprd_fastapi = FastApi(\n    ...\n    env_vars={\n        \"RUNTIME_ENV\": \"prd\",\n        # Get the OpenAI API key from the local environment\n        \"OPENAI_API_KEY\": getenv(\"OPENAI_API_KEY\"),\n        # Database configuration\n        \"DB_HOST\": AwsReference(prd_db.get_db_endpoint),\n        \"DB_PORT\": AwsReference(prd_db.get_db_port),\n        \"DB_USER\": AwsReference(prd_db.get_master_username),\n        \"DB_PASS\": AwsReference(prd_db.get_master_user_password),\n        \"DB_DATABASE\": AwsReference(prd_db.get_db_name),\n        # Wait for database to be available before starting the application\n        \"WAIT_FOR_DB\": ws_settings.prd_db_enabled,\n        # Migrate database on startup using alembic\n        # \"MIGRATE_DB\": ws_settings.prd_db_enabled,\n    },\n    ...\n)\n\n\nThe apps in your templates are already configured to read environment variables.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAdd Secrets\nDatabase Tables\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Add Secrets - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/secrets",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nAdd Secrets\n\nSecret management is a critical part of your application security and should be taken seriously.\n\nLocal secrets are defined in the worspace/secrets directory which is excluded from version control (see .gitignore). Its contents should be handled with the same security as passwords.\n\nProduction secrets are managed by AWS Secrets Manager.\n\nIncase you’re missing the secrets dir, copy workspace/example_secrets\n\n​\nDevelopment Secrets\n\nApps running locally can read secrets using a yaml file, for example:\n\ndev_resources.py\ndev_fastapi = FastApi(\n    ...\n    # Read secrets from secrets/dev_app_secrets.yml\n    secrets_file=ws_settings.ws_root.joinpath(\"workspace/secrets/dev_app_secrets.yml\"),\n)\n\n​\nProduction Secrets\n\nAWS Secrets are used to manage production secrets, which are read by the production apps.\n\nprd_resources.py\n# -*- Secrets for production application\nprd_secret = SecretsManager(\n    ...\n    # Create secret from workspace/secrets/prd_app_secrets.yml\n    secret_files=[\n        ws_settings.ws_root.joinpath(\"workspace/secrets/prd_app_secrets.yml\")\n    ],\n)\n\n# -*- Secrets for production database\nprd_db_secret = SecretsManager(\n    ...\n    # Create secret from workspace/secrets/prd_db_secrets.yml\n    secret_files=[ws_settings.ws_root.joinpath(\"workspace/secrets/prd_db_secrets.yml\")],\n)\n\n\nRead the secret in production apps using:\n\nFastApi\nRDS\nprd_fastapi = FastApi(\n    ...\n    aws_secrets=[prd_secret],\n    ...\n)\n\n\nProduction resources can also read secrets using yaml files but we highly recommend using AWS Secrets.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nInstall & Setup\nEnvironment variables\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nDevelopment Secrets\nProduction Secrets"
  },
  {
    "title": "SSH Access - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/ssh-access",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nSSH Access\n\nSSH Access is an important part of the developer workflow.\n\n​\nDev SSH Access\n\nSSH into the dev containers using the docker exec command\n\ndocker exec -it ai-api zsh\n\n​\nProduction SSH Access\n\nYour ECS tasks are already enabled with SSH access. SSH into the production containers using:\n\nECS_CLUSTER=ai-app-prd-cluster\nTASK_ARN=$(aws ecs list-tasks --cluster ai-app-prd-cluster --query \"taskArns[0]\" --output text)\nCONTAINER_NAME=ai-api-prd\n\naws ecs execute-command --cluster $ECS_CLUSTER \\\n    --task $TASK_ARN \\\n    --container $CONTAINER_NAME \\\n    --interactive \\\n    --command \"zsh\"\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCustom Domain & HTTPS\nWorkspace Settings\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nDev SSH Access\nProduction SSH Access"
  },
  {
    "title": "Setup workspace for new users - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/new-users",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace Settings\nCreate Git Repo\nAdd New Users\nFormat & Validate\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Workspace\nSetup workspace for new users\n\nFollow these steps to setup an existing workspace:\n\n1\n\nClone git repository\n\nClone the git repo and cd into the workspace directory\n\n2\n\nCreate and activate a virtual env\n\n3\n\nInstall phidata\n\n4\n\nSetup workspace\n\n5\n\nCopy secrets\n\nCopy workspace/example_secrets to workspace/secrets\n\n6\n\nStart workspace\n\nInstall docker desktop if needed.\n\n7\n\nStop workspace\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCreate Git Repo\nFormat & Validate\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Use Custom Domain and HTTPS - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/domain-https",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nUse Custom Domain and HTTPS\n​\nUse a custom domain\nRegister your domain with Route 53.\nPoint the domain to the loadbalancer DNS.\n​\nCustom domain for your Streamlit App\n\nCreate a record in the Route53 console to point app.[YOUR_DOMAIN] to the Streamlit App.\n\nYou can visit the app at http://app.aidev.run\n\nNote the http in the domain name.\n​\nCustom domain for your FastApi App\n\nCreate a record in the Route53 console to point api.[YOUR_DOMAIN] to the FastApi App.\n\nYou can access the api at http://api.aidev.run\n\nNote the http in the domain name.\n​\nAdd HTTPS\n\nTo add HTTPS:\n\nCreate a certificate using AWS ACM. Request a certificat for *.[YOUR_DOMAIN]\nCreating records in Route 53.\nAdd the certificate ARN to Apps\nMake sure the certificate is Issued before adding it to your Apps\n\nUpdate the llm-app/workspace/prd_resources.py file and add the load_balancer_certificate_arn to the FastApi and Streamlit Apps.\n\nworkspace/prd_resources.py\n\n# -*- Streamlit running on ECS\nprd_streamlit = Streamlit(\n    ...\n    # To enable HTTPS, create an ACM certificate and add the ARN below:\n    load_balancer_enable_https=True,\n    load_balancer_certificate_arn=\"arn:aws:acm:us-east-1:497891874516:certificate/6598c24a-d4fc-4f17-8ee0-0d3906eb705f\",\n    ...\n)\n\n# -*- FastApi running on ECS\nprd_fastapi = FastApi(\n    ...\n    # To enable HTTPS, create an ACM certificate and add the ARN below:\n    load_balancer_enable_https=True,\n    load_balancer_certificate_arn=\"arn:aws:acm:us-east-1:497891874516:certificate/6598c24a-d4fc-4f17-8ee0-0d3906eb705f\",\n    ...\n)\n\nCreate new Loadbalancer Listeners\n\nCreate new listeners for the loadbalancer to pickup the HTTPs configuration.\n\nterminal\nshorthand\nphi ws up --env prd --infra aws --name listener\n\nThe certificate should be Issued before applying it.\n\nAfter this, https should be working on your custom domain.\n\nUpdate existing listeners to redirect HTTP to HTTPS\nterminal\nshorthand\nphi ws patch --env prd --infra aws --name listener\n\n\nAfter this, all HTTP requests should redirect to HTTPS automatically.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCI/CD\nSSH Access\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUse a custom domain\nCustom domain for your Streamlit App\nCustom domain for your FastApi App\nAdd HTTPS"
  },
  {
    "title": "Production Application - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/production-app",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nProduction Application\n\nYour production application runs on AWS and its resources are defined in the workspace/prd_resources.py file. This guide shows how to:\n\nBuild a production image\nUpdate ECS Task Definitions\nUpdate ECS Services\n​\nWorkspace Settings\n\nThe WorkspaceSettings object in the workspace/settings.py file defines common settings used by your workspace apps and resources.\n\n​\nBuild your production image\n\nYour application uses the phidata images by default. To use your own image:\n\nCreate a Repository in ECR and authenticate or use Dockerhub.\nOpen workspace/settings.py file\nUpdate the image_repo to your image repository\nSet build_images=True and push_images=True\nOptional - Set build_images=False and push_images=False to use an existing image in the repository\n​\nCreate an ECR Repository\n\nTo use ECR, create the image repo and authenticate with ECR before pushing images.\n\n1. Create the image repository in ECR\n\nThe repo name should match the ws_name. Meaning if you’re using the default workspace name, the repo name would be ai.\n\n2. Authenticate with ECR\n\nAuthenticate with ECR\naws ecr get-login-password --region [region] | docker login --username AWS --password-stdin [account].dkr.ecr.[region].amazonaws.com\n\n\nYou can also use a helper script to avoid running the full command\n\nUpdate the script with your ECR repo before running.\n\nMac\n./scripts/auth_ecr.sh\n\n​\nUpdate the WorkspaceSettings\nworkspace/settings.py\nws_settings = WorkspaceSettings(\n    ...\n    # Subnet IDs in the aws_region\n    subnet_ids=[\"subnet-xyz\", \"subnet-xyz\"],\n    # -*- Image Settings\n    # Repository for images\n    image_repo=\"your-image-repo\",\n    # Build images locally\n    build_images=True,\n    # Push images after building\n    push_images=True,\n)\n\n\nThe image_repo defines the repo for your image.\n\nIf using dockerhub it would be something like phidata.\nIf using ECR it would be something like [ACCOUNT_ID].dkr.ecr.us-east-1.amazonaws.com\n​\nBuild a new image\n\nBuild the production image using:\n\nterminal\nshorthand\nphi ws up --env prd --infra docker --type image\n\n\nTo force rebuild images, use the --force or -f flag\n\nterminal\nshorthand\nphi ws up --env prd --infra docker --type image --force\n\n\nBecause the only docker resources in the production env are docker images, you can also use:\n\nBuild Images\nForce Build Images\nphi ws up prd:docker\n\n​\nECS Task Definition\n\nIf you updated the Image, CPU, Memory or Environment Variables, update the Task Definition using:\n\nterminal\nshorthand\nphi ws patch --env prd --infra aws --name td\n\n​\nECS Service\n\nTo redeploy the production application, update the ECS Service using:\n\nterminal\nshorthand\nphi ws patch --env prd --infra aws --name service\n\n\n\n\nIf you ONLY rebuilt the image, you do not need to update the task definition and can just patch the service to pickup the new image.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDevelopment Application\nInstall & Setup\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWorkspace Settings\nBuild your production image\nCreate an ECR Repository\nUpdate the WorkspaceSettings\nBuild a new image\nECS Task Definition\nECS Service"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  },
  {
    "title": "DuckDb Agent - Phidata",
    "url": "https://docs.phidata.com/reference/agents/duckdb",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nPython\nDuckDb\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nCustom Agents\nDuckDb Agent\n​\nExample\nduckdb_agent.py\nimport json\nfrom phi.agent.duckdb import DuckDbAgent\n\ntables = [\n    {\n        \"name\": \"movies\",\n        \"description\": \"Contains information about movies from IMDB.\",\n        \"path\": \"s3://phidata-public/demo_data/IMDB-Movie-Data.csv\",\n    },\n]\n\nduckdb_agent = DuckDbAgent(\n    show_function_calls=True,\n    semantic_model=json.dumps({\"tables\": tables}, indent=4),\n)\n\nduckdb_agent.print_response(\"What is the average rating of movies?\")\n\n​\nDuckDbAgent Params\nParameter\tType\tDefault\tDescription\nname\tstr\t\"DuckDbAgent\"\tName of the agent.\nsemantic_model\tOptional[str]\tNone\tSemantic model for the agent. Use this to describe the available tables, their description, data path and relations between tables.\nadd_history_to_messages\tbool\tTrue\tIf the chat history should be added to the messages.\nfollowups\tbool\tFalse\tIf the DuckDbAgent is allowed to run followup queries.\nread_tool_call_history\tbool\tTrue\tIf the DuckDbAgent is allowed to read the tool call history.\ndb_path\tOptional[str]\tNone\tPath to the DuckDb database file.\nconnection\tOptional[duckdb.DuckDBPyConnection]\tNone\tProvide an existing duckdb connection.\ninit_commands\tOptional[List]\tNone\tCommands ran when the duckdb connection is initialized.\nread_only\tbool\tFalse\tIf the database is read-only.\nconfig\tOptional[dict]\tNone\tDatabase config used to initialize the duckdb connection.\nrun_queries\tbool\tTrue\tIf the DuckDbAgent is allowed to run queries.\ninspect_queries\tbool\tTrue\tIf the DuckDbAgent is allowed to inspect queries.\ncreate_tables\tbool\tTrue\tIf the DuckDbAgent is allowed to create tables.\nsummarize_tables\tbool\tTrue\tIf the DuckDbAgent is allowed to summarize tables.\nexport_tables\tbool\tTrue\tIf the DuckDbAgent is allowed to export tables.\nbase_dir\tOptional[Path]\tNone\tWhere to save SQL files if needed.\nsave_files\tbool\tTrue\tIf the DuckDbAgent is allowed to save SQL files.\nread_files\tbool\tFalse\tIf the DuckDbAgent is allowed to read SQL files.\nlist_files\tbool\tFalse\tIf the DuckDbAgent is allowed to list SQL files.\n​\nAgent Reference\n\nDuckDbAgent is a subclass of the Agent class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nmodel\tOptional[Model]\tNone\tModel to use for this Agent (alias: \"provider\")\nname\tOptional[str]\tNone\tAgent name\nagent_id\tOptional[str]\tNone\tAgent UUID (autogenerated if not set)\nagent_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with this agent\nintroduction\tOptional[str]\tNone\tAgent introduction. This is added to the chat history when a run is started.\nuser_id\tOptional[str]\tNone\tID of the user interacting with this agent\nuser_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with the user interacting with this agent\nsession_id\tOptional[str]\tNone\tSession UUID (autogenerated if not set)\nsession_name\tOptional[str]\tNone\tSession name\nsession_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with this session\nmemory\tAgentMemory\tAgentMemory()\tAgent Memory\nadd_history_to_messages\tbool\tFalse\tAdd chat history to the messages sent to the Model. (alias: \"add_chat_history_to_messages\")\nnum_history_responses\tint\t3\tNumber of historical responses to add to the messages.\nknowledge\tOptional[AgentKnowledge]\tNone\tAgent Knowledge (alias: \"knowledge_base\")\nadd_context\tbool\tFalse\tEnable RAG by adding context from AgentKnowledge to the user prompt.\nretriever\tOptional[Callable[..., Optional[list[dict]]]]\tNone\tFunction to get context to add to the user_message\ncontext_format\tLiteral[\"json\", \"yaml\"]\t\"json\"\tFormat of the context\nadd_context_instructions\tbool\tFalse\tIf True, add instructions for using the context to the system prompt\nstorage\tOptional[AgentStorage]\tNone\tAgent Storage\ntools\tOptional[List[Union[Tool, Toolkit, Callable, Dict, Function]]]\tNone\tA list of tools provided to the Model.\nshow_tool_calls\tbool\tFalse\tShow tool calls in Agent response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) tool is called by the model.\nreasoning\tbool\tFalse\tEnable reasoning by working through the problem step by step.\nreasoning_model\tOptional[Model]\tNone\tModel to use for reasoning\nreasoning_agent\tOptional[Agent]\tNone\tAgent to use for reasoning\nreasoning_min_steps\tint\t1\tMinimum number of reasoning steps\nreasoning_max_steps\tint\t10\tMaximum number of reasoning steps\nread_chat_history\tbool\tFalse\tAdd a tool that allows the Model to read the chat history.\nsearch_knowledge\tbool\tTrue\tAdd a tool that allows the Model to search the knowledge base (aka Agentic RAG)\nupdate_knowledge\tbool\tFalse\tAdd a tool that allows the Model to update the knowledge base.\nread_tool_call_history\tbool\tFalse\tAdd a tool that allows the Model to get the tool call history.\nadd_messages\tOptional[List[Union[Dict, Message]]]\tNone\tA list of extra messages added after the system message and before the user message.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt: provide the system prompt as a string\nsystem_prompt_template\tOptional[PromptTemplate]\tNone\tSystem prompt template: provide the system prompt as a PromptTemplate\nuse_default_system_message\tbool\tTrue\tIf True, build a default system message using agent settings and use that\nsystem_message_role\tstr\t\"system\"\tRole for the system message\ndescription\tOptional[str]\tNone\tA description of the Agent that is added to the start of the system message.\ntask\tOptional[str]\tNone\tThe task the agent should achieve.\ninstructions\tOptional[List[str]]\tNone\tList of instructions for the agent.\nguidelines\tOptional[List[str]]\tNone\tList of guidelines for the agent.\nexpected_output\tOptional[str]\tNone\tProvide the expected output from the Agent.\nadditional_context\tOptional[str]\tNone\tAdditional context added to the end of the system message.\nprevent_hallucinations\tbool\tFalse\tIf True, add instructions to return \"I dont know\" when the agent does not know the answer.\nprevent_prompt_leakage\tbool\tFalse\tIf True, add instructions to prevent prompt leakage\nlimit_tool_access\tbool\tFalse\tIf True, add instructions for limiting tool access to the default system prompt if tools are provided\nmarkdown\tbool\tFalse\tIf markdown=true, add instructions to format the output using markdown\nadd_name_to_instructions\tbool\tFalse\tIf True, add the agent name to the instructions\nadd_datetime_to_instructions\tbool\tFalse\tIf True, add the current datetime to the instructions to give the agent a sense of time\nuser_prompt\tOptional[Union[List, Dict, str]]\tNone\tUser prompt: provide the user prompt as a string\nuser_prompt_template\tOptional[PromptTemplate]\tNone\tUser prompt template: provide the user prompt as a PromptTemplate\nuse_default_user_message\tbool\tTrue\tIf True, build a default user prompt using references and chat history\nuser_message_role\tstr\t\"user\"\tRole for the user message\nresponse_model\tOptional[Type[BaseModel]]\tNone\tProvide a response model to get the response as a Pydantic model (alias: \"output_model\")\nparse_response\tbool\tTrue\tIf True, the response from the Model is converted into the response_model\nstructured_outputs\tbool\tFalse\tUse the structured_outputs from the Model if available\nsave_response_to_file\tOptional[str]\tNone\tSave the response to a file\nteam\tOptional[List[\"Agent\"]]\tNone\tAn Agent can have a team of agents that it can transfer tasks to.\nrole\tOptional[str]\tNone\tWhen the agent is part of a team, this is the role of the agent in the team\nadd_transfer_instructions\tbool\tTrue\tAdd instructions for transferring tasks to team members\ndebug_mode\tbool\tFalse\tdebug_mode=True enables debug logs\nmonitoring\tbool\tFalse\tmonitoring=True logs Agent information to phidata.app for monitoring\ntelemetry\tbool\tTrue\ttelemetry=True logs minimal telemetry for analytics\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPython\nBase\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nDuckDbAgent Params\nAgent Reference"
  },
  {
    "title": "Run on AWS - Phidata",
    "url": "https://docs.phidata.com/templates/agent-api/run-aws",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nRun locally\nRun on AWS\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nAgent API\nRun on AWS\n\nLet’s run the Agent API in production on AWS.\n\n​\nAWS Setup\n1\n\nUpdate Credentials\n\nTo run on AWS, you need one of the following:\n\nThe ~/.aws/credentials file with your AWS credentials\nor AWS_ACCESS_KEY_ID + AWS_SECRET_ACCESS_KEY environment variables\n\nTo create the credentials file, install the aws cli and run aws configure\n\n2\n\nUpdate region and subnets\n\nAdd 2 subnets to the workspace/settings.py file (required for ECS services)\n\nworkspace/settings.py\nws_settings = WorkspaceSettings(\n    ...\n    # -*- AWS settings\n    # Add your Subnet IDs here\n    subnet_ids=[\"subnet-xyz\", \"subnet-xyz\"],\n    ...\n)\n\n\nPlease check that the subnets belong to the selected aws_region\n\n​\nUpdate Secrets\n1\n\nRDS database password\n\nUpdate the RDS database password in workspace/secrets/prd_db_secrets.yml\n\nworkspace/secrets/prd_db_secrets.yml\n# Secrets used by prd RDS database\nMASTER_USERNAME: api\nMASTER_USER_PASSWORD: \"api9999!!\"\n\n2\n\nAPI Secrets\n\nAdd any other secrets used by your api to workspace/secrets/prd_api_secrets.yml\n\nworkspace/secrets/prd_api_secrets.yml\nSECRET_KEY: \"very_secret\"\n# OPENAI_API_KEY: \"sk-***\"\n\n​\nCreate AWS resources\n\nCreate AWS resources using:\n\nterminal\nshorthand\nphi ws up --env prd --infra aws\n\n\nThis will create:\n\nECS Cluster for the application.\nECS Task Definitions and Services that run the application on the ECS cluster.\nLoadBalancer to route traffic to the application.\nSecurity Groups that control incoming and outgoing traffic.\nSecrets for managing application and database secrets.\nRDS Database for Knowledge Base and Storage.\n\nPress Enter to confirm and grab a cup of coffee while the resources spin up.\n\nThe RDS database takes about 5 minutes to activate.\nThese resources are defined in the workspace/prd_resources.py file.\nUse the ECS console to view services and logs.\nUse the RDS console to view the database instance.\n​\nProduction FastApi\nOpen the LoadBalancer DNS + the /docs endpoint to view the API Endpoints.\nTest the /v1/playground/agent/run endpoint with\n{\n  \"message\": \"howdy\",\n  \"agent_id\": \"example-agent\",\n  \"stream\": true\n}\n\n​\nUpdating Production\n\nFollow this guide to update your production application. You'll need to:\n\nCreate a new image\nUpdate the ECS task definition and services.\n​\nDelete AWS resources\n\nPlay around and then delete AWS resources using:\n\nterminal\nshorthand\nphi ws down --env prd --infra aws\n\n\nor delete individual resource groups using:\n\napp\napi\ndatabase\nphi ws down --env prd --infra aws --group app\n\n​\nNext\n\nCongratulations on running your Agent API on AWS. Next Steps:\n\nRead how to update workspace settings\nRead how to create a git repository for your workspace\nRead how to manage the production application\nRead how to format and validate your code\nRead how to add python libraries\nRead how to add a custom domain and HTTPS\nRead how to implement CI/CD\nChat with us on discord\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nRun locally\nDevelopment Application\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAWS Setup\nUpdate Secrets\nCreate AWS resources\nProduction FastApi\nUpdating Production\nDelete AWS resources\nNext"
  },
  {
    "title": "AWS Resources - Phidata",
    "url": "https://docs.phidata.com/templates/resources/aws/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nAWS\nECS\nRDS\nAWS\nAWS Resources\n\nAWS Resources enable us to create AWS services as pydantic objects, completing our vision of writing software, application and infrastructure code entirely in python.\n\n​\nExamples\n​\nS3 Bucket\n\nCopy the following code to a file resources.py and run phi start resources.py to create a bucket called my-bucket-885.\n\nresources.py\nfrom phi.aws.resource.s3 import S3Bucket\n\n# -*- S3 bucket called my-bucket-885\nprd_bucket = S3Bucket(name=\"my-bucket-885\")\n\n\nMake sure to delete the bucket using phi stop resources.py\n\n​\nSecret Manager\n\nCopy the following code to a file resources.py and run phi start resources.py to create a secret called my-secret.\n\nresources.py\nimport json\nfrom phi.aws.resource.secret import SecretsManager\n\n# -*- Secret called my-secret\nprd_secret = SecretsManager(\n    name=\"my-secret\",\n    secret_string=json.dumps({\"mysecretkey\": \"mysecretvalue\"}),\n    # Read secret variables from my_secrets.yml\n    # secret_files=[Path('my_secrets.yml')],\n)\n\n\nRead the secret in another file called read_my_secret.py\n\nread_my_secret.py\nfrom resources import my_secret\n\nprint(my_secret.get_secret_value(\"mysecretkey\"))\n\n\nRun this file using python read_my_secret.py.\n\nDelete the secret using phi stop resources.py\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nContainer\nECS\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExamples\nS3 Bucket\nSecret Manager"
  },
  {
    "title": "Docker - Phidata",
    "url": "https://docs.phidata.com/templates/resources/docker/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nDocker\nContainer\nAWS\nDocker\nDocker\n\nDocker is a game-changing technology that enables us to run applications locally. We package our Apps into Containers that include everything needed to run the application\n\n​\nDocker Resources\n\nPhidata enables us to define docker resources as pydantic objects so we can build our application layer purely in python. In most cases you will not be creating the Docker Resources directly, instead we’ll use Apps to create the resources for us.\n\ndifference from docker-compose\n\n​\nBenefits\nDefine containers and images as pydantic objects with input and type validation.\nAllows re-use and testing of resources.\nImport them in software layer like regular python objects.\nPackage multiple resources into Apps so we can define “Applications as Code”.\nEnable AI features that interact with the resource from python code.\n​\nContainer\n\nThe DockerContainer class defines a container, for example use the following code to define a container running the whoami image. Start it using phi start resources.py\n\nresources.py\nfrom phi.docker.resource.container import DockerContainer\n\nwhoami = DockerContainer(\n    name='whoami',\n    image='traefik/whoami',\n    ports={'80': 80},\n)\n\n\nTest it by opening http://localhost:80 or using:\n\ncurl -X POST http://localhost:80\n\n\nThe same can be defined as an App:\n\nresources.py\nfrom phi.docker.app.whoami import Whoami\n\nwhoami = Whoami()\n\n\nStop resources using phi stop resources.py\n\n​\nImage\n\nThe DockerImage class defines an image, for example use the following code create your own python image and run it in a container. Build it using phi start resources.py\n\nresources.py\nDockerfile\nfrom phi.docker.resource.container import DockerContainer\nfrom phi.docker.resource.image import DockerImage\n\npython_image = DockerImage(\n    name=\"my/python\",\n    tag=\"3.11\",\n    path=\".\",\n    # push_image=True,\n)\n\npython_container = DockerContainer(\n    name='python',\n    image=python_image.get_image_str(),\n)\n\n\n\n\nMake sure to add the Dockerfile in the current directory.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nContainer\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nDocker Resources\nBenefits\nContainer\nImage"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/agents/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nIntroduction\nPrompts\nTools\nKnowledge\nMemory\nStorage\nStructured Output\nReasoning\nTeams\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nAgents\nIntroduction\n\nAgents are autonomous programs that achieve tasks using language models.\n\nEngineers use phidata to build agents with memory, knowledge, tools and reasoning.\n\n​\nExample: Research Agent\n\nLet’s create a research agent that can search the web, read the top links and write a report for us. We “prompt” the agent using description and instructions.\n\n1\n\nCreate Research Agent\n\nCreate a file research_agent.py\n\nresearch_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.newspaper4k import Newspaper4k\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo(), Newspaper4k()],\n    description=\"You are a senior NYT researcher writing an article on a topic.\",\n    instructions=[\n        \"For a given topic, search for the top 5 links.\",\n        \"Then read each URL and extract the article text, if a URL isn't available, ignore it.\",\n        \"Analyse and prepare an NYT worthy article based on the information.\",\n    ],\n    markdown=True,\n    show_tool_calls=True,\n    add_datetime_to_instructions=True,\n    # debug_mode=True,\n)\nagent.print_response(\"Simulation theory\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install phidata openai duckduckgo-search newspaper4k lxml_html_clean\n\n\nRun the agent\n\npython research_agent.py\n\n\nThe description and instructions are converted to the system prompt and the input (e.g. Simulation theory) is passed as the user prompt.\n\nUse debug_mode=True to view the raw logs behind the scenes.\n\n​\nCapturing the Agent’s response in a variable\n\nWhile Agent.print_response() is useful for quick experiments, we typically want to capture the agent’s response in a variable to either pass to the frontend, another agent or use in our application. The Agent.run() function returns the response as a RunResponse object.\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.utils.pprint import pprint_run_response\n\nagent = Agent(...)\n\n# Run agent and return the response as a variable\nresponse: RunResponse = agent.run(\"Simulation theory\")\n# Print the response in markdown format\npprint_run_response(response, markdown=True)\n\n\nBy default stream=False, set stream=True to return a stream of RunResponse objects.\n\nfrom typing import Iterator\n\n# Run agent and return the response as a stream\nresponse_stream: Iterator[RunResponse] = agent.run(\"Simulation theory\", stream=True)\n# Print the response stream in markdown format\npprint_run_response(response_stream, markdown=True, show_time=True)\n\n​\nRunResponse\n\nThe Agent.run() function returns either a RunResponse object or an Iterator[RunResponse] when stream=True.\n\n​\nRunResponse Attributes\nAttribute\tType\tDefault\tDescription\ncontent\tAny\tNone\tContent of the response.\ncontent_type\tstr\t\"str\"\tSpecifies the data type of the content.\ncontext\tList[MessageContext]\tNone\tThe context added to the response for RAG.\nevent\tstr\tRunEvent.run_response.value\tEvent type of the response.\nevent_data\tDict[str, Any]\tNone\tData associated with the event.\nmessages\tList[Message]\tNone\tA list of messages included in the response.\nmetrics\tDict[str, Any]\tNone\tUsage metrics of the run.\nmodel\tstr\tNone\tThe model used in the run.\nrun_id\tstr\tNone\tRun Id.\nagent_id\tstr\tNone\tAgent Id for the run.\nsession_id\tstr\tNone\tSession Id for the run.\ntools\tList[Dict[str, Any]]\tNone\tList of tools provided to the model.\ncreated_at\tint\t-\tUnix timestamp of the response creation.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nGetting Help\nPrompts\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample: Research Agent\nCapturing the Agent’s response in a variable\nRunResponse\nRunResponse Attributes"
  },
  {
    "title": "PgVector - Phidata",
    "url": "https://docs.phidata.com/examples/integrations/pgvector",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nComposio\nPgVector\nSingleStore\nLanceDB\nPinecone\nQdrant\nChromaDB\nPortkey\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nIntegrations\nPgVector\n\nThe PgVector Agent uses PgVector as Knowledge Base and Storage for the Agent.\n\nfrom phi.agent import Agent\nfrom phi.storage.agent.postgres import PgAgentStorage\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nagent = Agent(\n    storage=PgAgentStorage(table_name=\"recipe_agent\", db_url=db_url),\n    knowledge_base=PDFUrlKnowledgeBase(\n        urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n        vector_db=PgVector(table_name=\"recipe_documents\", db_url=db_url),\n    ),\n    # Show tool calls in the response\n    show_tool_calls=True,\n    # Enable the agent to search the knowledge base\n    search_knowledge=True,\n    # Enable the agent to read the chat history\n    read_chat_history=True,\n)\n# Comment out after first run\nagent.knowledge_base.load(recreate=False)  # type: ignore\n\nagent.print_response(\"How do I make pad thai?\", markdown=True)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nRun PgVector\n\ndocker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\n3\n\nInstall libraries\n\npip install -U pgvector pypdf \"psycopg[binary]\" sqlalchemy phidata\n\n4\n\nRun PgVector Agent\n\nMac\nWindows\npython cookbook/integrations/pgvector/agent.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nComposio\nSingleStore\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage\nInformation"
  },
  {
    "title": "OpenAI - Phidata",
    "url": "https://docs.phidata.com/examples/provider/openai",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nOpenAI\nAzure\nClaude\nCohere\nFireworks\nGemini\nGroq\nMistral\nOllama\nTogether\nAWS Bedrock\nDeepSeek\nHuggingFace\nNvidia\nOpenRouter\nSambanova\nxAI\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nModels\nOpenAI\n​\nExample\nagent.py\n\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openai import OpenAIChat\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n)\n\n# Get the response in a variable\n# run: RunResponse = agent.run(\"Share a 2 sentence horror story.\")\n# print(run.content)\n\n# Print the response in the terminal\nagent.print_response(\"Share a 2 sentence horror story.\")\n\n\n​\nUsage\n\nGet your key from OpenAI here.\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install -U openai phidata\n\n3\n\nExport `OPENAI_API_KEY`\n\nexport OPENAI_API_KEY=sk-xxx\n\n4\n\nRun OpenAI Agent\n\npython cookbook/providers/openai/basic.py\n\n​\nInformation\nView on Github\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nVision Agent\nAzure\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage\nInformation"
  },
  {
    "title": "Advanced Example - News Report Generator - Phidata",
    "url": "https://docs.phidata.com/workflows/news-report-generator",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nIntroduction\nSession State\nStreaming\nAdvanced Example - News Report Generator\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nWorkflows\nAdvanced Example - News Report Generator\n\nLet’s work through a slightly more complex example of a news report generator. We want full control over the workflow, including the ability to stream the output. We also want to cache the results of the web search and the scrape.\n\nIn this workflow, we will generate a comprehensive news report on a given topic.\n\nFirst we will search the web for articles on the topic:\nUse cached search results if available and use_search_cache is True.\nOtherwise, perform a new web search.\nNext we will scrape the content of each article:\nUse cached scraped articles if available and use_scrape_cache is True.\nScrape new articles that aren’t in the cache.\nFinally we will generate the final report using the scraped article contents.\n\nThe caching mechanism is implemented using the session_state which is a dictionary that is persisted across workflow runs. This really helps with performance and cost.\n\n​\nFull Code\nnews_report_generator.py\nimport json\nfrom textwrap import dedent\nfrom typing import Optional, Dict, Iterator\n\nfrom pydantic import BaseModel, Field\n\nfrom phi.agent import Agent\nfrom phi.workflow import Workflow, RunResponse, RunEvent\nfrom phi.storage.workflow.sqlite import SqlWorkflowStorage\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.newspaper4k import Newspaper4k\nfrom phi.utils.pprint import pprint_run_response\nfrom phi.utils.log import logger\n\n\nclass NewsArticle(BaseModel):\n    title: str = Field(..., description=\"Title of the article.\")\n    url: str = Field(..., description=\"Link to the article.\")\n    summary: Optional[str] = Field(..., description=\"Summary of the article if available.\")\n\n\nclass SearchResults(BaseModel):\n    articles: list[NewsArticle]\n\n\nclass ScrapedArticle(BaseModel):\n    title: str = Field(..., description=\"Title of the article.\")\n    url: str = Field(..., description=\"Link to the article.\")\n    summary: Optional[str] = Field(..., description=\"Summary of the article if available.\")\n    content: Optional[str] = Field(\n        ...,\n        description=\"Content of the in markdown format if available. Return None if the content is not available or does not make sense.\",\n    )\n\n\nclass GenerateNewsReport(Workflow):\n    web_searcher: Agent = Agent(\n        tools=[DuckDuckGo()],\n        instructions=[\n            \"Given a topic, search for 10 articles and return the 5 most relevant articles.\",\n        ],\n        response_model=SearchResults,\n    )\n\n    article_scraper: Agent = Agent(\n        tools=[Newspaper4k()],\n        instructions=[\n            \"Given a url, scrape the article and return the title, url, and markdown formatted content.\",\n            \"If the content is not available or does not make sense, return None as the content.\",\n        ],\n        response_model=ScrapedArticle,\n    )\n\n    writer: Agent = Agent(\n        description=\"You are a Senior NYT Editor and your task is to write a new york times worthy cover story.\",\n        instructions=[\n            \"You will be provided with news articles and their contents.\",\n            \"Carefully **read** each article and **think** about the contents\",\n            \"Then generate a final New York Times worthy article in the <article_format> provided below.\",\n            \"Break the article into sections and provide key takeaways at the end.\",\n            \"Make sure the title is catchy and engaging.\",\n            \"Always provide sources for the article, do not make up information or sources.\",\n            \"REMEMBER: you are writing for the New York Times, so the quality of the article is important.\",\n        ],\n        expected_output=dedent(\"\"\"\\\n        An engaging, informative, and well-structured article in the following format:\n        <article_format>\n        ## Engaging Article Title\n\n        ### {Overview or Introduction}\n        {give a brief introduction of the article and why the user should read this report}\n        {make this section engaging and create a hook for the reader}\n\n        ### {Section title}\n        {break the article into sections}\n        {provide details/facts/processes in this section}\n\n        ... more sections as necessary...\n\n        ### Key Takeaways\n        {provide key takeaways from the article}\n\n        ### Sources\n        - [Title](url)\n        - [Title](url)\n        - [Title](url)\n        </article_format>\n        \"\"\"),\n    )\n\n    def run(\n        self, topic: str, use_search_cache: bool = True, use_scrape_cache: bool = True, use_cached_report: bool = False\n    ) -> Iterator[RunResponse]:\n        \"\"\"\n        Generate a comprehensive news report on a given topic.\n\n        This function orchestrates a workflow to search for articles, scrape their content,\n        and generate a final report. It utilizes caching mechanisms to optimize performance.\n\n        Args:\n            topic (str): The topic for which to generate the news report.\n            use_search_cache (bool, optional): Whether to use cached search results. Defaults to True.\n            use_scrape_cache (bool, optional): Whether to use cached scraped articles. Defaults to True.\n            use_cached_report (bool, optional): Whether to return a previously generated report on the same topic. Defaults to False.\n\n        Returns:\n            Iterator[RunResponse]: An stream of objects containing the generated report or status information.\n\n        Workflow Steps:\n        1. Check for a cached report if use_cached_report is True.\n        2. Search the web for articles on the topic:\n            - Use cached search results if available and use_search_cache is True.\n            - Otherwise, perform a new web search.\n        3. Scrape the content of each article:\n            - Use cached scraped articles if available and use_scrape_cache is True.\n            - Scrape new articles that aren't in the cache.\n        4. Generate the final report using the scraped article contents.\n\n        The function utilizes the `session_state` to store and retrieve cached data.\n        \"\"\"\n        logger.info(f\"Generating a report on: {topic}\")\n\n        # Use the cached report if use_cached_report is True\n        if use_cached_report and \"reports\" in self.session_state:\n            logger.info(\"Checking if cached report exists\")\n            for cached_report in self.session_state[\"reports\"]:\n                if cached_report[\"topic\"] == topic:\n                    yield RunResponse(\n                        run_id=self.run_id,\n                        event=RunEvent.workflow_completed,\n                        content=cached_report[\"report\"],\n                    )\n                    return\n\n        ####################################################\n        # Step 1: Search the web for articles on the topic\n        ####################################################\n\n        # 1.1: Get cached search_results from the session state if use_search_cache is True\n        search_results: Optional[SearchResults] = None\n        try:\n            if use_search_cache and \"search_results\" in self.session_state:\n                search_results = SearchResults.model_validate(self.session_state[\"search_results\"])\n                logger.info(f\"Found {len(search_results.articles)} articles in cache.\")\n        except Exception as e:\n            logger.warning(f\"Could not read search results from cache: {e}\")\n\n        # 1.2: If there are no cached search_results, ask the web_searcher to find the latest articles\n        if search_results is None:\n            web_searcher_response: RunResponse = self.web_searcher.run(topic)\n            if (\n                web_searcher_response\n                and web_searcher_response.content\n                and isinstance(web_searcher_response.content, SearchResults)\n            ):\n                logger.info(f\"WebSearcher identified {len(web_searcher_response.content.articles)} articles.\")\n                search_results = web_searcher_response.content\n                # Save the search_results in the session state\n                self.session_state[\"search_results\"] = search_results.model_dump()\n\n        # 1.3: If no search_results are found for the topic, end the workflow\n        if search_results is None or len(search_results.articles) == 0:\n            yield RunResponse(\n                run_id=self.run_id,\n                event=RunEvent.workflow_completed,\n                content=f\"Sorry, could not find any articles on the topic: {topic}\",\n            )\n            return\n\n        ####################################################\n        # Step 2: Scrape each article\n        ####################################################\n\n        # 2.1: Get cached scraped_articles from the session state if use_scrape_cache is True\n        scraped_articles: Dict[str, ScrapedArticle] = {}\n        if (\n            use_scrape_cache\n            and \"scraped_articles\" in self.session_state\n            and isinstance(self.session_state[\"scraped_articles\"], dict)\n        ):\n            for url, scraped_article in self.session_state[\"scraped_articles\"].items():\n                try:\n                    validated_scraped_article = ScrapedArticle.model_validate(scraped_article)\n                    scraped_articles[validated_scraped_article.url] = validated_scraped_article\n                except Exception as e:\n                    logger.warning(f\"Could not read scraped article from cache: {e}\")\n            logger.info(f\"Found {len(scraped_articles)} scraped articles in cache.\")\n\n        # 2.2: Scrape the articles that are not in the cache\n        for article in search_results.articles:\n            if article.url in scraped_articles:\n                logger.info(f\"Found scraped article in cache: {article.url}\")\n                continue\n\n            article_scraper_response: RunResponse = self.article_scraper.run(article.url)\n            if (\n                article_scraper_response\n                and article_scraper_response.content\n                and isinstance(article_scraper_response.content, ScrapedArticle)\n            ):\n                scraped_articles[article_scraper_response.content.url] = article_scraper_response.content.model_dump()\n                logger.info(f\"Scraped article: {article_scraper_response.content.url}\")\n\n        # 2.3: Save the scraped_articles in the session state\n        self.session_state[\"scraped_articles\"] = {k: v for k, v in scraped_articles.items()}\n\n        ####################################################\n        # Step 3: Write a report\n        ####################################################\n\n        # 3.1: Generate the final report\n        logger.info(\"Generating final report\")\n        writer_input = {\n            \"topic\": topic,\n            \"articles\": [v.model_dump() for v in scraped_articles.values()],\n        }\n        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)\n\n        # 3.2: Save the writer_response in the session state\n        if \"reports\" not in self.session_state:\n            self.session_state[\"reports\"] = []\n        self.session_state[\"reports\"].append({\"topic\": topic, \"report\": self.writer.run_response.content})\n\n\n# The topic to generate a report on\ntopic = \"IBM Hashicorp Acquisition\"\n\n# Instantiate the workflow\ngenerate_news_report = GenerateNewsReport(\n    session_id=f\"generate-report-on-{topic}\",\n    storage=SqlWorkflowStorage(\n        table_name=\"generate_news_report_workflows\",\n        db_file=\"tmp/workflows.db\",\n    ),\n)\n\n# Run workflow\nreport_stream: Iterator[RunResponse] = generate_news_report.run(\n    topic=topic, use_search_cache=True, use_scrape_cache=True, use_cached_report=False\n)\n\n# Print the response\npprint_run_response(report_stream, markdown=True)\n\n​\nRun the workflow\n\nInstall dependencies\n\npip install openai duckduckgo-search newspaper4k lxml_html_clean phidata\n\n\nRun the workflow\n\npython news_report_generator.py\n\n\nTest if the results are cached, run the workflow again with the same parameters.\n\npython news_report_generator.py\n\n​\nVideo\n\nCheckout the recording of the workflow running and see how the results are cached in the 2nd run.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nStreaming\nInstall & Upgrade\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nFull Code\nRun the workflow\nVideo"
  },
  {
    "title": "Python Function Agent - Phidata",
    "url": "https://docs.phidata.com/examples/agents/python-function-agent",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nPython Function Agent\n\nCreate a file python_function_agent.py with the following code:\n\npython_function_agent.py\nimport json\nimport httpx\n\nfrom phi.agent import Agent\n\n\ndef get_top_hackernews_stories(num_stories: int = 10) -> str:\n    \"\"\"Use this function to get top stories from Hacker News.\n\n    Args:\n        num_stories (int): Number of stories to return. Defaults to 10.\n\n    Returns:\n        str: JSON string of top stories.\n    \"\"\"\n\n    # Fetch top story IDs\n    response = httpx.get(\"https://hacker-news.firebaseio.com/v0/topstories.json\")\n    story_ids = response.json()\n\n    # Fetch story details\n    stories = []\n    for story_id in story_ids[:num_stories]:\n        story_response = httpx.get(f\"https://hacker-news.firebaseio.com/v0/item/{story_id}.json\")\n        story = story_response.json()\n        if \"text\" in story:\n            story.pop(\"text\", None)\n        stories.append(story)\n    return json.dumps(stories)\n\n\nagent = Agent(tools=[get_top_hackernews_stories], show_tool_calls=True, markdown=True)\nagent.print_response(\"Summarize the top 5 stories on hackernews?\", stream=True)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai phidata\n\n3\n\nRun the agent\n\npython python_function_agent.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nStructured Output\nVision Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "ArXiv Research Agent - Phidata",
    "url": "https://docs.phidata.com/examples/use-case/arxiv-research",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nUse Cases\nSql Agent\nWorld Building\nArXiv Research Agent\nHow To\nClone Cookbook\nUse Cases\nArXiv Research Agent\n\nThis guide is in the works\n\nMessage us on discord if you need help.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWorld Building\nClone Cookbook\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Install & Setup - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/install",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nInstall & Setup\n​\nInstall phidata\n\nWe highly recommend:\n\nInstalling phidata using pip in a python virtual environment.\nCreating an ai directory for your ai workspaces\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create an ai directory with a python virtual environment.\n\nMac\nWindows\nmkdir ai && cd ai\n\npython3 -m venv aienv\nsource aienv/bin/activate\n\n2\n\nInstall phidata\n\nInstall phidata using pip\n\nMac\nWindows\npip install -U phidata\n\n3\n\nInstall docker\n\nInstall docker desktop to run apps locally\n\n\n\n\nIf you encounter errors, try updating pip using python -m pip install --upgrade pip\n\n​\nUpgrade phidata\n\nTo upgrade phidata, run this in your virtual environment\n\npip install -U phidata --no-cache-dir\n\n​\nSetup workspace\n\nIf you have an existing phidata workspace, set it up using\n\nphi ws setup\n\n​\nReset phidata\n\nTo reset the phidata config, run\n\nphi init -r\n\n\nThis does not delete any physical data\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nProduction Application\nAdd Secrets\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nInstall phidata\nUpgrade phidata\nSetup workspace\nReset phidata"
  },
  {
    "title": "Format & Validate - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/format-and-validate",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace Settings\nCreate Git Repo\nAdd New Users\nFormat & Validate\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Workspace\nFormat & Validate\n​\nFormat\n\nFormatting the codebase using a set standard saves us time and mental energy. Phidata templates are pre-configured with ruff that you can run using a helper script or directly.\n\nterminal\nruff\n./scripts/format.sh\n\n​\nValidate\n\nLinting and Type Checking add an extra layer of protection to the codebase. We highly recommending running the validate script before pushing any changes.\n\nPhidata templates are pre-configured with ruff and mypy that you can run using a helper script or directly. Checkout the pyproject.toml file for the configuration.\n\nterminal\nruff\nmypy\n./scripts/validate.sh\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAdd New Users\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nFormat\nValidate"
  },
  {
    "title": "Development Application - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/development-app",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nDevelopment Application\nProduction Application\nInstall & Setup\nAdd Secrets\nEnvironment variables\nDatabase Tables\nCI/CD\nCustom Domain & HTTPS\nSSH Access\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Application\nDevelopment Application\n\nYour development application runs locally on docker and its resources are defined in the workspace/dev_resources.py file. This guide shows how to:\n\nBuild a development image\nRestart all docker containers\nRecreate development resources\n​\nWorkspace Settings\n\nThe WorkspaceSettings object in the workspace/settings.py file defines common settings used by your workspace apps and resources.\n\n​\nBuild your development image\n\nYour application uses the phidata images by default. To use your own image:\n\nOpen workspace/settings.py file\nUpdate the image_repo to your image repository\nSet build_images=True\nworkspace/settings.py\nws_settings = WorkspaceSettings(\n    ...\n    # -*- Image Settings\n    # Repository for images\n    image_repo=\"local\",\n    # Build images locally\n    build_images=True,\n)\n\n​\nBuild a new image\n\nBuild the development image using:\n\nterminal\nshort options\nphi ws up --env dev --infra docker --type image\n\n\nTo force rebuild images, use the --force or -f flag\n\nterminal\nshort options\nphi ws up --env dev --infra docker --type image --force\n\n​\nRestart all containers\n\nRestart all docker containers using:\n\nterminal\nshort options\nphi ws restart --env dev --infra docker --type container\n\n​\nRecreate development resources\n\nTo recreate all dev resources, use the --force flag:\n\nterminal\nfull options\nshorthand\nshort options\nphi ws up -f\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nRun on AWS\nProduction Application\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWorkspace Settings\nBuild your development image\nBuild a new image\nRestart all containers\nRecreate development resources"
  },
  {
    "title": "Create Git Repo - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/git-repo",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace Settings\nCreate Git Repo\nAdd New Users\nFormat & Validate\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Workspace\nCreate Git Repo\n\nCreate a git repository to share your application with your team.\n\n1\n\nCreate a git repository\n\nCreate a new git repository.\n\n2\n\nPush your code\n\nPush your code to the git repository.\n\nterminal\ngit init\ngit add .\ngit commit -m \"Init LLM App\"\ngit branch -M main\ngit remote add origin https://github.com/[YOUR_GIT_REPO].git\ngit push -u origin main\n\n3\n\nAsk your team to join\n\nAsk your team to follow the setup steps for new users to use this workspace.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWorkspace Settings\nAdd New Users\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Workspace Settings - Phidata",
    "url": "https://docs.phidata.com/templates/how-to/workspace-settings",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace Settings\nCreate Git Repo\nAdd New Users\nFormat & Validate\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nManage Workspace\nWorkspace Settings\n\nThe WorkspaceSettings object in the workspace/settings.py file defines common settings used by your apps and resources. Here are the settings we recommend updating:\n\nworkspace/settings.py\nws_settings = WorkspaceSettings(\n    # Update this to your project name\n    ws_name=\"ai\",\n    # Add your AWS subnets\n    subnet_ids=[\"subnet-xyz\", \"subnet-xyz\"],\n    # Add your image repository\n    image_repo=\"[ACCOUNT_ID].dkr.ecr.us-east-1.amazonaws.com\",\n    # Set to True to build images locally\n    build_images=True,\n    # Set to True to push images after building\n    push_images=True,\n)\n\n\nWorkspaceSettings can also be updated using environment variables or the .env file.\n\nCheckout the example.env file for an example.\n\n​\nWorkspace Name\n\nThe ws_name is used to name your apps and resources. Change it to your project or team name, for example:\n\nws_name=\"booking-ai\"\nws_name=\"reddit-ai\"\nws_name=\"vantage-ai\"\n\nThe ws_name is used to name:\n\nThe image for your application\nApps like db, streamlit app and fastapi server\nResources like buckets, secrets and loadbalancers\n\nCheckout the workspace/dev_resources.py and workspace/prd_resources.py file to see how its used.\n\n​\nImage Repository\n\nThe image_repo defines the repo for your image.\n\nIf using dockerhub it would be something like phidata.\nIf using ECR it would be something like [ACCOUNT_ID].dkr.ecr.us-east-1.amazonaws.com\n\nCheckout the dev_image in workspace/dev_resources.py and prd_image in workspace/prd_resources.py to see how its used.\n\n​\nBuild Images\n\nSetting build_images=True will build images locally when running phi ws up dev:docker or phi ws up prd:docker.\n\nCheckout the dev_image in workspace/dev_resources.py and prd_image in workspace/prd_resources.py to see how its used.\n\nRead more about:\n\nBuilding your development image\nBuilding your production image\n​\nPush Images\n\nSetting push_images=True will push images after building when running phi ws up dev:docker or phi ws up prd:docker.\n\nCheckout the dev_image in workspace/dev_resources.py and prd_image in workspace/prd_resources.py to see how its used.\n\nRead more about:\n\nBuilding your development image\nBuilding your production image\n​\nAWS Settings\n\nThe aws_region and subnet_ids provide values used for creating production resources. Checkout the workspace/prd_resources.py file to see how its used.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSSH Access\nCreate Git Repo\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWorkspace Name\nImage Repository\nBuild Images\nPush Images\nAWS Settings"
  },
  {
    "title": "Run on AWS - Phidata",
    "url": "https://docs.phidata.com/templates/agent-app/run-aws",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nRun locally\nRun on AWS\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nAgent App\nRun on AWS\n\nLet’s run the Agent App in production on AWS.\n\n​\nAWS Setup\n1\n\nUpdate Credentials\n\nTo run on AWS, you need one of the following:\n\nThe ~/.aws/credentials file with your AWS credentials\nor AWS_ACCESS_KEY_ID + AWS_SECRET_ACCESS_KEY environment variables\n\nTo create the credentials file, install the aws cli and run aws configure\n\n2\n\nUpdate region and subnets\n\nAdd 2 subnets to the workspace/settings.py file (required for ECS services)\n\nworkspace/settings.py\nws_settings = WorkspaceSettings(\n    ...\n    # -*- AWS settings\n    # Add your Subnet IDs here\n    subnet_ids=[\"subnet-xyz\", \"subnet-xyz\"],\n    ...\n)\n\n\nPlease check that the subnets belong to the selected aws_region\n\n​\nUpdate Secrets\n1\n\nStreamlit App Password\n\nUpdate the streamlit app password in workspace/secrets/prd_app_secrets.yml\n\nworkspace/secrets/prd_app_secrets.yml\nAPP_PASSWORD: \"admin\"\n# OPENAI_API_KEY: \"sk-***\"\n\n2\n\nRDS database password\n\nUpdate the RDS database password in workspace/secrets/prd_db_secrets.yml\n\nworkspace/secrets/prd_db_secrets.yml\n# Secrets used by prd RDS database\nMASTER_USERNAME: ai\nMASTER_USER_PASSWORD: \"ai9999!!\"\n\n​\nCreate AWS resources\n\nCreate AWS resources using:\n\nterminal\nshorthand\nphi ws up --env prd --infra aws\n\n\nThis will create:\n\nECS Cluster for the application.\nECS Task Definitions and Services that run the application on the ECS cluster.\nLoadBalancer to route traffic to the application.\nSecurity Groups that control incoming and outgoing traffic.\nSecrets for managing application and database secrets.\nRDS Database for Knowledge Base and Storage.\n\nPress Enter to confirm and grab a cup of coffee while the resources spin up.\n\nThe RDS database takes about 5 minutes to activate.\nThese resources are defined in the workspace/prd_resources.py file.\nUse the ECS console to view services and logs.\nUse the RDS console to view the database instance.\n​\nProduction Streamlit\n\nOpen the LoadBalancer DNS provided when creating the Streamlit App\n\nEnter the APP_PASSWORD from the prd_app_secrets.yml file (default: admin)\nEnter a username and test your AI Agent.\n​\nProduction FastApi\nOpen the LoadBalancer DNS + the /docs endpoint to view the API Endpoints.\nTest the /v1/playground/agent/run endpoint with\n{\n  \"message\": \"howdy\",\n  \"agent_id\": \"example-agent\",\n  \"stream\": true\n}\n\n​\nUpdating Production\n\nFollow this guide to update your production application. You'll need to:\n\nCreate a new image\nUpdate the ECS task definition and services.\n​\nDelete AWS resources\n\nPlay around and then delete AWS resources using:\n\nterminal\nshorthand\nphi ws down --env prd --infra aws\n\n\nor delete individual resource groups using:\n\napp\napi\ndatabase\nphi ws down --env prd --infra aws --group app\n\n​\nNext\n\nCongratulations on running your Agent App on AWS. Next Steps:\n\nRead how to update workspace settings\nRead how to create a git repository for your workspace\nRead how to manage the production application\nRead how to format and validate your code\nRead how to add python libraries\nRead how to add a custom domain and HTTPS\nRead how to implement CI/CD\nChat with us on discord\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nRun locally\nRun locally\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAWS Setup\nUpdate Secrets\nCreate AWS resources\nProduction Streamlit\nProduction FastApi\nUpdating Production\nDelete AWS resources\nNext"
  },
  {
    "title": "Connecting to Tableplus - Phidata",
    "url": "https://docs.phidata.com/faq/connecting-to-tableplus",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nFAQs\nDocker Connection Error\nEnvironment Variables Setup\nCommand line authentication\nConnecting to Tableplus\nFAQs\nConnecting to Tableplus\n\nIf you want to inspect your pgvector container to explore your storage or knowledge base, you can use TablePlus. Follow these steps:\n\n​\nStep 1: Start Your pgvector Container\n\nRun the following command to start a pgvector container locally:\n\ndocker run -d \\\n  -e POSTGRES_DB=ai \\\n  -e POSTGRES_USER=ai \\\n  -e POSTGRES_PASSWORD=ai \\\n  -e PGDATA=/var/lib/postgresql/data/pgdata \\\n  -v pgvolume:/var/lib/postgresql/data \\\n  -p 5532:5432 \\\n  --name pgvector \\\n  phidata/pgvector:16\n\nPOSTGRES_DB=ai sets the default database name.\nPOSTGRES_USER=ai and POSTGRES_PASSWORD=ai define the database credentials.\nThe container exposes port 5432 (mapped to 5532 on your local machine).\n​\nStep 2: Configure TablePlus\nOpen TablePlus: Launch the TablePlus application.\nCreate a New Connection: Click on the + icon to add a new connection.\nSelect PostgreSQL: Choose PostgreSQL as the database type.\n\nFill in the following connection details:\n\nHost: localhost\nPort: 5532\nDatabase: ai\nUser: ai\nPassword: ai\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nCommand line authentication\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nStep 1: Start Your pgvector Container\nStep 2: Configure TablePlus"
  },
  {
    "title": "Command line authentication - Phidata",
    "url": "https://docs.phidata.com/faq/phi-auth",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nFAQs\nDocker Connection Error\nEnvironment Variables Setup\nCommand line authentication\nConnecting to Tableplus\nFAQs\nCommand line authentication\n\nIf you run phi auth and you get the error: CLI authentication failed or your CLI gets stuck on\n\nWaiting for a response from browser...\n\n\nIt means that your CLI was not able to authenticate with your Phidata account on phidata.app\n\nThe quickest fix for this is to export your PHI_API_KEY environment variable. You can do this by running the following command:\n\nexport PHI_API_KEY=<your_api_key>\n\n\nYour API key can be found on phidata.app in the sidebar under API Key.\n\nReason for CLI authentication failure:\n\nSome browsers like Safari and Brave block connection to the localhost domain. Browsers like Chrome work great with phi auth.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nEnvironment Variables Setup\nConnecting to Tableplus\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify"
  },
  {
    "title": "Setting Environment Variables - Phidata",
    "url": "https://docs.phidata.com/faq/environment_variables",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nFAQs\nDocker Connection Error\nEnvironment Variables Setup\nCommand line authentication\nConnecting to Tableplus\nFAQs\nSetting Environment Variables\n\nTo configure your environment for applications, you may need to set environment variables. This guide provides instructions for setting environment variables in both macOS (Shell) and Windows (PowerShell and Windows Command Prompt).\n\n​\nmacOS\n​\nSetting Environment Variables in Shell\n​\nTemporary Environment Variables\n\nThese environment variables will only be available in the current shell session.\n\nexport VARIABLE_NAME=\"value\"\n\n\nTo display the environment variable:\n\necho $VARIABLE_NAME\n\n​\nPermanent Environment Variables\n\nTo make environment variables persist across sessions, add them to your shell configuration file (e.g., .bashrc, .bash_profile, .zshrc).\n\nFor Zsh:\n\necho 'export VARIABLE_NAME=\"value\"' >> ~/.zshrc\nsource ~/.zshrc\n\n\nTo display the environment variable:\n\necho $VARIABLE_NAME\n\n​\nWindows\n​\nSetting Environment Variables in PowerShell\n​\nTemporary Environment Variables\n\nThese environment variables will only be available in the current PowerShell session.\n\n$env:VARIABLE_NAME = \"value\"\n\n\nTo display the environment variable:\n\necho $env:VARIABLE_NAME\n\n​\nPermanent Environment Variables\n\nTo make environment variables persist across sessions, add them to your PowerShell profile script (e.g., Microsoft.PowerShell_profile.ps1).\n\nnotepad $PROFILE\n\n\nAdd the following line to the profile script:\n\n$env:VARIABLE_NAME = \"value\"\n\n\nSave and close the file, then reload the profile:\n\n. $PROFILE\n\n\nTo display the environment variable:\n\necho $env:VARIABLE_NAME\n\n​\nSetting Environment Variables in Windows Command Prompt\n​\nTemporary Environment Variables\n\nThese environment variables will only be available in the current Command Prompt session.\n\nset VARIABLE_NAME=value\n\n\nTo display the environment variable:\n\necho %VARIABLE_NAME%\n\n​\nPermanent Environment Variables\n\nTo make environment variables persist across sessions, you can use the setx command:\n\nsetx VARIABLE_NAME \"value\"\n\n\nNote: After setting an environment variable using setx, you need to restart the Command Prompt or any applications that need to read the new environment variable.\n\nTo display the environment variable in a new Command Prompt session:\n\necho %VARIABLE_NAME%\n\n\nBy following these steps, you can effectively set and display environment variables in macOS Shell, Windows Command Prompt, and PowerShell. This will ensure your environment is properly configured for your applications.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nDocker Connection Error\nCommand line authentication\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nmacOS\nSetting Environment Variables in Shell\nTemporary Environment Variables\nPermanent Environment Variables\nWindows\nSetting Environment Variables in PowerShell\nTemporary Environment Variables\nPermanent Environment Variables\nSetting Environment Variables in Windows Command Prompt\nTemporary Environment Variables\nPermanent Environment Variables"
  },
  {
    "title": "PythonAgent - Phidata",
    "url": "https://docs.phidata.com/reference/agents/python",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nPython\nDuckDb\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nCustom Agents\nPythonAgent\n​\nExample\npython_agent.py\nfrom phi.agent.python import PythonAgent\nfrom phi.file.local.csv import CsvFile\n\npython_agent = PythonAgent(\n    files=[\n        CsvFile(\n            path=\"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n            description=\"Contains information about movies from IMDB.\",\n        )\n    ],\n    pip_install=True,\n    show_function_calls=True,\n)\n\npython_agent.print_response(\"What is the average rating of movies?\")\n\n​\nPythonAgent Params\nParameter\tType\tDefault\tDescription\nname\tstr\t\"PythonAgent\"\tName of the PythonAgent.\nfiles\tList[File]\tNone\tList of Files available for the PythonAgent.\nfile_information\tstr\tNone\tProvide information about Files as a string.\ncharting_libraries\tList[str]\t['plotly', 'matplotlib', 'seaborn']\tList of charting libraries the PythonAgent can use.\nfollowups\tbool\tFalse\tIf the PythonAgent is allowed to ask follow-up questions.\nread_tool_call_history\tbool\tTrue\tIf the DuckDbAgent is allowed to read the tool call history.\nbase_dir\tPath\t.\tWhere to save files if needed.\nsave_and_run\tbool\tTrue\tIf the PythonAgent is allowed to save and run python code.\npip_install\tbool\tFalse\tIf the PythonAgent is allowed to pip install libraries. Disabled by default for security reasons.\nrun_code\tbool\tFalse\tIf the PythonAgent is allowed to run python code directly. Disabled by default for security reasons.\nlist_files\tbool\tFalse\tIf the PythonAgent is allowed to list files.\nrun_files\tbool\tTrue\tIf the PythonAgent is allowed to run files.\nread_files\tbool\tFalse\tIf the PythonAgent is allowed to read files.\nsafe_globals\tdict\tNone\tProvide a list of global variables to for the PythonAgent.\nsafe_locals\tdict\tNone\tProvide a list of local variables to for the PythonAgent.\nadd_chat_history_to_messages\tbool\tTrue\tIf the chat history should be added to the messages.\nnum_history_messages\tint\t6\tNumber of history messages to add to the response.\n​\nAgent Reference\n\nPythonAgent is a subclass of the Agent class and has access to the same params\n\nParameter\tType\tDefault\tDescription\nmodel\tOptional[Model]\tNone\tModel to use for this Agent (alias: \"provider\")\nname\tOptional[str]\tNone\tAgent name\nagent_id\tOptional[str]\tNone\tAgent UUID (autogenerated if not set)\nagent_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with this agent\nintroduction\tOptional[str]\tNone\tAgent introduction. This is added to the chat history when a run is started.\nuser_id\tOptional[str]\tNone\tID of the user interacting with this agent\nuser_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with the user interacting with this agent\nsession_id\tOptional[str]\tNone\tSession UUID (autogenerated if not set)\nsession_name\tOptional[str]\tNone\tSession name\nsession_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with this session\nmemory\tAgentMemory\tAgentMemory()\tAgent Memory\nadd_history_to_messages\tbool\tFalse\tAdd chat history to the messages sent to the Model. (alias: \"add_chat_history_to_messages\")\nnum_history_responses\tint\t3\tNumber of historical responses to add to the messages.\nknowledge\tOptional[AgentKnowledge]\tNone\tAgent Knowledge (alias: \"knowledge_base\")\nadd_context\tbool\tFalse\tEnable RAG by adding context from AgentKnowledge to the user prompt.\nretriever\tOptional[Callable[..., Optional[list[dict]]]]\tNone\tFunction to get context to add to the user_message\ncontext_format\tLiteral[\"json\", \"yaml\"]\t\"json\"\tFormat of the context\nadd_context_instructions\tbool\tFalse\tIf True, add instructions for using the context to the system prompt\nstorage\tOptional[AgentStorage]\tNone\tAgent Storage\ntools\tOptional[List[Union[Tool, Toolkit, Callable, Dict, Function]]]\tNone\tA list of tools provided to the Model.\nshow_tool_calls\tbool\tFalse\tShow tool calls in Agent response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) tool is called by the model.\nreasoning\tbool\tFalse\tEnable reasoning by working through the problem step by step.\nreasoning_model\tOptional[Model]\tNone\tModel to use for reasoning\nreasoning_agent\tOptional[Agent]\tNone\tAgent to use for reasoning\nreasoning_min_steps\tint\t1\tMinimum number of reasoning steps\nreasoning_max_steps\tint\t10\tMaximum number of reasoning steps\nread_chat_history\tbool\tFalse\tAdd a tool that allows the Model to read the chat history.\nsearch_knowledge\tbool\tTrue\tAdd a tool that allows the Model to search the knowledge base (aka Agentic RAG)\nupdate_knowledge\tbool\tFalse\tAdd a tool that allows the Model to update the knowledge base.\nread_tool_call_history\tbool\tFalse\tAdd a tool that allows the Model to get the tool call history.\nadd_messages\tOptional[List[Union[Dict, Message]]]\tNone\tA list of extra messages added after the system message and before the user message.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt: provide the system prompt as a string\nsystem_prompt_template\tOptional[PromptTemplate]\tNone\tSystem prompt template: provide the system prompt as a PromptTemplate\nuse_default_system_message\tbool\tTrue\tIf True, build a default system message using agent settings and use that\nsystem_message_role\tstr\t\"system\"\tRole for the system message\ndescription\tOptional[str]\tNone\tA description of the Agent that is added to the start of the system message.\ntask\tOptional[str]\tNone\tThe task the agent should achieve.\ninstructions\tOptional[List[str]]\tNone\tList of instructions for the agent.\nguidelines\tOptional[List[str]]\tNone\tList of guidelines for the agent.\nexpected_output\tOptional[str]\tNone\tProvide the expected output from the Agent.\nadditional_context\tOptional[str]\tNone\tAdditional context added to the end of the system message.\nprevent_hallucinations\tbool\tFalse\tIf True, add instructions to return \"I dont know\" when the agent does not know the answer.\nprevent_prompt_leakage\tbool\tFalse\tIf True, add instructions to prevent prompt leakage\nlimit_tool_access\tbool\tFalse\tIf True, add instructions for limiting tool access to the default system prompt if tools are provided\nmarkdown\tbool\tFalse\tIf markdown=true, add instructions to format the output using markdown\nadd_name_to_instructions\tbool\tFalse\tIf True, add the agent name to the instructions\nadd_datetime_to_instructions\tbool\tFalse\tIf True, add the current datetime to the instructions to give the agent a sense of time\nuser_prompt\tOptional[Union[List, Dict, str]]\tNone\tUser prompt: provide the user prompt as a string\nuser_prompt_template\tOptional[PromptTemplate]\tNone\tUser prompt template: provide the user prompt as a PromptTemplate\nuse_default_user_message\tbool\tTrue\tIf True, build a default user prompt using references and chat history\nuser_message_role\tstr\t\"user\"\tRole for the user message\nresponse_model\tOptional[Type[BaseModel]]\tNone\tProvide a response model to get the response as a Pydantic model (alias: \"output_model\")\nparse_response\tbool\tTrue\tIf True, the response from the Model is converted into the response_model\nstructured_outputs\tbool\tFalse\tUse the structured_outputs from the Model if available\nsave_response_to_file\tOptional[str]\tNone\tSave the response to a file\nteam\tOptional[List[\"Agent\"]]\tNone\tAn Agent can have a team of agents that it can transfer tasks to.\nrole\tOptional[str]\tNone\tWhen the agent is part of a team, this is the role of the agent in the team\nadd_transfer_instructions\tbool\tTrue\tAdd instructions for transferring tasks to team members\ndebug_mode\tbool\tFalse\tdebug_mode=True enables debug logs\nmonitoring\tbool\tFalse\tmonitoring=True logs Agent information to phidata.app for monitoring\ntelemetry\tbool\tTrue\ttelemetry=True logs minimal telemetry for analytics\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent\nDuckDb\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nPythonAgent Params\nAgent Reference"
  },
  {
    "title": "Building an Agent API - Phidata",
    "url": "https://docs.phidata.com/templates/agent-api/run-local",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nRun locally\nRun on AWS\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nAgent API\nBuilding an Agent API\n\nThe Agent Api let’s us serve agents using a FastApi server and store memory and knowledge in a Postgres database. Run it locally using docker or deploy to production on AWS.\n\n​\nSetup\n1\n\nCreate a virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall phidata\n\nMac\nWindows\npip install -U \"phidata[aws]\"\n\n3\n\nInstall docker\n\nInstall docker desktop to run your app locally\n\n4\n\nExport your OpenAI key\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nCreate your codebase\n\nCreate your codebase using the agent-api template\n\nMac\nWindows\nphi ws create -t agent-api -n agent-api\n\n\nThis will create a folder agent-api with the following structure:\n\nagent-api                     # root directory\n├── agents                  # add your Agents here\n├── api                     # add fastApi routes here\n├── db                      # add database tables here\n├── Dockerfile              # Dockerfile for the application\n├── pyproject.toml          # python project definition\n├── requirements.txt        # python dependencies generated by pyproject.toml\n├── scripts                 # helper scripts\n├── utils                   # shared utilities\n└── workspace               # phidata workspace directory\n    ├── dev_resources.py    # dev resources running locally\n    ├── prd_resources.py    # production resources running on AWS\n    ├── secrets             # secrets\n    └── settings.py         # phidata workspace settings\n\n​\nServe your Agents using FastApi\n\nFastApi is an exceptional framework for building RestApis. Its fast, well-designed and loved by everyone using it. Most production applications are built using a front-end framework like next.js backed by a RestAPI, where FastApi shines.\n\nYour codebase comes pre-configured with FastApi and PostgreSQL, along with some sample routes. Start your workspace using:\n\nterminal\nshorthand\nphi ws up\n\n\nPress Enter to confirm and give a few minutes for the image to download (only the first time). Verify container status and view logs on the docker dashboard.\n\nOpen localhost:8000/docs to view the API Endpoints.\nTest the /v1/playground/agent/run endpoint with\n{\n  \"message\": \"howdy\",\n  \"agent_id\": \"example-agent\",\n  \"stream\": true\n}\n\n​\nBuilding your AI Product\n\nThe agent-app comes with common endpoints that you can use to build your AI product. This API is developed in close collaboration with real AI Apps and are a great starting point.\n\nThe general workflow is:\n\nYour front-end/product will call the /v1/playground/agent/run to run Agents.\nUsing the session_id returned, your product can continue and serve chats to its users.\n​\nDelete local resources\n\nPlay around and stop the workspace using:\n\nterminal\nfull options\nshorthand\nphi ws down\n\n​\nNext\n\nCongratulations on running your AI API locally. Next Steps:\n\nRun your Agent API on AWS\nRead how to update workspace settings\nRead how to create a git repository for your workspace\nRead how to manage the development application\nRead how to format and validate your code\nRead how to add python libraries\nChat with us on discord\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nRun on AWS\nRun on AWS\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nCreate your codebase\nServe your Agents using FastApi\nBuilding your AI Product\nDelete local resources\nNext"
  },
  {
    "title": "Building an Agent App - Phidata",
    "url": "https://docs.phidata.com/templates/agent-app/run-local",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nRun locally\nRun on AWS\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nAgent App\nBuilding an Agent App\n\nThe Agent App let’s us serve agents using a FastApi server, test them using a Streamlit UI and store memory and knowledge in a Postgres database. Run it locally using docker or deploy to production on AWS.\n\n​\nSetup\n1\n\nCreate a virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall phidata\n\nMac\nWindows\npip install -U \"phidata[aws]\"\n\n3\n\nInstall docker\n\nInstall docker desktop to run your app locally\n\n4\n\nExport your OpenAI key\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nCreate your codebase\n\nCreate your codebase using the agent-app template\n\nMac\nWindows\nphi ws create -t agent-app -n agent-app\n\n\nThis will create a folder agent-app with the following structure:\n\nagent-app                     # root directory\n├── agents                  # add your Agents here\n├── app                     # add streamlit apps here\n├── api                     # add fastApi routes here\n├── db                      # add database tables here\n├── Dockerfile              # Dockerfile for the application\n├── pyproject.toml          # python project definition\n├── requirements.txt        # python dependencies generated using pyproject.toml\n├── scripts                 # helper scripts\n├── utils                   # shared utilities\n└── workspace               # phidata workspace directory\n    ├── dev_resources.py    # dev resources running locally\n    ├── prd_resources.py    # production resources running on AWS\n    ├── secrets             # secrets\n    └── settings.py         # phidata workspace settings\n\n​\nTest your Agents using Streamlit\n\nStreamlit allows us to build micro front-ends for testing our Agents. Start the app using:\n\nterminal\nshorthand\nphi ws up --group app\n\n\nPress Enter to confirm and give a few minutes for the image to download (only the first time). Verify container status and view logs on the docker dashboard.\n\nOpen localhost:8501 to view your AI Agent.\nThe streamlit apps are defined in the app folder\nThe Agents are defined in the agents folder.\n​\nServe your Agents using FastApi\n\nStreamlit is great for building micro front-ends but any production application will be built using a front-end framework like next.js backed by a RestApi built using FastApi.\n\nYour Agent App comes ready-to-use with FastApi endpoints. Start the api using:\n\nterminal\nshorthand\nphi ws up --group api\n\nOpen localhost:8000/docs to view the API Endpoints.\nTest the /v1/playground/agent/run endpoint with\n{\n  \"message\": \"howdy\",\n  \"agent_id\": \"example-agent\",\n  \"stream\": true\n}\n\n​\nBuilding your AI Product\n\nThe agent-app comes with common endpoints that you can use to build your AI product. This API is developed in close collaboration with real AI Apps and are a great starting point.\n\nThe general workflow is:\n\nYour front-end/product will call the /v1/playground/agent/run to run Agents.\nUsing the session_id returned, your product can continue and serve chats to its users.\n​\nDelete local resources\n\nPlay around and stop the workspace using:\n\nterminal\nfull options\nshorthand\nphi ws down\n\n\nor stop individual Apps using:\n\napp\napi\ndatabase\nphi ws down --group app\n\n​\nNext\n\nCongratulations on running your AI App locally. Next Steps:\n\nRun your Agent App on AWS\nRead how to update workspace settings\nRead how to create a git repository for your workspace\nRead how to manage the development application\nRead how to format and validate your code\nRead how to add python libraries\nChat with us on discord\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nRun on AWS\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nSetup\nCreate your codebase\nTest your Agents using Streamlit\nServe your Agents using FastApi\nBuilding your AI Product\nDelete local resources\nNext"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/templates/resources/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nResources\nIntroduction\n\nResources are the infrastructure components for your application. Similar to Apps, we define them as python classes and create using phi start or phi ws up.\n\n​\nExamples\nLocal Resources: Docker containers and images\nCloud Resources: RDS database, S3 bucket, ECS services, task definitions, security groups\nKubernetes Resources: Services, deployments\nDocker Container\nDocker Image\nS3 Bucket\nSecret\nRDS Database\nfrom phi.docker.resource.container import DockerContainer\n\nwhoami = DockerContainer(\n    name='whoami',\n    image='traefik/whoami',\n    ports={'80': 8080},\n)\n\n\n\n\nEach Resource is a pydantic object providing input and type validation.\n\n​\nMotivation\n\nResources provide the “Infrastructure Layer” for our AI products. The software we write needs to be served by an Application, which in turn needs to run on an Infrastructure Resoure.\n\nDefining Applications as Code and Infrastructure as Code allows us completely write our application as python code - providing numerous benefits like re-usability, version control, unit testing, formatting.\n\nPhidata currently provides:\n\nDocker Resources\nAWS Resources\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFeatures\nDocker\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExamples\nMotivation"
  },
  {
    "title": "Examples - Phidata",
    "url": "https://docs.phidata.com/templates/apps/examples",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nApps\nExamples\n​\nRun PgVector on Docker\n\nCreate a file resources.py with the following contents:\n\nresources.py\nfrom phi.docker.app.postgres import PgVectorDb\nfrom phi.docker.resources import DockerResources\n\n# -*- PgVector running on port 5432:5432\nvector_db = PgVectorDb(\n    pg_user=\"ai\",\n    pg_password=\"ai\",\n    pg_database=\"ai\",\n    debug_mode=True,\n)\n\n# -*- DockerResources\ndev_docker_resources = DockerResources(apps=[vector_db])\n\n\nStart resources using:\n\nMac\nWindows\nphi start resources.py\n\n\nPress Enter to confirm and verify container status on the docker dashboard.\n\n​\nRun Jupyter on Docker\n\nA jupyter notebook is a must have for AI development. Update the resources.py file to:\n\nresources.py\nfrom os import getenv\n\nfrom phi.docker.app.jupyter import Jupyter\nfrom phi.docker.app.postgres import PgVectorDb\nfrom phi.docker.resources import DockerResources\n\n# -*- PgVector running on port 5432:5432\nvector_db = PgVectorDb(\n    pg_user=\"ai\",\n    pg_password=\"ai\",\n    pg_database=\"ai\",\n    debug_mode=True,\n)\n\n# -*- Jupyter running on port 8888:8888\njupyter = Jupyter(\n    mount_workspace=True,\n    env_vars={\"OPENAI_API_KEY\": getenv(\"OPENAI_API_KEY\")},\n)\n\n# -*- DockerResources\ndev_docker_resources = DockerResources(\n    apps=[vector_db, jupyter],\n)\n\n\nStart resources using:\n\nMac\nWindows\nphi start resources.py\n\n​\nView Jupyterlab UI\nOpen localhost:8888 to view the Jupyterlab UI. Password: admin\nThe directory is automatically mounted in the notebook.\n​\nStop resources\nMac\nWindows\nphi stop resources.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nFeatures\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nRun PgVector on Docker\nRun Jupyter on Docker\nView Jupyterlab UI\nStop resources"
  },
  {
    "title": "Features - Phidata",
    "url": "https://docs.phidata.com/templates/apps/features",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nApps\nFeatures\n​\nInstall requirements on startup\n\nApps can install requirements on container startup. Update the Jupyter app to:\n\nresources.py\n...\n# -*- Jupyter running on port 8888:8888\njupyter = Jupyter(\n    mount_workspace=True,\n    install_requirements=True,\n    requirements_file=\"requirements.txt\",\n    env_vars={\"OPENAI_API_KEY\": getenv(\"OPENAI_API_KEY\")},\n)\n...\n\n\nCreate a requirements.txt file in the same directory\n\nrequirements.txt\nopenai\n\n​\nPatch resources\nterminal\nfull options\nphi patch resources.py -y\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nExamples\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nInstall requirements on startup\nPatch resources"
  },
  {
    "title": "Workflows - Phidata",
    "url": "https://docs.phidata.com/workflows",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nWorkflows\n\nWorkflows are deterministic, stateful, multi-agent pipelines that power many of our production use cases. They are incredibly powerful and offer the following benefits:\n\nControl and Flexibility: You have full control over the multi-agent process, how the input is processed, which agents are used and in what order.\nBuilt-in Memory: You can store state and cache results in a database at any time, meaning your agents can re-use results from previous steps.\nDefined as a python class: You do not need to learn a new framework, its just python.\n\nHow to build a workflow:\n\nDefine your workflow as a class by inheriting from the Workflow class\nAdd one or more agents to the workflow\nImplement your logic in the run() method\nCache results in the session_state as needed\nRun the workflow using the .run() method\n​\nExample: Blog Post Generator\n\nLet’s create a blog post generator that can search the web, read the top links and write a blog post for us. We’ll cache intermediate results in the database to improve performance.\n\n​\nCreate the Workflow\n\nCreate a file blog_post_generator.py\n\nblog_post_generator.py\nimport json\nfrom typing import Optional, Iterator\n\nfrom pydantic import BaseModel, Field\n\nfrom phi.agent import Agent\nfrom phi.workflow import Workflow, RunResponse, RunEvent\nfrom phi.storage.workflow.sqlite import SqlWorkflowStorage\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.utils.pprint import pprint_run_response\nfrom phi.utils.log import logger\n\n\nclass NewsArticle(BaseModel):\n    title: str = Field(..., description=\"Title of the article.\")\n    url: str = Field(..., description=\"Link to the article.\")\n    summary: Optional[str] = Field(..., description=\"Summary of the article if available.\")\n\n\nclass SearchResults(BaseModel):\n    articles: list[NewsArticle]\n\n\nclass BlogPostGenerator(Workflow):\n    searcher: Agent = Agent(\n        tools=[DuckDuckGo()],\n        instructions=[\"Given a topic, search for 20 articles and return the 5 most relevant articles.\"],\n        response_model=SearchResults,\n    )\n\n    writer: Agent = Agent(\n        instructions=[\n            \"You will be provided with a topic and a list of top articles on that topic.\",\n            \"Carefully read each article and generate a New York Times worthy blog post on that topic.\",\n            \"Break the blog post into sections and provide key takeaways at the end.\",\n            \"Make sure the title is catchy and engaging.\",\n            \"Always provide sources, do not make up information or sources.\",\n        ],\n    )\n\n    def run(self, topic: str, use_cache: bool = True) -> Iterator[RunResponse]:\n        logger.info(f\"Generating a blog post on: {topic}\")\n\n        # Use the cached blog post if use_cache is True\n        if use_cache and \"blog_posts\" in self.session_state:\n            logger.info(\"Checking if cached blog post exists\")\n            for cached_blog_post in self.session_state[\"blog_posts\"]:\n                if cached_blog_post[\"topic\"] == topic:\n                    logger.info(\"Found cached blog post\")\n                    yield RunResponse(\n                        run_id=self.run_id,\n                        event=RunEvent.workflow_completed,\n                        content=cached_blog_post[\"blog_post\"],\n                    )\n                    return\n\n        # Step 1: Search the web for articles on the topic\n        num_tries = 0\n        search_results: Optional[SearchResults] = None\n        # Run until we get a valid search results\n        while search_results is None and num_tries < 3:\n            try:\n                num_tries += 1\n                searcher_response: RunResponse = self.searcher.run(topic)\n                if (\n                    searcher_response\n                    and searcher_response.content\n                    and isinstance(searcher_response.content, SearchResults)\n                ):\n                    logger.info(f\"Searcher found {len(searcher_response.content.articles)} articles.\")\n                    search_results = searcher_response.content\n                else:\n                    logger.warning(\"Searcher response invalid, trying again...\")\n            except Exception as e:\n                logger.warning(f\"Error running searcher: {e}\")\n\n        # If no search_results are found for the topic, end the workflow\n        if search_results is None or len(search_results.articles) == 0:\n            yield RunResponse(\n                run_id=self.run_id,\n                event=RunEvent.workflow_completed,\n                content=f\"Sorry, could not find any articles on the topic: {topic}\",\n            )\n            return\n\n        # Step 2: Write a blog post\n        logger.info(\"Writing blog post\")\n        # Prepare the input for the writer\n        writer_input = {\n            \"topic\": topic,\n            \"articles\": [v.model_dump() for v in search_results.articles],\n        }\n        # Run the writer and yield the response\n        yield from self.writer.run(json.dumps(writer_input, indent=4), stream=True)\n\n        # Save the blog post in the session state for future runs\n        if \"blog_posts\" not in self.session_state:\n            self.session_state[\"blog_posts\"] = []\n        self.session_state[\"blog_posts\"].append({\"topic\": topic, \"blog_post\": self.writer.run_response.content})\n\n\n# The topic to generate a blog post on\ntopic = \"US Elections 2024\"\n\n# Create the workflow\ngenerate_blog_post = BlogPostGenerator(\n    session_id=f\"generate-blog-post-on-{topic}\",\n    storage=SqlWorkflowStorage(\n        table_name=\"generate_blog_post_workflows\",\n        db_file=\"tmp/workflows.db\",\n    ),\n)\n\n# Run workflow\nblog_post: Iterator[RunResponse] = generate_blog_post.run(topic=topic, use_cache=True)\n\n# Print the response\npprint_run_response(blog_post, markdown=True)\n\n​\nRun the workflow\n\nInstall libraries\n\npip install phidata openai duckduckgo-search sqlalchemy phidata\n\n\nRun the workflow\n\npython blog_post_generator.py\n\n\nNow the results are cached in the database and can be re-used for future runs. Run the workflow again to view the cached results.\n\npython blog_post_generator.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nMonitoring\nTemplates\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample: Blog Post Generator\nCreate the Workflow\nRun the workflow"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/templates/apps/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nApps\nIntroduction\n\nApps are tools like FastApi, PgVector, Streamlit, Jupyter, Django that we define as python classes and run using phi start or phi ws up.\n\nWhen running Apps using phidata, think of them as infrastructure as code but at a higher level of abstraction. Instead of defining containers, volumes etc. we define the application we want to run. We run Applications as Code instead of Infrastructure as Code.\n\nThe same App can run on docker, AWS (ECS) or Kubernetes (EKS). The App creates the underlying resources like LoadBalancers, Services, Deployments. As the underlying resources become more complex, the concept of Apps become more appealing.\n\n​\nExample\n\nLets run a Jupyter notebook and PgVector on docker.\n\nCopy the following contents to a file resources.py and run phi start resources.py\n\nresources.py\nfrom phi.docker.app.jupyter import Jupyter\nfrom phi.docker.app.postgres import PgVectorDb\nfrom phi.docker.resources import DockerResources\n\n# -*- PgVector running on port 5432:5432\nvector_db = PgVectorDb(pg_user=\"ai\", pg_password=\"ai\", pg_database=\"ai\")\n\n# -*- Jupyter running on port 8888:8888\njupyter = Jupyter(mount_workspace=True)\n\n# -*- DockerResources\ndev_docker_resources = DockerResources(apps=[vector_db, jupyter])\n\nEach App is a pydantic object providing input and type validation.\nNote how the mount_workspace automatically mounts the directory\nNote how PgVectorDb sets the required settings and creates the volume.\n\nWhile this is a simple example, these concepts become very powerful for complex applications.\n\n​\nMotivation\n\nApps provide the “Application Layer” for our AI products.\n\nThe software we write needs to be served by an Application, and this Application needs to run the same locally for development and in the cloud for production. By defining Applications as Code, we bring the benefits of Infrastructure as Code to the software layer.\n\nDefining Applications as Code also allows us to package “software systems” into templates. Meaning every phidata template can run locally using docker or on AWS with 1 command.\n\nFinally, defining Applications as python objects means we can import them in our code like regular objects making the following code possible:\n\nfrom resources import vector_db\n\ndb_url=vector_db.get_db_connection_local()\n\n\nCheckout some example apps you can run on docker:\n\nPgVector\nJupyter\n\nDefining Applications as Code offers many benefits, such as:\n\nInstall requirements on startup\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nResources\nExamples\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nMotivation"
  },
  {
    "title": "Workspace Resources - Phidata",
    "url": "https://docs.phidata.com/templates/workspace/resources",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nWorkspace\nWorkspace Resources\n\nThe workspace directory in a codebase contains the resources that are created/deleted using phi ws up/phi ws down.\n\nAny .py file in the workspace containing a DockerResources, AwsResources or K8sResources object can be used to define the workspace resources.\n\nTo add your own resources, just create a python file, define resources and add them to a DockerResources, AwsResources or K8sResources object.\n\n​\nExample\n​\nDockerResources\nworkspace/dev_resources.py\nfrom phi.docker.app.fastapi import FastApi\nfrom phi.docker.app.postgres import PgVectorDb\nfrom phi.docker.app.streamlit import Streamlit\nfrom phi.docker.resources import DockerResources\n\n#\n# -*- Resources for the Development Environment\n#\n\n# -*- Dev image\ndev_image = DockerImage(\n    ...\n)\n\n# -*- Dev database running on port 5432:5432\ndev_db = PgVectorDb(\n    ...\n)\n\n# -*- Streamlit running on port 8501:8501\ndev_streamlit = Streamlit(\n    ...\n)\n\n# -*- FastApi running on port 8000:8000\ndev_fastapi = FastApi(\n    ...\n)\n\n# -*- Dev DockerResources\ndev_docker_resources = DockerResources(\n    env=ws_settings.dev_env,\n    network=ws_settings.ws_name,\n    apps=[dev_db, dev_streamlit, dev_fastapi, dev_jupyter_app],\n)\n\n​\nAwsResources\nworkspace/prd_resources.py\nfrom phi.aws.app.fastapi import FastApi\nfrom phi.aws.app.streamlit import Streamlit\nfrom phi.aws.resources import AwsResources\nfrom phi.aws.resource.ecs import EcsCluster\nfrom phi.aws.resource.ec2 import SecurityGroup, InboundRule\nfrom phi.aws.resource.rds import DbInstance, DbSubnetGroup\nfrom phi.aws.resource.reference import AwsReference\nfrom phi.aws.resource.s3 import S3Bucket\nfrom phi.aws.resource.secret import SecretsManager\nfrom phi.docker.resources import DockerResources\nfrom phi.docker.resource.image import DockerImage\n\n#\n# -*- Resources for the Production Environment\n#\n\n# -*- Production image\nprd_image = DockerImage(\n    ...\n)\n\n# -*- S3 bucket for production data\nprd_bucket = S3Bucket(\n    ...\n)\n\n# -*- Secrets for production application\nprd_secret = SecretsManager(\n    ...\n)\n# -*- Secrets for production database\nprd_db_secret = SecretsManager(\n    ...\n)\n\n# -*- Security Group for the load balancer\nprd_lb_sg = SecurityGroup(\n    ...\n)\n# -*- Security Group for the application\nprd_sg = SecurityGroup(\n    ...\n)\n# -*- Security Group for the database\nprd_db_port = 5432\nprd_db_sg = SecurityGroup(\n    ...\n)\n\n# -*- RDS Database Subnet Group\nprd_db_subnet_group = DbSubnetGroup(\n    ...\n)\n\n# -*- RDS Database Instance\nprd_db = DbInstance(\n    ...\n)\n\n# -*- Streamlit running on ECS\nprd_streamlit = Streamlit(\n    ...\n)\n\n# -*- FastApi running on ECS\nprd_fastapi = FastApi(\n    ...\n)\n\n# -*- Production DockerResources\nprd_docker_resources = DockerResources(\n    env=ws_settings.prd_env,\n    network=ws_settings.ws_name,\n    resources=[prd_image],\n)\n\n# -*- Production AwsResources\nprd_aws_resources = AwsResources(\n    env=ws_settings.prd_env,\n    apps=[prd_streamlit, prd_fastapi],\n    resources=[prd_lb_sg, prd_sg, prd_db_sg, prd_secret, prd_db_secret, prd_db_subnet_group, prd_db, prd_bucket],\n)\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nSettings\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nDockerResources\nAwsResources"
  },
  {
    "title": "Workspace Settings - Phidata",
    "url": "https://docs.phidata.com/templates/workspace/settings",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nWorkspace\nWorkspace Settings\n\nThe WorkspaceSettings object, usually defined in the workspace/settings.py file is used to defines common settings used by your workspace apps and resources.\n\nIts not mandatory and doesn’t serve any other purpose except to hold configuration used by workspace apps and resources. The values in the WorkspaceSettings object can also be set using Environment variables or a .env file.\n\n​\nExample\n\nAn example WorkspaceSettings used by the llm-app template. View this file on github\n\nworkspace/settings.py\nfrom pathlib import Path\n\nfrom phi.workspace.settings import WorkspaceSettings\n\n#\n# -*- Define workspace settings using a WorkspaceSettings object\n# these values can also be set using environment variables or a .env file\n#\nws_settings = WorkspaceSettings(\n    # Workspace name: used for naming resources\n    ws_name=\"ai\",\n    # Path to the workspace root\n    ws_root=Path(__file__).parent.parent.resolve(),\n    # -*- Dev settings\n    dev_env=\"dev\",\n    # -*- Dev Apps\n    dev_app_enabled=True,\n    dev_api_enabled=True,\n    dev_db_enabled=True,\n    # dev_jupyter_enabled=True,\n    # -*- Production settings\n    prd_env=\"prd\",\n    # -*- Production Apps\n    prd_app_enabled=True,\n    prd_api_enabled=True,\n    prd_db_enabled=True,\n    # -*- AWS settings\n    # Region for AWS resources\n    aws_region=\"us-east-1\",\n    # Availability Zones for AWS resources\n    aws_az1=\"us-east-1a\",\n    aws_az2=\"us-east-1b\",\n    # Subnet IDs in the aws_region\n    # subnet_ids=[\"subnet-xyz\", \"subnet-xyz\"],\n    #\n    # -*- Image Settings\n    #\n    # Default repository for images\n    image_repo=\"phidata\"\n    # Build images locally\n    build_images=False\n    # Push images after building\n    push_images=False\n    # Skip cache when building images\n    skip_image_cache=False\n    # Force pull images in FROM\n    force_pull_images=False\n)\n\n​\nUsage\n\nUse the workspace settings to\n\nName resources\nGet the workspace root path using ws_settings.ws_root\ndev_resources.py\n...\n# -*- Streamlit running on port 8501:8501\ndev_streamlit = Streamlit(\n    name=f\"{ws_settings.dev_key}-app\",\n    enabled=ws_settings.dev_app_enabled,\n    ...\n    # Read secrets from secrets/dev_app_secrets.yml\n    secrets_file=ws_settings.ws_root.joinpath(\"workspace/secrets/dev_app_secrets.yml\")\n)\n\nHold AWS constants like availability zone and subnets\nprd_resources.py\n# -*- FastApi running on ECS\nprd_fastapi = FastApi(\n    name=f\"{ws_settings.prd_key}-api\",\n    enabled=ws_settings.prd_api_enabled,\n    ...\n    subnets=ws_settings.subnet_ids,\n    ...\n)\n\n# -*- RDS Database Instance\nprd_db = DbInstance(\n    name=f\"{ws_settings.prd_key}-db\",\n    enabled=ws_settings.prd_db_enabled,\n    ...\n    availability_zone=ws_settings.aws_az1,\n    ...\n)\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nResources\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nUsage"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/templates/workspace/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nWorkspace\nIntroduction\n\nA phidata template creates a Workspace, which is just an umbrella term for your codebase.\n\n​\nCreate new workspace\n\nRun phi ws create to create a new workspace using a phidata template\n\nCreate Workspace\nCreate AI App\nCreate AI Api\nCreate Django App\nphi ws create\n\n\n\n\nphi will ask for a workspace template and name if not provided.\n\n​\nSetup existing workspace\n\nRun phi ws setup to setup an existing directory as a phidata workspace\n\nterminal\nwith debug logs\nphi ws setup\n\n​\nStart workspace\n\nRun phi ws up to create workspace resources\n\nterminal\nshorthand\nfull options\nshort options\nphi ws up\n\n​\nStop workspace\n\nRun phi ws down to delete workspace resources\n\nterminal\nshorthand\nfull options\nshort options\nphi ws down\n\n​\nPatch workspace\n\nRun phi ws patch to update workspace resources\n\nterminal\nshorthand\nfull options\nshort options\nphi ws patch\n\n\n\n\nThe patch command in under development for some resources. Use restart if needed\n\n​\nRestart workspace\n\nRun phi ws restart to stop resources and start them again\n\nterminal\nshorthand\nfull options\nshort options\nphi ws restart\n\n​\nCommand Options\nRun phi ws up --help to view all options\n​\nEnvironment (--env)\n\nUse the --env or -e flag to filter the environment (dev/prd)\n\nflag\nshorthand\nshort options\nphi ws up --env dev\n\n​\nInfra (--infra)\n\nUse the --infra or -i flag to filter the infra (docker/aws/k8s)\n\nflag\nshorthand\nshort options\nphi ws up --infra docker\n\n​\nGroup (--group)\n\nUse the --group or -g flag to filter by resource group.\n\nflag\nfull options\nshorthand\nshort options\nphi ws up --group app\n\n​\nName (--name)\n\nUse the --name or -n flag to filter by resource name\n\nflag\nfull options\nshorthand\nshort options\nphi ws up --name app\n\n​\nType (--type)\n\nUse the --type or -t flag to filter by resource type.\n\nflag\nfull options\nshorthand\nshort options\nphi ws up --type container\n\n​\nDry Run (--dry-run)\n\nThe --dry-run or -dr flag can be used to dry-run the command. phi ws up -dr will only print resources, not create them.\n\nflag\nfull options\nshorthand\nshort options\nphi ws up --dry-run\n\n​\nShow Debug logs (--debug)\n\nUse the --debug or -d flag to show debug logs.\n\nflag\nfull options\nshorthand\nshort options\nphi ws up -d\n\n​\nForce recreate images & containers (-f)\n\nUse the --force or -f flag to force recreate images & containers\n\nflag\nfull options\nshorthand\nshort options\nphi ws up -f\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFormat & Validate\nSettings\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nCreate new workspace\nSetup existing workspace\nStart workspace\nStop workspace\nPatch workspace\nRestart workspace\nCommand Options\nEnvironment (--env)\nInfra (--infra)\nGroup (--group)\nName (--name)\nType (--type)\nDry Run (--dry-run)\nShow Debug logs (--debug)\nForce recreate images & containers (-f)"
  },
  {
    "title": "Vision Agent - Phidata",
    "url": "https://docs.phidata.com/examples/agents/vision-agent",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nVision Agent\n\nCreate a file vision_agent.py with the following code:\n\nvision_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    markdown=True,\n)\n\nagent.print_response(\n    \"What are in these images? Is there any difference between them?\",\n    images=[\n        \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n        \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n    ],\n)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai phidata\n\n3\n\nRun the agent\n\npython vision_agent.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPython Function Agent\nOpenAI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  },
  {
    "title": "Structured Output - Phidata",
    "url": "https://docs.phidata.com/examples/agents/structured-output",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nStructured Output\n\nCreate a file structured_output.py with the following code:\n\nstructured_output.py\nfrom typing import List\nfrom rich.pretty import pprint  # noqa\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent, RunResponse  # noqa\nfrom phi.model.openai import OpenAIChat\n\n\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(\n        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n    )\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\n\n# Get the response in a variable\n# json_mode_response: RunResponse = json_mode_agent.run(\"New York\")\n# pprint(json_mode_response.content)\n# structured_output_response: RunResponse = structured_output_agent.run(\"New York\")\n# pprint(structured_output_response.content)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai phidata\n\n3\n\nRun the agent\n\npython structured_output.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nData Analyst\nPython Function Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Data Analyst - Phidata",
    "url": "https://docs.phidata.com/examples/agents/data-analyst",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nData Analyst\n\nCreate a file data_analyst.py with the following code:\n\ndata_analyst.py\nimport json\nfrom phi.model.openai import OpenAIChat\nfrom phi.agent.duckdb import DuckDbAgent\n\ndata_analyst = DuckDbAgent(\n    model=OpenAIChat(model=\"gpt-4o\"),\n    semantic_model=json.dumps(\n        {\n            \"tables\": [\n                {\n                    \"name\": \"movies\",\n                    \"description\": \"Contains information about movies from IMDB.\",\n                    \"path\": \"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n                }\n            ]\n        }\n    ),\n    markdown=True,\n)\ndata_analyst.print_response(\n    \"Show me a histogram of ratings. \"\n    \"Choose an appropriate bucket size but share how you chose it. \"\n    \"Show me the result as a pretty ascii diagram\",\n    stream=True,\n)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai duckdb phidata\n\n3\n\nRun the agent\n\npython data_analyst.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPython Agent\nStructured Output\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Python Agent - Phidata",
    "url": "https://docs.phidata.com/examples/agents/python-agent",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nPython Agent\n\nCreate a file python_agent.py with the following code:\n\npython_agent.py\nfrom pathlib import Path\n\nfrom phi.agent.python import PythonAgent\nfrom phi.model.openai import OpenAIChat\nfrom phi.file.local.csv import CsvFile\n\ncwd = Path(__file__).parent.resolve()\ntmp = cwd.joinpath(\"tmp\")\nif not tmp.exists():\n    tmp.mkdir(exist_ok=True, parents=True)\n\npython_agent = PythonAgent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    base_dir=tmp,\n    files=[\n        CsvFile(\n            path=\"https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv\",\n            description=\"Contains information about movies from IMDB.\",\n        )\n    ],\n    markdown=True,\n    pip_install=True,\n    show_tool_calls=True,\n)\npython_agent.print_response(\"What is the average rating of movies?\")\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai phidata\n\n3\n\nRun the agent\n\npython python_agent.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nReasoning Agent\nData Analyst\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Reasoning Agent - Phidata",
    "url": "https://docs.phidata.com/examples/agents/reasoning-agent",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nReasoning Agent\n\nCreate a file reasoning_agent.py with the following code:\n\nreasoning_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\ntask = (\n    \"Three missionaries and three cannibals need to cross a river. \"\n    \"They have a boat that can carry up to two people at a time. \"\n    \"If, at any time, the cannibals outnumber the missionaries on either side of the river, the cannibals will eat the missionaries. \"\n    \"How can all six people get across the river safely? Provide a step-by-step solution and show the solutions as an ascii diagram\"\n)\n\nreasoning_agent = Agent(model=OpenAIChat(id=\"gpt-4o\"), reasoning=True, markdown=True, structured_outputs=True)\nreasoning_agent.print_response(task, stream=True, show_full_reasoning=True)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai phidata\n\n3\n\nRun the agent\n\npython reasoning_agent.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent Team\nPython Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Agent Team - Phidata",
    "url": "https://docs.phidata.com/examples/agents/agent-team",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nAgent Team\n\nCreate a file agent_team.py with the following code:\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai yfinance duckduckgo-search phidata\n\n3\n\nRun the agent\n\npython agent_team.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nFinance Agent\nReasoning Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Finance Agent - Phidata",
    "url": "https://docs.phidata.com/examples/agents/finance-agent",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nFinance Agent\n\nCreate a file finance_agent.py with the following code:\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai yfinance phidata\n\n3\n\nRun the agent\n\npython finance_agent.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWeb Search Agent\nAgent Team\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Web Search Agent - Phidata",
    "url": "https://docs.phidata.com/examples/agents/web-search",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nWeb Search Agent\nFinance Agent\nAgent Team\nReasoning Agent\nPython Agent\nData Analyst\nStructured Output\nPython Function Agent\nVision Agent\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nAgents\nWeb Search Agent\n\nCreate a file web_search.py with the following code:\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n​\nUsage\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\npip install openai duckduckgo-search phidata\n\n3\n\nRun the agent\n\npython web_search.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nIntroduction\nFinance Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nUsage"
  },
  {
    "title": "Clone Cookbook - Phidata",
    "url": "https://docs.phidata.com/examples/how-to/use-cookbook",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nHow To\nClone Cookbook\n\nThe phidata cookbook contains in-depth examples and code. From basic agents, function calling, structured output to advanced fine-tuning and evaluations.\n\n​\nClone the cookbook\n1\n\nFork & clone the phidata repo\n\nWe recommend forking the phidata repo first so you can customize the cookbooks, and contribute your own recipes back to the repo.\n\nFork & clone the phidata repo\n\ngit clone https://github.com/phidatahq/phidata\n\n\ncd into the phidata directory\n\ncd phidata\n\n2\n\nCreate a virtual environment\n\nCreate a virtual environment with the required libraries and install the project in editable mode. You can use a helper script or run these steps manually.\n\nMac\nManual (Mac)\nWindows\n./scripts/create_venv.sh\nsource phienv/bin/activate\n\n3\n\nRun any recipe\n\nSet your OPENAI_API_KEY\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nInstall openai and duckduckgo-search\n\npip install openai duckduckgo-search\n\n\nRun the agents/web_search.py recipe\n\npython cookbook/agents/01_web_search.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nArXiv Research Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nClone the cookbook"
  },
  {
    "title": "Upgrade to v2.5.0 - Phidata",
    "url": "https://docs.phidata.com/migration/2-5-0",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nHow To\nUpgrade to v2.5.0\n\nThis guide will help you migrate your code to v2.5.0\n\n​\nKey Changes\nConstructor: Assistant() -> Agent()\nLLM/Model: llm -> model\nKnowledge Base: knowledge_base -> knowledge\nRunResponse: Pydantic model for string response\nStructured Output: Changes in how structured output is handled\n​\nDetailed Migration Steps\n​\n1. Update Import Statements\n# Version < 2.5.0\nfrom phi.assistant import Assistant\nfrom phi.llm.openai import OpenAIChat\nfrom phi.storage.assistant.postgres import PgAssistantStorage\n\n# Version >= 2.5.0\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.storage.agent.postgres import PgAgentStorage\n\n​\n2. Update Arguments\n\nReplace llm with model and model with id.\n\n# Version < 2.5.0\nfrom phi.assistant import Assistant\nfrom phi.llm.openai import OpenAIChat\n\nassistant = Assistant(\n    llm=OpenAIChat(model=\"gpt-4o\"),\n)\n\n# Version >= 2.5.0\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\nagent = Agent(\n    # Note: 'llm' is now 'model' and 'model' is now 'id'\n    model=OpenAIChat(id=\"gpt-4o\"),\n)\n\n​\n3. Update Knowledge Base\n\nReplace knowledge_base with knowledge.\n\n# Version < 2.5.0\nfrom phi.assistant import Assistant\nfrom phi.storage.assistant.postgres import PgAssistantStorage\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector2\nfrom phi.llm.openai import OpenAIChat\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=PgVector2(collection=\"recipes\", db_url=db_url),\n)\n\n# Comment out after first run\nknowledge_base.load()\n\nstorage = PgAssistantStorage(table_name=\"pdf_assistant\", db_url=db_url)\n\nassistant = Assistant(\n    llm=OpenAIChat(model=\"gpt-4o\"),\n    knowledge_base=knowledge_base,\n    search_knowledge=True, # enables agent to search knowledge base\n    storage=storage,\n)\n\nres = assistant.run(\"What is the recipe for chicken curry?\")\n\n\n# Version >= 2.5.0\nfrom phi.agent import Agent, RunResponse\nfrom phi.storage.agent.postgres import PgAgentStorage\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.pgvector import PgVector, SearchType\nfrom phi.model.openai import OpenAIChat\n\ndb_url = \"postgresql+psycopg://ai:ai@localhost:5532/ai\"\n\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    vector_db=PgVector(table_name=\"recipes\", db_url=db_url, search_type=SearchType.hybrid),\n)\n\n# Comment out after first run\nknowledge_base.load()\n\nstorage = PgAgentStorage(table_name=\"pdf_agent\", db_url=db_url)\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    knowledge=knowledge_base,\n    storage=storage,\n)\n\nresponse: RunResponse = agent.run(\"What is the recipe for chicken curry?\")\nres = response.content\n\n​\n4. Output model response as a string\n# Version < 2.5.0\nfrom phi.assistant import Assistant\nfrom phi.llm.openai import OpenAIChat\n\nassistant = Assistant(\n    llm=OpenAIChat(model=\"gpt-4o\"),\n)\n\nres = assistant.run(\"What is the recipe for chicken curry?\")\n\n# Version >= 2.5.0\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openai import OpenAIChat\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n)\n\nresponse: RunResponse = agent.run(\"What is the recipe for chicken curry?\")\nres = response.content\n\n​\n5. Handle structured outputs\n\nReplace output_model with response_model.\n\nIf you are using OpenAI models, you can set structured_outputs=True to get a structured output.\n\n# Version < 2.5.0\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom rich.pretty import pprint\nfrom phi.assistant import Assistant\nfrom phi.llm.openai import OpenAIChat\n\n\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(\n        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n    )\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n\nmovie_assistant = Assistant(\n    llm=OpenAIChat(model=\"gpt-4-turbo-preview\"),\n    description=\"You help people write movie ideas.\",\n    output_model=MovieScript,\n)\n\npprint(movie_assistant.run(\"New York\"))\n\n# Version >= 2.5.0\nfrom typing import List\nfrom rich.pretty import pprint\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent, RunResponse\nfrom phi.model.openai import OpenAIChat\n\n\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(\n        ..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\"\n    )\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n\n# Print the response\njson_mode_agent.print_response(\"New York\")\n\n# Get the response in a variable\njson_mode_response: RunResponse = json_mode_agent.run(\"New York\")\npprint(json_mode_response.content)\n\n\n# Agent that uses structured outputs\n# Note: `structured_output` only works with OpenAI models\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\n# Print the response\nstructured_output_agent.print_response(\"New York\")\n\n# Get the response in a variable\nstructured_output_response: RunResponse = structured_output_agent.run(\"New York\")\npprint(structured_output_response.content)\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nInstall & Upgrade\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nKey Changes\nDetailed Migration Steps\n1. Update Import Statements\n2. Update Arguments\n3. Update Knowledge Base\n4. Output model response as a string\n5. Handle structured outputs"
  },
  {
    "title": "Install & Upgrade - Phidata",
    "url": "https://docs.phidata.com/how-to/install",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nHow To\nInstall & Upgrade\n​\nInstall phidata\n\nWe recommend installing phidata using pip in a python virtual environment\n\n1\n\nCreate a virtual environment\n\nOpen the Terminal and create a python virtual environment.\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall phidata\n\nInstall the latest version of phidata\n\nMac\nWindows\npip install -U phidata\n\n\nIf you encounter errors, try updating pip using python -m pip install --upgrade pip\n\n​\nUpgrade phidata\n\nTo upgrade phidata, run this inside your virtual environment\n\npip install -U phidata --no-cache-dir\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAdvanced Example - News Report Generator\nUpgrade to v2.5.0\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nInstall phidata\nUpgrade phidata"
  },
  {
    "title": "Getting Help - Phidata",
    "url": "https://docs.phidata.com/getting-help",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nGetting Help\n\nThank you for building with phidata. If you need help, please come chat with us on discord or post your questions on the community forum.\n\n​\nLooking for dedicated support?\n\nWe’ve helped many companies build AI products, the general workflow is:\n\nBuild agents to perform tasks specific to your product.\nServe your agents via an API and connect them to your product.\nMonitor, evaluate and improve your AI product.\n\nWe provide dedicated support and development, book a call to get started. Our prices start at $20k/month and we specialize in taking companies from idea to production within 3 months.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nVideos\nIntroduction\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nLooking for dedicated support?"
  },
  {
    "title": "Videos - Phidata",
    "url": "https://docs.phidata.com/videos",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nVideos\n\nWe regularly post videos on our YouTube channel. From tutorials to explainer videos, our goal is to de-mystify Agent development and make it accessible to everyone.\n\n​\nAgents 101\nIntroduction and Setup\nAgent UI Overview\nFully local Agents with Ollama\nLocal Agents with Llama3.1:8b\nAgent Memory\nReasoning Agents\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nTemplates\nGetting Help\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAgents 101"
  },
  {
    "title": "Templates - Phidata",
    "url": "https://docs.phidata.com/templates",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nTemplates\n\nRunning Agents in production is hard, we need to:\n\nServe them using an application like FastApi, Django or Streamlit.\nManage their sessions, memory and knowlege in a database.\nMonitor, evaluate and improve their performance.\n\nPhidata not only makes building Agents easy but also provides pre-built templates for agentic systems that you can deploy to your own AWS account. Here’s how they work:\n\nCreate your codebase using a template: phi ws create\nRun your application locally: phi ws up\nRun your application on AWS: phi ws up prd:aws\n\nWe strongly believe that the data used by Agents should be stored securely inside your VPC.\n\nWe fully support BYOC (Bring Your Own Cloud) and encourage you to use your own AWS account.\n\n​\nAgent App\n\nLet’s build an agent-app which includes a Streamlit UI, FastApi server and Postgres database for memory and knowledge. Run it locally using docker or deploy to production on AWS.\n\n​\nSetup\n1\n\nCreate a virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall phidata\n\nMac\nWindows\npip install -U \"phidata[aws]\"\n\n3\n\nInstall docker\n\nInstall docker desktop to run your app locally\n\n4\n\nExport your OpenAI key\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nCreate your codebase\n\nCreate your codebase using the agent-app template\n\nMac\nWindows\nphi ws create -t agent-app -n agent-app\n\n\nThis will create a folder agent-app with the following structure:\n\nagent-app                     # root directory\n├── agents                  # add your Agents here\n├── app                     # add streamlit apps here\n├── api                     # add fastApi routes here\n├── db                      # add database tables here\n├── Dockerfile              # Dockerfile for the application\n├── pyproject.toml          # python project definition\n├── requirements.txt        # python dependencies generated using pyproject.toml\n├── scripts                 # helper scripts\n├── utils                   # shared utilities\n└── workspace               # phidata workspace directory\n    ├── dev_resources.py    # dev resources running locally\n    ├── prd_resources.py    # production resources running on AWS\n    ├── secrets             # secrets\n    └── settings.py         # phidata workspace settings\n\n​\nTest your Agents using Streamlit\n\nStreamlit allows us to build micro front-ends for testing our Agents. Start the app using:\n\nterminal\nshorthand\nphi ws up --group app\n\n\nPress Enter to confirm and give a few minutes for the image to download (only the first time). Verify container status and view logs on the docker dashboard.\n\nOpen localhost:8501 to view your AI Agent.\nThe streamlit apps are defined in the app folder\nThe Agents are defined in the agents folder.\n​\nServe your Agents using FastApi\n\nStreamlit is great for building micro front-ends but any production application will be built using a front-end framework like next.js backed by a RestApi built using FastApi.\n\nYour Agent App comes ready-to-use with FastApi endpoints. Start the api using:\n\nterminal\nshorthand\nphi ws up --group api\n\nOpen localhost:8000/docs to view the API Endpoints.\nTest the /v1/playground/agent/run endpoint with\n{\n  \"message\": \"howdy\",\n  \"agent_id\": \"example-agent\",\n  \"stream\": true\n}\n\n​\nBuilding your AI Product\n\nThe agent-app comes with common endpoints that you can use to build your AI product. This API is developed in close collaboration with real AI Apps and are a great starting point.\n\nThe general workflow is:\n\nYour front-end/product will call the /v1/playground/agent/run to run Agents.\nUsing the session_id returned, your product can continue and serve chats to its users.\n​\nDelete local resources\n\nPlay around and stop the workspace using:\n\nterminal\nfull options\nshorthand\nphi ws down\n\n\nor stop individual Apps using:\n\napp\napi\ndatabase\nphi ws down --group app\n\n​\nNext\n\nCongratulations on running an Agent App locally. Next Steps:\n\nRun your Agent App on AWS\nRead how to update workspace settings\nRead how to create a git repository for your workspace\nRead how to manage the development application\nRead how to format and validate your code\nRead how to add python libraries\nChat with us on discord\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWorkflows\nVideos\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAgent App\nSetup\nCreate your codebase\nTest your Agents using Streamlit\nServe your Agents using FastApi\nBuilding your AI Product\nDelete local resources\nNext"
  },
  {
    "title": "Monitoring - Phidata",
    "url": "https://docs.phidata.com/monitoring",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nMonitoring\n\nPhidata comes with built-in monitoring and debugging.\n\nYou can set monitoring=True on any agent to log that agent’s sessions or set PHI_MONITORING=true in your environment to log all agent sessions.\n\nCreate a file monitoring.py with the following code:\n\nmonitoring.py\nfrom phi.agent import Agent\n\nagent = Agent(markdown=True, monitoring=True)\nagent.print_response(\"Share a 2 sentence horror story\")\n\n​\nAuthenticate with phidata\n\nAuthenticate with phidata by running the following command:\n\nphi auth\n\n\nOR by exporting the PHI_API_KEY for your workspace from phidata.app\n\nMac\nWindows\nexport PHI_API_KEY=phi-***\n\n​\nRun the agent\n\nRun the agent and view the session on phidata.app/sessions\n\npython monitoring.py\n\n​\nDebugging\n\nPhidata also includes a built-in debugger that will show debug logs in the terminal. You can set debug_mode=True on any agent to view debug logs or set PHI_DEBUG=true in your environment.\n\ndebugging.py\nfrom phi.agent import Agent\n\nagent = Agent(markdown=True, debug_mode=True)\nagent.print_response(\"Share a 2 sentence horror story\")\n\n\nRun the agent to view debug logs in the terminal:\n\npython debugging.py\n\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nWorkflows\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthenticate with phidata\nRun the agent\nDebugging"
  },
  {
    "title": "Agent UI - Phidata",
    "url": "https://docs.phidata.com/agent-ui",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgent UI\n\nPhidata provides a beautiful Agent UI for interacting with your agents.\n\nAgent Playground\n\nNo data is sent to phidata, all agent sessions are stored locally in a sqlite database.\n\nLet’s take it for a spin, create a file playground.py\n\nplayground.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.storage.agent.sqlite import SqlAgentStorage\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\nfrom phi.playground import Playground, serve_playground_app\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    storage=SqlAgentStorage(table_name=\"web_agent\", db_file=\"agents.db\"),\n    add_history_to_messages=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    storage=SqlAgentStorage(table_name=\"finance_agent\", db_file=\"agents.db\"),\n    add_history_to_messages=True,\n    markdown=True,\n)\n\napp = Playground(agents=[finance_agent, web_agent]).get_app()\n\nif __name__ == \"__main__\":\n    serve_playground_app(\"playground:app\", reload=True)\n\nMake sure the serve_playground_app() points to the file that contains your Playground app.\n​\nAuthenticate with phidata\n\nAuthenticate with phidata by running the following command:\n\nphi auth\n\n\nOR by exporting the PHI_API_KEY for your workspace from phidata.app\n\nMac\nWindows\nexport PHI_API_KEY=phi-***\n\n​\nRun the playground\n\nInstall dependencies and run the Agent Playground:\n\npip install 'fastapi[standard]' sqlalchemy\n\npython playground.py\n\n​\nView the playground\nOpen your link provided or navigate to http://phidata.app/playground (login required)\nSelect the localhost:7777 endpoint and start chatting with your agents!\n​\nDemo Agents\n\nThe Agent Playground includes a few demo agents that you can test with. If you have recommendations for other agents we should build, please let us know in the community forum.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgents\nMonitoring\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAuthenticate with phidata\nRun the playground\nView the playground\nDemo Agents"
  },
  {
    "title": "Could Not Connect To Docker - Phidata",
    "url": "https://docs.phidata.com/faq/could-not-connect-to-docker",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nFAQs\nDocker Connection Error\nEnvironment Variables Setup\nCommand line authentication\nConnecting to Tableplus\nFAQs\nCould Not Connect To Docker\n\nIf you have Docker up and running and get the following error, please read on:\n\nERROR    Could not connect to docker. Please confirm docker is installed and running\nERROR    Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))\n\n​\nQuick fix\n\nCreate the /var/run/docker.sock symlink using:\n\nsudo ln -s \"$HOME/.docker/run/docker.sock\" /var/run/docker.sock\n\n\nIn 99% of the cases, this should work. If it doesnt, try:\n\nsudo chown $USER /var/run/docker.sock\n\n​\nFull details\n\nPhidata uses docker-py to run containers, and if the /var/run/docker.sock is missing or has incorrect permissions, it cannot connect to docker.\n\nTo fix, please create the /var/run/docker.sock file using:\n\nsudo ln -s \"$HOME/.docker/run/docker.sock\" /var/run/docker.sock\n\n\nIf that does not work, check the permissions using ls -l /var/run/docker.sock.\n\nIf the /var/run/docker.sock does not exist, check if the $HOME/.docker/run/docker.sock file is missing. If its missing, please reinstall Docker.\n\nIf none of this works and the /var/run/docker.sock exists:\n\nGive your user permissions to the /var/run/docker.sock file:\nsudo chown $USER /var/run/docker.sock\n\nGive your user permissions to the docker group:\nsudo usermod -a -G docker $USER\n\n​\nMore info\nDocker-py Issue\nStackoverflow answer\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nEnvironment Variables Setup\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nQuick fix\nFull details\nMore info"
  },
  {
    "title": "Agent - Phidata",
    "url": "https://docs.phidata.com/reference/agent",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nBuilding Blocks\nAgent\nCustom Agents\nModels\nStorage\nKnowledge Base\nVectorDbs\nCommand Line\nphi\nphi ws\nBuilding Blocks\nAgent\n\nThe Agent class provides an easy to use interface to language models.\n\n​\nExample\nagent.py\nfrom phi.agent import Agent\n\nagent = Agent(description=\"You help people with their health and fitness goals.\")\n\n# -*- Print a response\nagent.print_response('Share a quick healthy breakfast recipe.', markdown=True)\n\n# -*- Get the response as a string\nresponse = agent.run('Share a quick healthy breakfast recipe.', stream=False)\n\n# -*- Get the response as a stream\nresponse = \"\"\nfor delta in agent.run('Share a quick healthy breakfast recipe.'):\n    response += delta\n\n​\nAgent Params\nParameter\tType\tDefault\tDescription\nmodel\tOptional[Model]\tNone\tModel to use for this Agent (alias: \"provider\")\nname\tOptional[str]\tNone\tAgent name\nagent_id\tOptional[str]\tNone\tAgent UUID (autogenerated if not set)\nagent_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with this agent\nintroduction\tOptional[str]\tNone\tAgent introduction. This is added to the chat history when a run is started.\nuser_id\tOptional[str]\tNone\tID of the user interacting with this agent\nuser_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with the user interacting with this agent\nsession_id\tOptional[str]\tNone\tSession UUID (autogenerated if not set)\nsession_name\tOptional[str]\tNone\tSession name\nsession_data\tOptional[Dict[str, Any]]\tNone\tMetadata associated with this session\nmemory\tAgentMemory\tAgentMemory()\tAgent Memory\nadd_history_to_messages\tbool\tFalse\tAdd chat history to the messages sent to the Model. (alias: \"add_chat_history_to_messages\")\nnum_history_responses\tint\t3\tNumber of historical responses to add to the messages.\nknowledge\tOptional[AgentKnowledge]\tNone\tAgent Knowledge (alias: \"knowledge_base\")\nadd_context\tbool\tFalse\tEnable RAG by adding context from AgentKnowledge to the user prompt.\nretriever\tOptional[Callable[..., Optional[list[dict]]]]\tNone\tFunction to get context to add to the user_message\ncontext_format\tLiteral[\"json\", \"yaml\"]\t\"json\"\tFormat of the context\nadd_context_instructions\tbool\tFalse\tIf True, add instructions for using the context to the system prompt\nstorage\tOptional[AgentStorage]\tNone\tAgent Storage\ntools\tOptional[List[Union[Tool, Toolkit, Callable, Dict, Function]]]\tNone\tA list of tools provided to the Model.\nshow_tool_calls\tbool\tFalse\tShow tool calls in Agent response.\ntool_call_limit\tOptional[int]\tNone\tMaximum number of tool calls allowed.\ntool_choice\tOptional[Union[str, Dict[str, Any]]]\tNone\tControls which (if any) tool is called by the model.\nreasoning\tbool\tFalse\tEnable reasoning by working through the problem step by step.\nreasoning_model\tOptional[Model]\tNone\tModel to use for reasoning\nreasoning_agent\tOptional[Agent]\tNone\tAgent to use for reasoning\nreasoning_min_steps\tint\t1\tMinimum number of reasoning steps\nreasoning_max_steps\tint\t10\tMaximum number of reasoning steps\nread_chat_history\tbool\tFalse\tAdd a tool that allows the Model to read the chat history.\nsearch_knowledge\tbool\tTrue\tAdd a tool that allows the Model to search the knowledge base (aka Agentic RAG)\nupdate_knowledge\tbool\tFalse\tAdd a tool that allows the Model to update the knowledge base.\nread_tool_call_history\tbool\tFalse\tAdd a tool that allows the Model to get the tool call history.\nadd_messages\tOptional[List[Union[Dict, Message]]]\tNone\tA list of extra messages added after the system message and before the user message.\nsystem_prompt\tOptional[str]\tNone\tSystem prompt: provide the system prompt as a string\nsystem_prompt_template\tOptional[PromptTemplate]\tNone\tSystem prompt template: provide the system prompt as a PromptTemplate\nuse_default_system_message\tbool\tTrue\tIf True, build a default system message using agent settings and use that\nsystem_message_role\tstr\t\"system\"\tRole for the system message\ndescription\tOptional[str]\tNone\tA description of the Agent that is added to the start of the system message.\ntask\tOptional[str]\tNone\tThe task the agent should achieve.\ninstructions\tOptional[List[str]]\tNone\tList of instructions for the agent.\nguidelines\tOptional[List[str]]\tNone\tList of guidelines for the agent.\nexpected_output\tOptional[str]\tNone\tProvide the expected output from the Agent.\nadditional_context\tOptional[str]\tNone\tAdditional context added to the end of the system message.\nprevent_hallucinations\tbool\tFalse\tIf True, add instructions to return \"I dont know\" when the agent does not know the answer.\nprevent_prompt_leakage\tbool\tFalse\tIf True, add instructions to prevent prompt leakage\nlimit_tool_access\tbool\tFalse\tIf True, add instructions for limiting tool access to the default system prompt if tools are provided\nmarkdown\tbool\tFalse\tIf markdown=true, add instructions to format the output using markdown\nadd_name_to_instructions\tbool\tFalse\tIf True, add the agent name to the instructions\nadd_datetime_to_instructions\tbool\tFalse\tIf True, add the current datetime to the instructions to give the agent a sense of time\nuser_prompt\tOptional[Union[List, Dict, str]]\tNone\tUser prompt: provide the user prompt as a string\nuser_prompt_template\tOptional[PromptTemplate]\tNone\tUser prompt template: provide the user prompt as a PromptTemplate\nuse_default_user_message\tbool\tTrue\tIf True, build a default user prompt using references and chat history\nuser_message_role\tstr\t\"user\"\tRole for the user message\nresponse_model\tOptional[Type[BaseModel]]\tNone\tProvide a response model to get the response as a Pydantic model (alias: \"output_model\")\nparse_response\tbool\tTrue\tIf True, the response from the Model is converted into the response_model\nstructured_outputs\tbool\tFalse\tUse the structured_outputs from the Model if available\nsave_response_to_file\tOptional[str]\tNone\tSave the response to a file\nteam\tOptional[List[\"Agent\"]]\tNone\tAn Agent can have a team of agents that it can transfer tasks to.\nrole\tOptional[str]\tNone\tWhen the agent is part of a team, this is the role of the agent in the team\nadd_transfer_instructions\tbool\tTrue\tAdd instructions for transferring tasks to team members\ndebug_mode\tbool\tFalse\tdebug_mode=True enables debug logs\nmonitoring\tbool\tFalse\tmonitoring=True logs Agent information to phidata.app for monitoring\ntelemetry\tbool\tTrue\ttelemetry=True logs minimal telemetry for analytics\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nPython\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nExample\nAgent Params"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/templates/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nTemplates\nIntroduction\nAgent App\nAgent API\nHow to\nManage Application\nManage Workspace\nWorkspace\nIntroduction\nSettings\nResources\nApps\nIntroduction\nExamples\nFeatures\nResources\nIntroduction\nDocker\nAWS\nTemplates\nIntroduction\n\nTo run agents in production, we need to:\n\nServe them using an application like FastApi, Django or Streamlit.\nManage their sessions, memory and knowlege in a database.\nMonitor, evaluate and improve their performance.\n\nPhidata not only makes building Agents easy but also provides templates that can be deployed to AWS with 1 command. Here’s how they work:\n\nCreate your codebase using a template: phi ws create\nRun your application locally: phi ws up\nRun your application on AWS: phi ws up prd:aws\n\nWe strongly believe that data used by AI applications should be stored securely inside your VPC.\n\nWe fully support BYOC (Bring Your Own Cloud) and encourage you to use your own AWS account.\n\n​\nTemplates\n\nWe recommend starting with the agent-app template and adding your own agents.\n\nAgent App\n\nRun agents using FastApi, Streamlit and store memory and knowlege in Postgres\n\nAgent Api\n\nRun agents using FastApi and store memory and knowlege in Postgres\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nRun locally\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nTemplates"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\n15680\n2160\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  },
  {
    "title": "Introduction - Phidata",
    "url": "https://docs.phidata.com/examples/introduction",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nExamples\nIntroduction\nAgents\nModels\nIntegrations\nAgent Teams\nUse Cases\nHow To\nClone Cookbook\nExamples\nIntroduction\n\nHere you’ll find examples that’ll help you use phidata, from basic agents and workflows to advanced fine-tuning and evaluations. If you have more, please contribute to this list.\n\nYou can run each recipe individually or clone the phidata cookbook and run it from there.\n\n​\nAgents\nWeb Search\n\nAn agent that can search the web.\n\nFinance Agent\n\nAn agent that can analyze financial data.\n\nAgent Team\n\nA Team of Agents that can work together.\n\nReasoning Agent\n\nAn Agent that can reason and provide a step-by-step solution.\n\nPython Agent\n\nAn Agent that can write and run python code.\n\nData Analyst\n\nAn Agent that can analyze data using DuckDB.\n\nStructured Output\n\nAn Agent that can respond with pydantic objects.\n\nPython Function Agent\n\nAn Agent that can call python functions.\n\nVision Agent\n\nAn Agent that can use an image as input.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nWeb Search Agent\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nAgents"
  },
  {
    "title": "Agents - Phidata",
    "url": "https://docs.phidata.com/agents",
    "html": "Search or ask...\nCtrl K\nDiscord\nCommunity\nLog In\nphidatahq/phidata\nDocumentation\nExamples\nTemplates\nReference\nFAQs\nPhidata home page\nIntroduction\nAgents\nAgent UI\nMonitoring\nWorkflows\nTemplates\nVideos\nGetting Help\nDocumentation\nAgents\nModels\nTools\nKnowledge\nVectorDbs\nStorage\nEmbeddings\nWorkflows\nHow To\nInstall & Upgrade\nUpgrade to v2.5.0\nIntroduction\nAgents\n\nAgents are autonomous programs that complete tasks using language models.\n\n​\nWhat is phidata?\n\nPhidata is a framework for building agentic systems, engineers use phidata to:\n\nBuild Agents with memory, knowledge, tools and reasoning.\nBuild teams of Agents that can work together.\nChat with Agents using a beautiful Agent UI.\nMonitor, evaluate and optimize Agents.\nBuild agentic systems i.e. applications with an API, database and vectordb.\n​\nLet’s build some agents\n1\n\nSetup your virtual environment\n\nMac\nWindows\npython3 -m venv ~/.venvs/aienv\nsource ~/.venvs/aienv/bin/activate\n\n2\n\nInstall libraries\n\nMac\nWindows\npip install -U phidata openai\n\n3\n\nExport your OpenAI key\n\nPhidata works with every LLM but for these examples let’s use OpenAI.\n\nMac\nWindows\nexport OPENAI_API_KEY=sk-***\n\n\nYou can get an API key from here.\n\n​\nWeb Search Agent\n\nLet’s build a simple agent that can search the web, create a file web_search.py\n\n1\n\nCreate a web search agent\n\nweb_search.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nweb_agent.print_response(\"Whats happening in France?\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install duckduckgo-search\n\n\nRun the agent\n\npython web_search.py\n\n​\nFinancial Agent\n\nLets create another agent that can query financial data, create a file finance_agent.py\n\n1\n\nCreate a finance agent\n\nfinance_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.yfinance import YFinanceTools\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True, company_news=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\nfinance_agent.print_response(\"Summarize analyst recommendations for NVDA\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install yfinance\n\n\nRun the agent\n\npython finance_agent.py\n\n​\nTeam of Agents\n\nA team of agents can work together to solve complex problems, create a file agent_team.py\n\n1\n\nCreate an agent team\n\nagent_team.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.tools.duckduckgo import DuckDuckGo\nfrom phi.tools.yfinance import YFinanceTools\n\nweb_agent = Agent(\n    name=\"Web Agent\",\n    role=\"Search the web for information\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[DuckDuckGo()],\n    instructions=[\"Always include sources\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nfinance_agent = Agent(\n    name=\"Finance Agent\",\n    role=\"Get financial data\",\n    model=OpenAIChat(id=\"gpt-4o\"),\n    tools=[YFinanceTools(stock_price=True, analyst_recommendations=True, company_info=True)],\n    instructions=[\"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team = Agent(\n    team=[web_agent, finance_agent],\n    instructions=[\"Always include sources\", \"Use tables to display data\"],\n    show_tool_calls=True,\n    markdown=True,\n)\n\nagent_team.print_response(\"Summarize analyst recommendations and share the latest news for NVDA\", stream=True)\n\n2\n\nRun the agent team\n\nRun the agent team\n\npython agent_team.py\n\n\nAgent teams are non-deterministic and are not recommended for production systems, we recommend using workflows instead.\n\n​\nAgentic RAG\n\nInstead of always inserting the “context” into the prompt, we give our Agent a tool to search its knowledge base (vector db) for the information it needs.\n\nThis saves tokens and improves response quality. Create a file rag_agent.py\n\n1\n\nCreate a RAG agent\n\nrag_agent.py\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\nfrom phi.embedder.openai import OpenAIEmbedder\nfrom phi.knowledge.pdf import PDFUrlKnowledgeBase\nfrom phi.vectordb.lancedb import LanceDb, SearchType\n\n# Create a knowledge base from a PDF\nknowledge_base = PDFUrlKnowledgeBase(\n    urls=[\"https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf\"],\n    # Use LanceDB as the vector database\n    vector_db=LanceDb(\n        table_name=\"recipes\",\n        uri=\"tmp/lancedb\",\n        search_type=SearchType.vector,\n        embedder=OpenAIEmbedder(model=\"text-embedding-3-small\"),\n    ),\n)\n# Comment out after first run as the knowledge base is loaded\nknowledge_base.load()\n\nagent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    # Add the knowledge base to the agent\n    knowledge=knowledge_base,\n    show_tool_calls=True,\n    markdown=True,\n)\nagent.print_response(\"How do I make chicken and galangal in coconut milk soup\", stream=True)\n\n2\n\nRun the agent\n\nInstall libraries\n\npip install lancedb tantivy pypdf sqlalchemy\n\n\nRun the agent\n\npython rag_agent.py\n\n​\nStructured Outputs\n\nAgents can return their output in a structured format as a Pydantic model.\n\nCreate a file structured_output.py\n\n1\n\nCreate a structured output agent\n\nstructured_output.py\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom phi.agent import Agent\nfrom phi.model.openai import OpenAIChat\n\n# Define a Pydantic model to enforce the structure of the output\nclass MovieScript(BaseModel):\n    setting: str = Field(..., description=\"Provide a nice setting for a blockbuster movie.\")\n    ending: str = Field(..., description=\"Ending of the movie. If not available, provide a happy ending.\")\n    genre: str = Field(..., description=\"Genre of the movie. If not available, select action, thriller or romantic comedy.\")\n    name: str = Field(..., description=\"Give a name to this movie\")\n    characters: List[str] = Field(..., description=\"Name of characters for this movie.\")\n    storyline: str = Field(..., description=\"3 sentence storyline for the movie. Make it exciting!\")\n\n# Agent that uses JSON mode\njson_mode_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n)\n# Agent that uses structured outputs\nstructured_output_agent = Agent(\n    model=OpenAIChat(id=\"gpt-4o-2024-08-06\"),\n    description=\"You write movie scripts.\",\n    response_model=MovieScript,\n    structured_outputs=True,\n)\n\njson_mode_agent.print_response(\"New York\")\nstructured_output_agent.print_response(\"New York\")\n\n2\n\nRun the agent\n\npython structured_output.py\n\n​\nNext Steps\nChat with your Agents using a beautiful Agent UI.\nLearn how to monitor and debug your Agents.\nFor more advanced cases, build deterministic, stateful, multi-agent workflows.\n\nWas this page helpful?\n\nYes\nNo\nSuggest edits\nAgent UI\nx\ngithub\ndiscord\nyoutube\nwebsite\nPowered by Mintlify\nOn this page\nWhat is phidata?\nLet’s build some agents\nWeb Search Agent\nFinancial Agent\nTeam of Agents\nAgentic RAG\nStructured Outputs\nNext Steps"
  }
]